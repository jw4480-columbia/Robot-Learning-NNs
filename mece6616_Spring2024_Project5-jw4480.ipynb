{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KeFkzyo2s5QZl2PDyguSItXvceDgrorp","timestamp":1713749570112},{"file_id":"1Pr2hrhczGE8v5U8UulPCPlmEeeTyjdFk","timestamp":1712862547064}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **MECS6616 Spring 2024 - Project 5**"],"metadata":{"id":"PxhEChyomf5o"}},{"cell_type":"markdown","source":["# **Introduction**\n","\n","***IMPORTANT:***\n","- **Before starting, make sure to read the [Assignment Instructions](https://courseworks2.columbia.edu/courses/197115/pages/assignment-instructions) page on Courseworks to understand the workflow and submission requirements for this project.**\n","\n","**FOR PROJECT 5!!!**\n","- Apart from the link to your notebook, you are also required to submit `q_network.pth` of Part 1 and `ppo_network.zip` (model checkpoints are loaded and saved by stable_baselines3 as zip files) of Part 2 to Coursework. You should put the link to your notebook in the comment entry"],"metadata":{"id":"50kTBhSwmrJB"}},{"cell_type":"markdown","metadata":{"id":"inY7y5CRo97q"},"source":["# Project Setup\n"]},{"cell_type":"code","source":["# DO NOT CHANGE\n","\n","# There will be error messages from this command. You can ignore those error messages\n","# as long as you see \"Successfully installed setuptools-65.5.0\" at the end.\n","\n","# After installing setuptools, a pop-up window will appear and you will be prompted\n","# to restart the notebook environment. Click on the restart environment button before continuing\n","\n","!pip install setuptools==65.5.0"],"metadata":{"id":"PTRNqFBLkRDV","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"ok","timestamp":1714060333985,"user_tz":240,"elapsed":19012,"user":{"displayName":"Jingran Wang","userId":"11496959489179416337"}},"outputId":"edf6c914-6a2d-43a7-deae-09bb9e794a2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting setuptools==65.5.0\n","  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: setuptools\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 67.7.2\n","    Uninstalling setuptools-67.7.2:\n","      Successfully uninstalled setuptools-67.7.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 65.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed setuptools-65.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","pkg_resources","setuptools"]},"id":"e7f1439da5634330ad38974c0c75abf5"}},"metadata":{}}]},{"cell_type":"markdown","source":["**----------------------------**\n","**WAIT FOR NOTEBOOK TO RESTART**\n","**----------------------------**"],"metadata":{"id":"tnf22sQzqw6_"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"QPIiNSZ8hb8Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715013212319,"user_tz":240,"elapsed":1196,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"7f14161e-4be3-4913-9c99-241e39e41951"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mecs6616_sp24_project5'...\n","remote: Enumerating objects: 15, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 15 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (15/15), 9.22 KiB | 1.54 MiB/s, done.\n"]}],"source":["# DO NOT CHANGE\n","\n","# After running this cell, the folder 'mecs6616_sp23_project3' will show up in the file explorer on the left (click on the folder icon if it's not open)\n","# It may take a few seconds to appear\n","!git clone https://github.com/roamlab/mecs6616_sp24_project5.git"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ise8RAQhhs3X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715013212565,"user_tz":240,"elapsed":248,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"e4c5c8ce-9b7a-47ee-8a43-4438297f6625"},"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/mecs6616_sp24_project5/arm_dynamics_base.py' -> '/content/arm_dynamics_base.py'\n","'/content/mecs6616_sp24_project5/arm_dynamics.py' -> '/content/arm_dynamics.py'\n","'/content/mecs6616_sp24_project5/arm_env.py' -> '/content/arm_env.py'\n","'/content/mecs6616_sp24_project5/geometry.py' -> '/content/geometry.py'\n","'/content/mecs6616_sp24_project5/README.md' -> '/content/README.md'\n","'/content/mecs6616_sp24_project5/render.py' -> '/content/render.py'\n","'/content/mecs6616_sp24_project5/robot.py' -> '/content/robot.py'\n","'/content/mecs6616_sp24_project5/score.py' -> '/content/score.py'\n"]}],"source":["# DO NOT CHANGE\n","\n","# copy all needed files into the working directory. This is simply to make accessing files easier\n","!cp -av /content/mecs6616_sp24_project5/* /content/"]},{"cell_type":"code","source":["# DO NOT CHANGE\n","\n","# There will be error messages from this command. You can ignore those error messages\n","# as long as you see \"Successfully installed gym-0.21.0 stable-baselines3-1.5.0\" at the end.\n","\n","!pip install wheel==0.38.4\n","!pip install gym==0.21.0 stable-baselines3==1.5.0"],"metadata":{"id":"qEFlC9hVkRrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715013301977,"user_tz":240,"elapsed":88480,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"ced33085-f056-476c-c860-e84d86acc8e9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wheel==0.38.4\n","  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n","Installing collected packages: wheel\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.43.0\n","    Uninstalling wheel-0.43.0:\n","      Successfully uninstalled wheel-0.43.0\n","Successfully installed wheel-0.38.4\n","Collecting gym==0.21.0\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting stable-baselines3==1.5.0\n","  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.7/177.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0) (2.2.1)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==1.5.0) (2.2.1+cu121)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==1.5.0) (2.0.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==1.5.0) (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->stable-baselines3==1.5.0) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->stable-baselines3==1.5.0)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==1.5.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==1.5.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==1.5.0) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==1.5.0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->stable-baselines3==1.5.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->stable-baselines3==1.5.0) (1.3.0)\n","Building wheels for collected packages: gym\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616799 sha256=9baf886eba8332bc12c7d183cc72ef9ef4267440555dccba6bd708ae86421fb2\n","  Stored in directory: /root/.cache/pip/wheels/81/aa/90/b67df76370d3916a2189b662cf48da38ce41a4e7e58b6abff5\n","Successfully built gym\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gym, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","Successfully installed gym-0.21.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 stable-baselines3-1.5.0\n"]}]},{"cell_type":"markdown","source":["# Part 1: Implement DQN\n","\n","For this part, you will implement DQN from scratch. You SHOULD NOT use any RL libraries."],"metadata":{"id":"-KNg9fzU5Un7"}},{"cell_type":"markdown","metadata":{"id":"t-JvzRuwNsYz"},"source":["## Starter Code Explanation\n","In addition to code you are already familiar with from the previous project (i.e. arm dynamics, etc.) we are providing an \"Environment\" in the `ArmEnv` class. The environment \"wraps around\" the arm dynamics and provides the key functions that an RL algorithm expects: reset(...) and step(...). The implementation of `ArmEnv` follows the [OpenAI Gym](https://www.gymlibrary.dev/api/core/) API standard. It is a standard that is accepeted by many RL libraries and allows for our problem to be easily solved with various RL libraries. Take a moment to familiarize yourself with these functions! See [here](https://www.gymlibrary.dev/api/core/) for more information on the definition of the reset(...) and step(...) functions.\n","\n","Important notes:\n","\n","* The ArmEnv expects an action similar to the one used previously: a vector with a torque for every arm joint. Thus, the native action space for this environment is high-dimensional, and continuous. DQN will require an action space that is 1-dimensional and discrete. You will need to convert between these. For example, you can have an action space of [0, 1, 2,] where each number just represents the identity of an action candidate, and a conversion dictionary {0: [-0.1, -0.1], 1: [0.1, 0.1], 2: [0, 0]}. Then, when the Q network output an action 1, it will be converted into [0.1, 0.1] and used by the environment. Note that this is just an example method to implement the conversion and you do not have to follow the same procedure.\n","* The observation provided by the environment will comprise the same state vector as before, to which we append the current position of the end_effector and the goal for the end-effector. Since your policy must learn to reach arbitrary goals, the goal must be provided as part of the observation. So the observation will consist of 8 values: 4 for the state, 2 for the pos_ee and 2 for the goal.\n","* The maximum episode length of the environment is 200 steps. Each step is simulated for 0.01 second. This should be used for both training and testing.\n","* The reward function of this environment is by default r(s, a) = - dist(pos_ee, goal)^2 where represents the negative square of L2 distance between the current position of the end-effector and the goal position."]},{"cell_type":"markdown","source":["### Arm Environment Example\n","You are encouraged to view the `arm_env.py` file to understand the `random_goal()`, `reset()` and `step()`  functions but do not modify the file.\n","\n","The `env.reset()` method, will reset the arm in the vertically downwards position and set a new random goal by calling the `random_goal()` method. By understanding how the goals are set you could guide your training in that direction. You can also provide your own goal as a (2,1) array to the reset function as an argument. This could come handy later when training the model.\n","\n","The `env.step()` function takes an action as a (2,1) shaped array and outputs the next observation, reward, done and info. `info` is a dictionary with pos_ee and vel_ee values. This can come handy if you attempt to do some reward engineering.\n","\n","The cell below provides an example of random policy interacting with the ArmEnv for 50 steps (0.5 seconds)"],"metadata":{"id":"gw8H0PZcSv7F"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"o6r9kJ5jpeds","executionInfo":{"status":"ok","timestamp":1715013360225,"user_tz":240,"elapsed":1031,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}}},"outputs":[],"source":["from render import Renderer\n","from arm_env import ArmEnv\n","from robot import Robot\n","from arm_dynamics import ArmDynamics\n","import numpy as np\n","\n","# DO NOT CHANGE arm parameters\n","arm = Robot(\n","        ArmDynamics(\n","            num_links=2,\n","            link_mass=0.1,\n","            link_length=1,\n","            joint_viscous_friction=0.1,\n","            dt=0.01,\n","\t    \t\t\tgravity=False\n","        )\n","    )\n","arm.reset()\n","# ------------------\n","\n","env = ArmEnv(arm, gui=False)\n","\n","# Passing our own defined goal to the reset function\n","# goal = np.array([[0.5], [-1.5]])\n","# obs = env.reset(goal)\n","\n","# Resetting the environment without the goal will set a random goal position\n","obs = env.reset()\n","\n","for _ in range(50):\n","  rand_action = np.random.uniform(-1.5, 1.5, (2,1))\n","  obs, reward, done, info = env.step(rand_action)"]},{"cell_type":"markdown","metadata":{"id":"4jmXTT_ngdqG"},"source":["### QNetwork\n","This class defines the architecture of your network. You must fill in the __init__(...) function which defines your network, and the forward(...) function which performs the forward pass.\n","\n","Your action space should be discrete, with whatever cardinality you decide. The size of the output layer of your Q-Network should thus be the same as the cardinality of your action space. When selecting an action, a policy must choose the one that has the highest estimated Q-value for the current state. As part of the QNetwork class, we are providing the function select_discrete_action(...) which does exactly that.\n","\n","The arm environment itself however expects a 2-dimensional, continuous action vector. Therefore, when it comes to send an action to the environment, you must provide the kind of action the environment expects. It is your job to determine how to convert between the discrete action space of your Q-Network and the continuous action space of the arm. You do this by filling in the action_discrete_to_continuous(...) function in your QNetwork. You can expect to call the step function of the environment like this:\n","\n","```\n","self.env.step(self.q_network.action_discrete_to_continuous(discrete_action))\n","```"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7UyguLRKgf_I","executionInfo":{"status":"ok","timestamp":1715013364744,"user_tz":240,"elapsed":3827,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.optim as optim\n","\n","\n","\n","class QNetwork(nn.Module):\n","  def __init__(self, env):\n","    super(QNetwork, self).__init__()\n","    #--------- YOUR CODE HERE --------------\n","    self.fc1 = nn.Linear(env.observation_space.shape[0], 128)\n","    self.fc2 = nn.Linear(128, 128)\n","    self.fc3 = nn.Linear(128,20)\n","\n","\n","\n","    #---------------------------------------\n","\n","  def forward(self, x, device):\n","    #--------- YOUR CODE HERE --------------\n","    x = torch.FloatTensor(x)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","    #---------------------------------------\n","\n","\n","  def select_discrete_action(self, obs, device):\n","    # Put the observation through the network to estimate q values for all possible discrete actions\n","    est_q_vals = self.forward(obs.reshape((1,) + obs.shape), device)\n","    # Choose the discrete action with the highest estimated q value\n","    discrete_action = torch.argmax(est_q_vals, dim=1).tolist()[0]\n","    return discrete_action\n","\n","  def action_discrete_to_continuous(self, discrete_action):\n","    #--------- YOUR CODE HERE --------------\n","    #random assigned action is for somereason better\n","    act_dict={\n","        0:[0.25,-0.4],\n","        1:[-1.4,0.7],\n","        2:[-0.9,0.4],\n","        3:[-0.3,-0.15],\n","        4:[-0.6,1.3],\n","        5:[1,-0.6],\n","        6:[-0.6,-1.2],\n","        7:[-1.2,-1.4],\n","        8:[0.7,0.1],\n","        9:[1.3,-0.9],\n","        10:[0.1,0.25],\n","        11:[1.3,0.2],\n","        12:[-0.15,0],\n","        13:[1,-0.7],\n","        14:[0.2,1.2],\n","        15:[-0.3,0.7],\n","        16:[-0.8,-1.3],\n","        17:[0.4,0.2],\n","        18:[-0.5,1.2],\n","        19:[0.3,-0.2],\n","    }\n","    continuous_action = np.array(act_dict[discrete_action])\n","    return continuous_action\n","    #---------------------------------------\n"]},{"cell_type":"markdown","source":["We provide you with code to use the replay buffer in your RL implementation. You do not need to change the ReplayBuffer class.\n","```\n","rb = ReplayBuffer()\n","```\n","After creating a ReplayBuffer object you can add samples in the buffer using `put()`:\n","```\n","rb.put((obs, action, reward, next_obs, done))\n","```\n","Take random samples from the buffer using:\n","```\n","obs, actions, rewards, next_obses, dones = rb.sample(batch_size)\n","```\n"],"metadata":{"id":"IUjAeQcPdsGR"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"q7NytRAXtYkE","executionInfo":{"status":"ok","timestamp":1715013364745,"user_tz":240,"elapsed":2,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}}},"outputs":[],"source":["import collections\n","import random\n","import numpy as np\n","\n","\n","class ReplayBuffer():\n","    def __init__(self, buffer_limit):\n","        self.buffer = collections.deque(maxlen=buffer_limit)\n","\n","    def put(self, transition):\n","        self.buffer.append(transition)\n","\n","    def sample(self, n):\n","        mini_batch = random.sample(self.buffer, n)\n","        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n","\n","        for transition in mini_batch:\n","            s, a, r, s_prime, done_mask = transition\n","            s_lst.append(s)\n","            a_lst.append(a)\n","            r_lst.append(r)\n","            s_prime_lst.append(s_prime)\n","            done_mask_lst.append(done_mask)\n","\n","        return np.array(s_lst), np.array(a_lst), \\\n","               np.array(r_lst), np.array(s_prime_lst), \\\n","               np.array(done_mask_lst)"]},{"cell_type":"markdown","source":["### TrainDQN\n","Here, you must fill in the train(...) function that actually trains your network.\n","\n","We are providing a helper function called save_model(...) that will save the current Q-network. Use this as you see fit.\n","\n","To set one network equal to another one, you can use code like this:\n","```\n","target_network.load_state_dict(self.q_network.state_dict())\n","```\n","\n","If you would like to be graded with a specific seed for the random number generators, make sure to change the default seed in the initialization of the TrainDQN class.\n","\n","The time taken to train the model will depend mainly on how big is your model architecture and the number of episodes you run the training for. As a reference, the time taken to train a model on 1500 episodes, which passed all evaluation metrics was about an hour.\n","* Reference value for clipping the gradient value as mentioned in class: 0.2\n","* Reference value for a typical size of Replay Buffer: >10k\n","* Reference value for batch size while training: 64 - 512\n","\n","Note that these are just reference values and larger is not always better as it may slow things down.\n","\n","It is good practice in RL to ensure simpler things are working before complicating environments or training techniques.\n","\n","If you think your training method is not working at all, you could pass a fixed goal to the `env.reset()` method during the training loop to ensure that your model is learning."],"metadata":{"id":"pxVawoBLe3bd"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"EwS8xVR7tbeQ","executionInfo":{"status":"ok","timestamp":1715013365623,"user_tz":240,"elapsed":149,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}}},"outputs":[],"source":["import time\n","from render import Renderer\n","from arm_env import ArmEnv\n","import numpy as np\n","from math import dist\n","import os\n","from geometry import polar2cartesian\n","\n","\n","class TrainDQN:\n","\n","  def __init__(self, env, seed=4):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    self.env = env\n","    self.device = torch.device('cpu')\n","    self.q_network = QNetwork(env).to(self.device)\n","    self.target_network = QNetwork(env).to(self.device)\n","    self.target_network.load_state_dict(self.q_network.state_dict())\n","    self.rb=ReplayBuffer(10000)\n","\n","  def save_model(self, episode_num, save_dir='models'):\n","    timestr = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n","    model_dir = os.path.join(save_dir, timestr)\n","    if not os.path.exists(os.path.join(model_dir)):\n","      os.makedirs(os.path.join(model_dir))\n","    savepath = os.path.join(model_dir, f'q_network_ep_{episode_num:04d}.pth')\n","    torch.save(self.q_network.state_dict(), savepath)\n","    print(f'model saved to {savepath}\\n')\n","    return savepath\n","\n","\n","  def train_one_step(self,BATCH_SIZE,GAMMA,max_grad,optimizer):\n","\n","    obs_as_array, actions, rewards, next_obses_as_array, dones=self.rb.sample(BATCH_SIZE)\n","    #print(obs)\n","    #convert to tensors\n","    obs_as_tensor = torch.tensor(obs_as_array, dtype=torch.float32)\n","    act_as_tensor = torch.tensor(actions, dtype=torch.long)\n","    r_as_tensor = torch.tensor(rewards, dtype=torch.float32)\n","    next_obses_as_tensor = torch.tensor(next_obses_as_array, dtype=torch.float32)\n","    dones_as_tensor = torch.tensor(dones, dtype=torch.float32)\n","\n","    #Compute Q values\n","    Q_A = self.q_network.forward(obs_as_tensor, self.device).gather(1, act_as_tensor.unsqueeze(1)).squeeze()\n","    Q_T_m = self.target_network.forward(next_obses_as_tensor, self.device).max(1)[0]\n","    Q_T_est = r_as_tensor + GAMMA * Q_T_m\n","\n","    #Loss function\n","    loss = torch.mean(F.mse_loss(Q_A, Q_T_est))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(self.q_network.parameters(), max_grad)\n","    optimizer.step()\n","    return loss.item()\n","\n","  #test a specific model on a series of goals to get overall performance\n","  def test_model(self,model_path,goals):\n","    test_network = QNetwork(env).to(self.device)\n","    test_network.load_state_dict(torch.load(model_path))\n","    test_network.eval()\n","    total_return=0\n","\n","    for goal in goals:\n","      done = False\n","      obs = env.reset(goal)\n","\n","      episode_return = 0\n","      while not done:\n","        action = test_network.select_discrete_action(obs, self.device)\n","        action = test_network.action_discrete_to_continuous(action)\n","        new_obs, reward, done, info = env.step(action)\n","        episode_return += reward\n","\n","        obs = new_obs\n","      #print('Episode return: ', episode_return)\n","      total_return+=episode_return\n","    total_return/=len(goals)\n","\n","    return total_return\n","\n","  #generate a set of random goals\n","  def generate_goals_series(self,len):\n","    radius_max = 2.0\n","    radius_min = 1.5\n","    angle_max = 0.5\n","    angle_min = -0.5\n","    goals=[]\n","    for i in range(len):\n","      radius = (radius_max - radius_min) * np.random.random() + radius_min\n","      angle = (angle_max - angle_min) * np.random.random() + angle_min\n","      angle -= np.pi / 2\n","      goal = polar2cartesian(radius, angle)\n","      goals.append(goal)\n","\n","    return goals\n","\n","  def train(self):\n","\n","    #--------- YOUR CODE HERE --------------\n","    path_pool=[]\n","\n","    num_epi=1500\n","    batch_size=128\n","    max_grad=3\n","    GAMMA=0.9\n","    eps_threshold=0.2\n","    eps_decay=0.95\n","    optimizer = torch.optim.Adam(self.q_network.parameters(), lr = 0.0005)\n","    reward_episode_max=float('-inf')\n","\n","    #--------- TRAIN 1500 EPISODES --------------\n","    for episode in range(num_epi):\n","      obs=self.env.reset()\n","      reward_episode=0\n","      eps_threshold*=eps_decay\n","      while True:\n","        rand=np.random.uniform(low=0,high=1)\n","        if rand>eps_threshold:\n","          #with torch.no_grad():\n","          discrete_action = self.q_network.select_discrete_action(obs,self.device)\n","        else:\n","          discrete_action=np.random.randint(0,20)\n","        continuous_action = self.q_network.action_discrete_to_continuous(discrete_action)\n","\n","\n","        next_obs, next_r, next_done, _ = self.env.step(continuous_action)\n","\n","        if next_done:\n","          break\n","\n","        reward_episode+=next_r\n","        self.rb.put((obs, discrete_action, next_r, next_obs, next_done))\n","\n","        if len(self.rb.buffer) >= 2000:\n","          self.train_one_step(batch_size,GAMMA,max_grad,optimizer)\n","\n","        obs=next_obs\n","\n","      print(f'End of episode {episode}, totel reward is: {reward_episode}')\n","\n","      if episode%25==0:\n","        self.target_network.load_state_dict(self.q_network.state_dict())\n","      if reward_episode>-5 and episode>=800:\n","        save_path=self.save_model(episode_num=episode)\n","        path_pool.append(save_path)\n","    print('now all models have finished training')\n","    #--------- TRAINING FINISH, RETURN A SET OF GOOD MODEL --------------\n","\n","    #--------- THEN CHOOSE BEST MODEL RUNNING TESTS --------------\n","    goals=self.generate_goals_series(20)\n","    max_reward=float('-inf')\n","    for path in path_pool:\n","      test_reward=self.test_model(path,goals)\n","      print(f'model tested: {path}\\n')\n","      print(f'overall performance: {test_reward}\\n\\n')\n","      if test_reward>max_reward:\n","        max_reward=test_reward\n","        best_model_path=path\n","\n","\n","    return best_model_path\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"sEHSV1Q1BT1t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715017728892,"user_tz":240,"elapsed":4263365,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"95ee95c1-274d-4461-8a14-0f0efbda9d48"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","End of episode 218, totel reward is: -118.29092668266759\n","End of episode 219, totel reward is: -45.40520310440002\n","End of episode 220, totel reward is: -43.02989376855593\n","End of episode 221, totel reward is: -52.07646091235992\n","End of episode 222, totel reward is: -18.2242606310167\n","End of episode 223, totel reward is: -404.814359766083\n","End of episode 224, totel reward is: -58.793500932716896\n","End of episode 225, totel reward is: -57.515989672475804\n","End of episode 226, totel reward is: -197.88409579008342\n","End of episode 227, totel reward is: -80.45324112336198\n","End of episode 228, totel reward is: -74.31477627415723\n","End of episode 229, totel reward is: -264.8402320055236\n","End of episode 230, totel reward is: -32.112686764053706\n","End of episode 231, totel reward is: -40.67331400545908\n","End of episode 232, totel reward is: -79.7282909765223\n","End of episode 233, totel reward is: -16.288506999834397\n","End of episode 234, totel reward is: -11.548263129248726\n","End of episode 235, totel reward is: -709.3526849667401\n","End of episode 236, totel reward is: -41.117008414900546\n","End of episode 237, totel reward is: -39.455857134906466\n","End of episode 238, totel reward is: -14.901549241659708\n","End of episode 239, totel reward is: -24.311947176309825\n","End of episode 240, totel reward is: -7.379739992184502\n","End of episode 241, totel reward is: -20.002608060850903\n","End of episode 242, totel reward is: -4.089725044950356\n","End of episode 243, totel reward is: -5.498992797931875\n","End of episode 244, totel reward is: -19.137440915418207\n","End of episode 245, totel reward is: -58.650437371008785\n","End of episode 246, totel reward is: -69.8929783501379\n","End of episode 247, totel reward is: -21.837069139952174\n","End of episode 248, totel reward is: -13.230370810950744\n","End of episode 249, totel reward is: -36.35156693667649\n","End of episode 250, totel reward is: -19.518698914086006\n","End of episode 251, totel reward is: -59.849194658172195\n","End of episode 252, totel reward is: -12.216514665745164\n","End of episode 253, totel reward is: -43.191554687066365\n","End of episode 254, totel reward is: -34.65474732519121\n","End of episode 255, totel reward is: -11.712766773175419\n","End of episode 256, totel reward is: -46.550960309640566\n","End of episode 257, totel reward is: -24.04170044887496\n","End of episode 258, totel reward is: -13.36758728239671\n","End of episode 259, totel reward is: -24.765735367796047\n","End of episode 260, totel reward is: -15.209946651983794\n","End of episode 261, totel reward is: -243.35187606752388\n","End of episode 262, totel reward is: -14.722695263587342\n","End of episode 263, totel reward is: -527.2110271697688\n","End of episode 264, totel reward is: -23.140235030877882\n","End of episode 265, totel reward is: -47.42089126793822\n","End of episode 266, totel reward is: -13.483125646347633\n","End of episode 267, totel reward is: -14.933811477327552\n","End of episode 268, totel reward is: -182.02376750405983\n","End of episode 269, totel reward is: -19.671786109468197\n","End of episode 270, totel reward is: -11.434485146179021\n","End of episode 271, totel reward is: -323.43544098784537\n","End of episode 272, totel reward is: -373.98280058434517\n","End of episode 273, totel reward is: -58.866639879345016\n","End of episode 274, totel reward is: -61.83623612366659\n","End of episode 275, totel reward is: -14.979133675254307\n","End of episode 276, totel reward is: -19.02795554716793\n","End of episode 277, totel reward is: -15.70110359161847\n","End of episode 278, totel reward is: -529.7628587691427\n","End of episode 279, totel reward is: -556.102029855308\n","End of episode 280, totel reward is: -77.08830342576772\n","End of episode 281, totel reward is: -12.973795434282342\n","End of episode 282, totel reward is: -484.5760672849001\n","End of episode 283, totel reward is: -313.67270048210617\n","End of episode 284, totel reward is: -6.460028841848635\n","End of episode 285, totel reward is: -716.4029057966108\n","End of episode 286, totel reward is: -486.95685295680516\n","End of episode 287, totel reward is: -763.953916550986\n","End of episode 288, totel reward is: -38.33448329653479\n","End of episode 289, totel reward is: -285.57589666375696\n","End of episode 290, totel reward is: -40.224672114679784\n","End of episode 291, totel reward is: -366.4118838834939\n","End of episode 292, totel reward is: -225.05558336628894\n","End of episode 293, totel reward is: -1.9133125199850916\n","End of episode 294, totel reward is: -594.7075371079372\n","End of episode 295, totel reward is: -962.616853961288\n","End of episode 296, totel reward is: -619.8661724726187\n","End of episode 297, totel reward is: -188.25312848046724\n","End of episode 298, totel reward is: -568.3178668614177\n","End of episode 299, totel reward is: -48.87010813260029\n","End of episode 300, totel reward is: -153.11370150987412\n","End of episode 301, totel reward is: -312.9621068721946\n","End of episode 302, totel reward is: -553.6825224018257\n","End of episode 303, totel reward is: -374.65939588064936\n","End of episode 304, totel reward is: -30.79547110250926\n","End of episode 305, totel reward is: -45.71770480680325\n","End of episode 306, totel reward is: -209.36387956408302\n","End of episode 307, totel reward is: -4.42777880033394\n","End of episode 308, totel reward is: -41.595459748218595\n","End of episode 309, totel reward is: -61.335460300089856\n","End of episode 310, totel reward is: -37.09176591271386\n","End of episode 311, totel reward is: -72.53289194854551\n","End of episode 312, totel reward is: -30.419047533014513\n","End of episode 313, totel reward is: -75.88492495271501\n","End of episode 314, totel reward is: -407.1136737230328\n","End of episode 315, totel reward is: -112.00114267899043\n","End of episode 316, totel reward is: -241.71690699050797\n","End of episode 317, totel reward is: -273.2337034668502\n","End of episode 318, totel reward is: -21.606774273885456\n","End of episode 319, totel reward is: -35.55985504576531\n","End of episode 320, totel reward is: -314.8639462022728\n","End of episode 321, totel reward is: -59.43893726680663\n","End of episode 322, totel reward is: -17.8304832871037\n","End of episode 323, totel reward is: -295.18947219583737\n","End of episode 324, totel reward is: -72.57241119030627\n","End of episode 325, totel reward is: -123.67245820144845\n","End of episode 326, totel reward is: -462.1030008103247\n","End of episode 327, totel reward is: -49.632198527007425\n","End of episode 328, totel reward is: -34.18364825550969\n","End of episode 329, totel reward is: -586.5444571593646\n","End of episode 330, totel reward is: -8.364985391657543\n","End of episode 331, totel reward is: -63.30966670209483\n","End of episode 332, totel reward is: -316.6687437530136\n","End of episode 333, totel reward is: -12.369268001559677\n","End of episode 334, totel reward is: -149.51831512063822\n","End of episode 335, totel reward is: -341.4453046026422\n","End of episode 336, totel reward is: -176.6055566861311\n","End of episode 337, totel reward is: -66.34109733421492\n","End of episode 338, totel reward is: -51.961224184329026\n","End of episode 339, totel reward is: -46.927048419796\n","End of episode 340, totel reward is: -41.437891645442505\n","End of episode 341, totel reward is: -33.55061248924678\n","End of episode 342, totel reward is: -47.35740456155976\n","End of episode 343, totel reward is: -21.62324407248135\n","End of episode 344, totel reward is: -51.85036777748387\n","End of episode 345, totel reward is: -43.05293526220224\n","End of episode 346, totel reward is: -28.985734253372488\n","End of episode 347, totel reward is: -84.5714679734287\n","End of episode 348, totel reward is: -60.477495184030545\n","End of episode 349, totel reward is: -28.356698145240276\n","End of episode 350, totel reward is: -24.62893985187768\n","End of episode 351, totel reward is: -53.25772353173005\n","End of episode 352, totel reward is: -8.686307776680303\n","End of episode 353, totel reward is: -21.89895404694141\n","End of episode 354, totel reward is: -5.5176600648478065\n","End of episode 355, totel reward is: -31.298749660696963\n","End of episode 356, totel reward is: -15.513886167269789\n","End of episode 357, totel reward is: -38.82885306712092\n","End of episode 358, totel reward is: -4.680026716228541\n","End of episode 359, totel reward is: -6.079905819155573\n","End of episode 360, totel reward is: -13.76809526953853\n","End of episode 361, totel reward is: -25.213282134704023\n","End of episode 362, totel reward is: -10.298204148687143\n","End of episode 363, totel reward is: -45.23710619897785\n","End of episode 364, totel reward is: -17.14278579717618\n","End of episode 365, totel reward is: -22.471490161807814\n","End of episode 366, totel reward is: -40.018603919810396\n","End of episode 367, totel reward is: -15.094583400930807\n","End of episode 368, totel reward is: -12.836027643145949\n","End of episode 369, totel reward is: -2.289661538797542\n","End of episode 370, totel reward is: -5.916919255403719\n","End of episode 371, totel reward is: -17.537681086539997\n","End of episode 372, totel reward is: -172.75831936231316\n","End of episode 373, totel reward is: -23.11981030331038\n","End of episode 374, totel reward is: -22.935775806588346\n","End of episode 375, totel reward is: -2.6454370308398167\n","End of episode 376, totel reward is: -12.856237784274427\n","End of episode 377, totel reward is: -10.063707150290545\n","End of episode 378, totel reward is: -35.30093656088831\n","End of episode 379, totel reward is: -4.0861697147140355\n","End of episode 380, totel reward is: -4.869818746581363\n","End of episode 381, totel reward is: -9.094012695139238\n","End of episode 382, totel reward is: -11.795219014698091\n","End of episode 383, totel reward is: -32.47453656748724\n","End of episode 384, totel reward is: -683.8964427499443\n","End of episode 385, totel reward is: -4.683744328102075\n","End of episode 386, totel reward is: -18.02027391036039\n","End of episode 387, totel reward is: -14.49318069042099\n","End of episode 388, totel reward is: -30.419123969179115\n","End of episode 389, totel reward is: -16.411472701704973\n","End of episode 390, totel reward is: -12.66167999469832\n","End of episode 391, totel reward is: -51.10209709721078\n","End of episode 392, totel reward is: -22.53542466735616\n","End of episode 393, totel reward is: -10.622477025327054\n","End of episode 394, totel reward is: -21.603366037134574\n","End of episode 395, totel reward is: -17.546598285127526\n","End of episode 396, totel reward is: -24.59126263247752\n","End of episode 397, totel reward is: -18.894122035407868\n","End of episode 398, totel reward is: -23.48426434979055\n","End of episode 399, totel reward is: -17.586239157494752\n","End of episode 400, totel reward is: -19.517702695398103\n","End of episode 401, totel reward is: -1.8284552469642956\n","End of episode 402, totel reward is: -32.851761048838746\n","End of episode 403, totel reward is: -19.217534867984888\n","End of episode 404, totel reward is: -12.290515680516092\n","End of episode 405, totel reward is: -16.23116580730015\n","End of episode 406, totel reward is: -8.86126277419222\n","End of episode 407, totel reward is: -8.825173543417979\n","End of episode 408, totel reward is: -11.783571231887652\n","End of episode 409, totel reward is: -6.268421399809152\n","End of episode 410, totel reward is: -25.04751334345015\n","End of episode 411, totel reward is: -16.183209682022945\n","End of episode 412, totel reward is: -5.811436409479041\n","End of episode 413, totel reward is: -1.5210944749705952\n","End of episode 414, totel reward is: -15.928477206914302\n","End of episode 415, totel reward is: -17.93849485721391\n","End of episode 416, totel reward is: -9.251363080474354\n","End of episode 417, totel reward is: -26.417590707555483\n","End of episode 418, totel reward is: -9.624512216546586\n","End of episode 419, totel reward is: -7.326511673180985\n","End of episode 420, totel reward is: -20.9459966143507\n","End of episode 421, totel reward is: -11.508667875697931\n","End of episode 422, totel reward is: -9.754662515341696\n","End of episode 423, totel reward is: -3.964846668090224\n","End of episode 424, totel reward is: -7.584429536216095\n","End of episode 425, totel reward is: -4.285905097734661\n","End of episode 426, totel reward is: -19.402955440552503\n","End of episode 427, totel reward is: -6.5197933149443275\n","End of episode 428, totel reward is: -5.432123651589129\n","End of episode 429, totel reward is: -12.787837084592597\n","End of episode 430, totel reward is: -10.94547619596337\n","End of episode 431, totel reward is: -8.413730936773668\n","End of episode 432, totel reward is: -2.783878404225647\n","End of episode 433, totel reward is: -4.485465880908153\n","End of episode 434, totel reward is: -13.441680172005034\n","End of episode 435, totel reward is: -16.82458560295498\n","End of episode 436, totel reward is: -8.891421237288814\n","End of episode 437, totel reward is: -47.14136346347152\n","End of episode 438, totel reward is: -7.65147376187361\n","End of episode 439, totel reward is: -10.287182109933417\n","End of episode 440, totel reward is: -5.193499591455295\n","End of episode 441, totel reward is: -2.18458307349102\n","End of episode 442, totel reward is: -11.157353028965595\n","End of episode 443, totel reward is: -6.116135239293299\n","End of episode 444, totel reward is: -14.465213311664776\n","End of episode 445, totel reward is: -5.671610009026895\n","End of episode 446, totel reward is: -3.3209127061572516\n","End of episode 447, totel reward is: -18.346707368192178\n","End of episode 448, totel reward is: -5.428145012029685\n","End of episode 449, totel reward is: -7.337636391891167\n","End of episode 450, totel reward is: -3.585634608494255\n","End of episode 451, totel reward is: -22.540685701186643\n","End of episode 452, totel reward is: -14.482996381783712\n","End of episode 453, totel reward is: -14.223134220858892\n","End of episode 454, totel reward is: -8.475730266902382\n","End of episode 455, totel reward is: -11.890909282777438\n","End of episode 456, totel reward is: -9.885743556195138\n","End of episode 457, totel reward is: -1.6593491412725085\n","End of episode 458, totel reward is: -9.010375463899429\n","End of episode 459, totel reward is: -9.951203120929309\n","End of episode 460, totel reward is: -7.514803688863822\n","End of episode 461, totel reward is: -6.767032005180006\n","End of episode 462, totel reward is: -8.04627123121264\n","End of episode 463, totel reward is: -321.7880519209924\n","End of episode 464, totel reward is: -11.794511094091687\n","End of episode 465, totel reward is: -3.1086879341929077\n","End of episode 466, totel reward is: -7.891265449404501\n","End of episode 467, totel reward is: -6.169714467915424\n","End of episode 468, totel reward is: -9.38825500881867\n","End of episode 469, totel reward is: -13.859879462456862\n","End of episode 470, totel reward is: -1.7247736277686776\n","End of episode 471, totel reward is: -11.379048568522407\n","End of episode 472, totel reward is: -18.25959865763643\n","End of episode 473, totel reward is: -17.453200720860735\n","End of episode 474, totel reward is: -14.088232742246934\n","End of episode 475, totel reward is: -7.80603894824472\n","End of episode 476, totel reward is: -22.590630207152422\n","End of episode 477, totel reward is: -2.367911443050493\n","End of episode 478, totel reward is: -13.991216300520472\n","End of episode 479, totel reward is: -11.3155761973903\n","End of episode 480, totel reward is: -3.9889968213768476\n","End of episode 481, totel reward is: -5.80824643415216\n","End of episode 482, totel reward is: -28.675799190057603\n","End of episode 483, totel reward is: -23.25503515042538\n","End of episode 484, totel reward is: -23.636411707629986\n","End of episode 485, totel reward is: -8.301636717884769\n","End of episode 486, totel reward is: -2.9300933936063043\n","End of episode 487, totel reward is: -4.444495531344305\n","End of episode 488, totel reward is: -3.3011693080431974\n","End of episode 489, totel reward is: -5.988244880066806\n","End of episode 490, totel reward is: -3.567888119515012\n","End of episode 491, totel reward is: -9.572688413905809\n","End of episode 492, totel reward is: -16.577468781567397\n","End of episode 493, totel reward is: -4.846785627528877\n","End of episode 494, totel reward is: -3.531491398590476\n","End of episode 495, totel reward is: -5.905346184001403\n","End of episode 496, totel reward is: -8.34736007663502\n","End of episode 497, totel reward is: -10.834460240979757\n","End of episode 498, totel reward is: -10.402273637824633\n","End of episode 499, totel reward is: -6.991076171131742\n","End of episode 500, totel reward is: -5.525413021220487\n","End of episode 501, totel reward is: -8.634628196761444\n","End of episode 502, totel reward is: -7.009812953236925\n","End of episode 503, totel reward is: -10.785919918702428\n","End of episode 504, totel reward is: -10.125164904108209\n","End of episode 505, totel reward is: -6.80811987773898\n","End of episode 506, totel reward is: -10.45940033091525\n","End of episode 507, totel reward is: -6.80121453638148\n","End of episode 508, totel reward is: -11.946310405452872\n","End of episode 509, totel reward is: -34.842017439931745\n","End of episode 510, totel reward is: -7.784319323598866\n","End of episode 511, totel reward is: -1.7198171359566228\n","End of episode 512, totel reward is: -4.6566256739820355\n","End of episode 513, totel reward is: -2.8137743424902926\n","End of episode 514, totel reward is: -6.382065737112992\n","End of episode 515, totel reward is: -4.0943178607775925\n","End of episode 516, totel reward is: -7.154095274683247\n","End of episode 517, totel reward is: -5.674857821902393\n","End of episode 518, totel reward is: -66.2992453460857\n","End of episode 519, totel reward is: -5.497781367473764\n","End of episode 520, totel reward is: -5.449278074221111\n","End of episode 521, totel reward is: -3.2908507830893603\n","End of episode 522, totel reward is: -10.746751815348532\n","End of episode 523, totel reward is: -2.937772852122787\n","End of episode 524, totel reward is: -3.3996060144498412\n","End of episode 525, totel reward is: -15.433479955863662\n","End of episode 526, totel reward is: -6.417767575079228\n","End of episode 527, totel reward is: -3.4449204122255477\n","End of episode 528, totel reward is: -6.776866282527059\n","End of episode 529, totel reward is: -4.572197377497108\n","End of episode 530, totel reward is: -10.300885697498396\n","End of episode 531, totel reward is: -6.841330907395539\n","End of episode 532, totel reward is: -2.8576852901814123\n","End of episode 533, totel reward is: -10.464154337585592\n","End of episode 534, totel reward is: -2.4522306479418443\n","End of episode 535, totel reward is: -3.342605007265223\n","End of episode 536, totel reward is: -8.935956480741826\n","End of episode 537, totel reward is: -3.648214144729426\n","End of episode 538, totel reward is: -1.8380214200421272\n","End of episode 539, totel reward is: -6.018287677908912\n","End of episode 540, totel reward is: -8.114935421704075\n","End of episode 541, totel reward is: -9.37537569032202\n","End of episode 542, totel reward is: -5.626127740382541\n","End of episode 543, totel reward is: -3.4629984900471547\n","End of episode 544, totel reward is: -5.330373918853157\n","End of episode 545, totel reward is: -6.3720593931180725\n","End of episode 546, totel reward is: -5.8923348083279565\n","End of episode 547, totel reward is: -4.492963662676487\n","End of episode 548, totel reward is: -3.157548619635473\n","End of episode 549, totel reward is: -3.3137714775145963\n","End of episode 550, totel reward is: -6.444969863209513\n","End of episode 551, totel reward is: -3.1628060287925974\n","End of episode 552, totel reward is: -7.5533992375567385\n","End of episode 553, totel reward is: -6.410143733950729\n","End of episode 554, totel reward is: -3.219597391592076\n","End of episode 555, totel reward is: -4.345302800104741\n","End of episode 556, totel reward is: -8.793666143455512\n","End of episode 557, totel reward is: -2.569885224215266\n","End of episode 558, totel reward is: -1.0812108613487466\n","End of episode 559, totel reward is: -3.1895216790172385\n","End of episode 560, totel reward is: -4.016520070911848\n","End of episode 561, totel reward is: -3.8119633915582334\n","End of episode 562, totel reward is: -10.012980064687842\n","End of episode 563, totel reward is: -1.9463394000894452\n","End of episode 564, totel reward is: -31.120380226184032\n","End of episode 565, totel reward is: -3.3010072163723816\n","End of episode 566, totel reward is: -6.440059902168792\n","End of episode 567, totel reward is: -2.037383901286361\n","End of episode 568, totel reward is: -6.575282435870733\n","End of episode 569, totel reward is: -2.255295063525739\n","End of episode 570, totel reward is: -4.325067380452092\n","End of episode 571, totel reward is: -5.94458558221618\n","End of episode 572, totel reward is: -5.028607187945515\n","End of episode 573, totel reward is: -2.6802307554500335\n","End of episode 574, totel reward is: -3.1433742211836306\n","End of episode 575, totel reward is: -10.028497690658197\n","End of episode 576, totel reward is: -0.4877603124937916\n","End of episode 577, totel reward is: -4.233519993328845\n","End of episode 578, totel reward is: -11.135686875125586\n","End of episode 579, totel reward is: -3.5793438082632933\n","End of episode 580, totel reward is: -7.823358386129067\n","End of episode 581, totel reward is: -10.695519094097758\n","End of episode 582, totel reward is: -9.662234806873128\n","End of episode 583, totel reward is: -3.316470802408538\n","End of episode 584, totel reward is: -3.669212054663047\n","End of episode 585, totel reward is: -2.507579172221005\n","End of episode 586, totel reward is: -2.1576965201998286\n","End of episode 587, totel reward is: -1.3687244081114043\n","End of episode 588, totel reward is: -4.337780087696789\n","End of episode 589, totel reward is: -10.375292260444455\n","End of episode 590, totel reward is: -4.135611220208644\n","End of episode 591, totel reward is: -3.1049194397549598\n","End of episode 592, totel reward is: -4.3595306694123135\n","End of episode 593, totel reward is: -9.155921571770081\n","End of episode 594, totel reward is: -6.822069663577201\n","End of episode 595, totel reward is: -0.5957608503743038\n","End of episode 596, totel reward is: -6.299549564829366\n","End of episode 597, totel reward is: -1.9101745318983674\n","End of episode 598, totel reward is: -7.7237158978232925\n","End of episode 599, totel reward is: -2.370770197555164\n","End of episode 600, totel reward is: -6.396462437075056\n","End of episode 601, totel reward is: -3.752115767682821\n","End of episode 602, totel reward is: -16.804198521938822\n","End of episode 603, totel reward is: -7.166897667467381\n","End of episode 604, totel reward is: -1.4810874852786684\n","End of episode 605, totel reward is: -1.09684823357104\n","End of episode 606, totel reward is: -4.034215222349346\n","End of episode 607, totel reward is: -4.668599319562505\n","End of episode 608, totel reward is: -3.1398516450934313\n","End of episode 609, totel reward is: -3.0447487718837722\n","End of episode 610, totel reward is: -3.979760541872343\n","End of episode 611, totel reward is: -1.8089944094195844\n","End of episode 612, totel reward is: -2.493816699580402\n","End of episode 613, totel reward is: -3.4316423777199945\n","End of episode 614, totel reward is: -2.9443315913404335\n","End of episode 615, totel reward is: -1.4968559030593416\n","End of episode 616, totel reward is: -7.443357941064592\n","End of episode 617, totel reward is: -7.799538574386905\n","End of episode 618, totel reward is: -3.498962558912953\n","End of episode 619, totel reward is: -4.92082407224803\n","End of episode 620, totel reward is: -3.530028410636897\n","End of episode 621, totel reward is: -1.9729448930151223\n","End of episode 622, totel reward is: -2.0397927413230925\n","End of episode 623, totel reward is: -3.004271330080763\n","End of episode 624, totel reward is: -6.070790096520393\n","End of episode 625, totel reward is: -3.871578390700528\n","End of episode 626, totel reward is: -5.840458206681414\n","End of episode 627, totel reward is: -5.166718821031833\n","End of episode 628, totel reward is: -8.449840187415994\n","End of episode 629, totel reward is: -3.119647667141313\n","End of episode 630, totel reward is: -2.9071148176270385\n","End of episode 631, totel reward is: -15.950190447855514\n","End of episode 632, totel reward is: -5.932327869117136\n","End of episode 633, totel reward is: -1.317882481036166\n","End of episode 634, totel reward is: -1.69840374909046\n","End of episode 635, totel reward is: -5.593668204121482\n","End of episode 636, totel reward is: -2.1134354814757956\n","End of episode 637, totel reward is: -1.5803837950020028\n","End of episode 638, totel reward is: -1.6268116191837503\n","End of episode 639, totel reward is: -2.6688891549321085\n","End of episode 640, totel reward is: -6.148289901032143\n","End of episode 641, totel reward is: -9.171553786110445\n","End of episode 642, totel reward is: -3.6379321509367175\n","End of episode 643, totel reward is: -1.487433627408218\n","End of episode 644, totel reward is: -5.964608885034407\n","End of episode 645, totel reward is: -2.56579184986575\n","End of episode 646, totel reward is: -1529.16568552475\n","End of episode 647, totel reward is: -8.073627613534748\n","End of episode 648, totel reward is: -3.248717447247458\n","End of episode 649, totel reward is: -10.360277974543832\n","End of episode 650, totel reward is: -2.8521825684211537\n","End of episode 651, totel reward is: -3.2177366018990767\n","End of episode 652, totel reward is: -20.129838892425553\n","End of episode 653, totel reward is: -5.790715731534614\n","End of episode 654, totel reward is: -3.8488742420223283\n","End of episode 655, totel reward is: -3.191220060038408\n","End of episode 656, totel reward is: -2.384064890813897\n","End of episode 657, totel reward is: -2.2245797064923996\n","End of episode 658, totel reward is: -33.75749955489355\n","End of episode 659, totel reward is: -4.961357242187404\n","End of episode 660, totel reward is: -4.306683385373022\n","End of episode 661, totel reward is: -6.168161490986881\n","End of episode 662, totel reward is: -0.9905959008469941\n","End of episode 663, totel reward is: -2.2867960105350926\n","End of episode 664, totel reward is: -1.2691918710590564\n","End of episode 665, totel reward is: -2.3681955814655082\n","End of episode 666, totel reward is: -3.645398821823301\n","End of episode 667, totel reward is: -5.980892483471379\n","End of episode 668, totel reward is: -2.8718277741252622\n","End of episode 669, totel reward is: -1.5361042290228266\n","End of episode 670, totel reward is: -3.4771793643970197\n","End of episode 671, totel reward is: -1.1281810363002527\n","End of episode 672, totel reward is: -42.46812176627149\n","End of episode 673, totel reward is: -4.289164582635279\n","End of episode 674, totel reward is: -11.681121121408728\n","End of episode 675, totel reward is: -2.1693288447715626\n","End of episode 676, totel reward is: -0.7642297754220495\n","End of episode 677, totel reward is: -66.17271199739355\n","End of episode 678, totel reward is: -3.1220092076040693\n","End of episode 679, totel reward is: -18.398052344661764\n","End of episode 680, totel reward is: -0.7967493085661194\n","End of episode 681, totel reward is: -4.607761399996593\n","End of episode 682, totel reward is: -1.8735142107807399\n","End of episode 683, totel reward is: -34.04958790234529\n","End of episode 684, totel reward is: -13.232558303437447\n","End of episode 685, totel reward is: -0.7994739969286401\n","End of episode 686, totel reward is: -3.9254242050958346\n","End of episode 687, totel reward is: -5.730762167146501\n","End of episode 688, totel reward is: -3.262638144068154\n","End of episode 689, totel reward is: -8.63770499895163\n","End of episode 690, totel reward is: -2.930667859656863\n","End of episode 691, totel reward is: -1.1473666897007124\n","End of episode 692, totel reward is: -11.049637741236126\n","End of episode 693, totel reward is: -1.8738086434873806\n","End of episode 694, totel reward is: -1.026435473056756\n","End of episode 695, totel reward is: -3.432693516817095\n","End of episode 696, totel reward is: -5.493539559908523\n","End of episode 697, totel reward is: -4.68702891405156\n","End of episode 698, totel reward is: -3.1713012105430387\n","End of episode 699, totel reward is: -5.067964057144424\n","End of episode 700, totel reward is: -2.941518494753412\n","End of episode 701, totel reward is: -0.8474033579043219\n","End of episode 702, totel reward is: -1.2530709042743744\n","End of episode 703, totel reward is: -2.547967113752767\n","End of episode 704, totel reward is: -5.394920211971965\n","End of episode 705, totel reward is: -2.2026583930090355\n","End of episode 706, totel reward is: -2.551828567198439\n","End of episode 707, totel reward is: -10.739774531587493\n","End of episode 708, totel reward is: -6.358764564431116\n","End of episode 709, totel reward is: -1.8510688908539643\n","End of episode 710, totel reward is: -8.505628641213582\n","End of episode 711, totel reward is: -2.9038101612869056\n","End of episode 712, totel reward is: -3.480704793229983\n","End of episode 713, totel reward is: -0.4976510634939001\n","End of episode 714, totel reward is: -2.005318075369825\n","End of episode 715, totel reward is: -23.135723516243786\n","End of episode 716, totel reward is: -17.77488327829035\n","End of episode 717, totel reward is: -1.8626700210811673\n","End of episode 718, totel reward is: -4.258266623348153\n","End of episode 719, totel reward is: -12.952841862894863\n","End of episode 720, totel reward is: -1.6269911888118462\n","End of episode 721, totel reward is: -7.549605519772019\n","End of episode 722, totel reward is: -2.46605710621061\n","End of episode 723, totel reward is: -18.407881975545102\n","End of episode 724, totel reward is: -2.445144046902443\n","End of episode 725, totel reward is: -2.779410506437949\n","End of episode 726, totel reward is: -5.959325491713139\n","End of episode 727, totel reward is: -6.144512824529058\n","End of episode 728, totel reward is: -5.721836696956048\n","End of episode 729, totel reward is: -2.6166955696106666\n","End of episode 730, totel reward is: -0.40944107252960116\n","End of episode 731, totel reward is: -3.73949345298404\n","End of episode 732, totel reward is: -5.566885815871659\n","End of episode 733, totel reward is: -2.3770879762182284\n","End of episode 734, totel reward is: -1.7422249665846208\n","End of episode 735, totel reward is: -1.0306608247039313\n","End of episode 736, totel reward is: -0.5866393491906791\n","End of episode 737, totel reward is: -3.378877507969558\n","End of episode 738, totel reward is: -1.484561104622668\n","End of episode 739, totel reward is: -1.9935364292600652\n","End of episode 740, totel reward is: -11.393663147884675\n","End of episode 741, totel reward is: -1.584950667351244\n","End of episode 742, totel reward is: -0.6712497141894443\n","End of episode 743, totel reward is: -3.0439103939303727\n","End of episode 744, totel reward is: -1.4275135870241942\n","End of episode 745, totel reward is: -3.166294107070205\n","End of episode 746, totel reward is: -3.9456035347663017\n","End of episode 747, totel reward is: -3.4816858819909244\n","End of episode 748, totel reward is: -2.7000301671568714\n","End of episode 749, totel reward is: -761.1460346935486\n","End of episode 750, totel reward is: -3.7027652554351516\n","End of episode 751, totel reward is: -52.11006425083654\n","End of episode 752, totel reward is: -4.649612980061139\n","End of episode 753, totel reward is: -4.822981585646068\n","End of episode 754, totel reward is: -2.1775350069103685\n","End of episode 755, totel reward is: -5.0555297816608\n","End of episode 756, totel reward is: -12.610559151359016\n","End of episode 757, totel reward is: -3.7857970611372096\n","End of episode 758, totel reward is: -11.76795346729943\n","End of episode 759, totel reward is: -2.079976217515501\n","End of episode 760, totel reward is: -3.30639951361738\n","End of episode 761, totel reward is: -5.201234799060617\n","End of episode 762, totel reward is: -3.1302665238952807\n","End of episode 763, totel reward is: -7.715956880880383\n","End of episode 764, totel reward is: -3.8142954426474747\n","End of episode 765, totel reward is: -12.111622619468854\n","End of episode 766, totel reward is: -4.761335586598699\n","End of episode 767, totel reward is: -46.203624395065034\n","End of episode 768, totel reward is: -11.605963335021123\n","End of episode 769, totel reward is: -6.083901568271905\n","End of episode 770, totel reward is: -2.5871586604819408\n","End of episode 771, totel reward is: -2.544584531070809\n","End of episode 772, totel reward is: -2.6638460864667994\n","End of episode 773, totel reward is: -8.920669793196994\n","End of episode 774, totel reward is: -17.080173399295894\n","End of episode 775, totel reward is: -2.979562539929055\n","End of episode 776, totel reward is: -2.116821190167986\n","End of episode 777, totel reward is: -17.63395765539827\n","End of episode 778, totel reward is: -1.4044697779124105\n","End of episode 779, totel reward is: -7.697515560504601\n","End of episode 780, totel reward is: -9.0107501493314\n","End of episode 781, totel reward is: -522.2005722023264\n","End of episode 782, totel reward is: -5.586496574822145\n","End of episode 783, totel reward is: -4.169742510611644\n","End of episode 784, totel reward is: -7.5470429879762415\n","End of episode 785, totel reward is: -3.7338915422364343\n","End of episode 786, totel reward is: -8.216816335638665\n","End of episode 787, totel reward is: -4.965424920073303\n","End of episode 788, totel reward is: -2.3672876131828953\n","End of episode 789, totel reward is: -4.144688839098431\n","End of episode 790, totel reward is: -1.0952937203136028\n","End of episode 791, totel reward is: -1.9622236234870094\n","End of episode 792, totel reward is: -1.9508939825666343\n","End of episode 793, totel reward is: -423.94463275880605\n","End of episode 794, totel reward is: -149.49990585990872\n","End of episode 795, totel reward is: -2.290100948732875\n","End of episode 796, totel reward is: -4.855869675716724\n","End of episode 797, totel reward is: -4.8781733991394844\n","End of episode 798, totel reward is: -2.0272541996716256\n","End of episode 799, totel reward is: -2.0190730899198317\n","End of episode 800, totel reward is: -27.95513469925286\n","End of episode 801, totel reward is: -10.869959508874642\n","End of episode 802, totel reward is: -1.6542498216537864\n","model saved to models/2024-05-06_16-52-42/q_network_ep_0802.pth\n","\n","End of episode 803, totel reward is: -3.107675607132609\n","model saved to models/2024-05-06_16-52-43/q_network_ep_0803.pth\n","\n","End of episode 804, totel reward is: -1.8654691815610869\n","model saved to models/2024-05-06_16-52-44/q_network_ep_0804.pth\n","\n","End of episode 805, totel reward is: -83.2950536693363\n","End of episode 806, totel reward is: -3.982406068851195\n","model saved to models/2024-05-06_16-52-46/q_network_ep_0806.pth\n","\n","End of episode 807, totel reward is: -3.6994602015092695\n","model saved to models/2024-05-06_16-52-47/q_network_ep_0807.pth\n","\n","End of episode 808, totel reward is: -5.393682678905393\n","End of episode 809, totel reward is: -2.2190781611990644\n","model saved to models/2024-05-06_16-52-49/q_network_ep_0809.pth\n","\n","End of episode 810, totel reward is: -523.4255748296162\n","End of episode 811, totel reward is: -3.760393070054552\n","model saved to models/2024-05-06_16-52-52/q_network_ep_0811.pth\n","\n","End of episode 812, totel reward is: -4.686995633559493\n","model saved to models/2024-05-06_16-52-53/q_network_ep_0812.pth\n","\n","End of episode 813, totel reward is: -4.836100714109952\n","model saved to models/2024-05-06_16-52-54/q_network_ep_0813.pth\n","\n","End of episode 814, totel reward is: -1.4965585969074344\n","model saved to models/2024-05-06_16-52-55/q_network_ep_0814.pth\n","\n","End of episode 815, totel reward is: -15.717901216161486\n","End of episode 816, totel reward is: -1.3331243284322802\n","model saved to models/2024-05-06_16-52-58/q_network_ep_0816.pth\n","\n","End of episode 817, totel reward is: -0.898648837320709\n","model saved to models/2024-05-06_16-52-59/q_network_ep_0817.pth\n","\n","End of episode 818, totel reward is: -4.340994598274248\n","model saved to models/2024-05-06_16-53-00/q_network_ep_0818.pth\n","\n","End of episode 819, totel reward is: -11.244307310454076\n","End of episode 820, totel reward is: -1.9733330078670988\n","model saved to models/2024-05-06_16-53-02/q_network_ep_0820.pth\n","\n","End of episode 821, totel reward is: -14.653370564555791\n","End of episode 822, totel reward is: -3.179165871027361\n","model saved to models/2024-05-06_16-53-05/q_network_ep_0822.pth\n","\n","End of episode 823, totel reward is: -4.182913391661125\n","model saved to models/2024-05-06_16-53-06/q_network_ep_0823.pth\n","\n","End of episode 824, totel reward is: -8.88217257036468\n","End of episode 825, totel reward is: -3.0095780366341147\n","model saved to models/2024-05-06_16-53-08/q_network_ep_0825.pth\n","\n","End of episode 826, totel reward is: -19.239103647281464\n","End of episode 827, totel reward is: -2.7444173966789585\n","model saved to models/2024-05-06_16-53-10/q_network_ep_0827.pth\n","\n","End of episode 828, totel reward is: -1.78049628377921\n","model saved to models/2024-05-06_16-53-11/q_network_ep_0828.pth\n","\n","End of episode 829, totel reward is: -2.665113985252298\n","model saved to models/2024-05-06_16-53-12/q_network_ep_0829.pth\n","\n","End of episode 830, totel reward is: -0.7388441944864369\n","model saved to models/2024-05-06_16-53-13/q_network_ep_0830.pth\n","\n","End of episode 831, totel reward is: -0.7300160120146977\n","model saved to models/2024-05-06_16-53-14/q_network_ep_0831.pth\n","\n","End of episode 832, totel reward is: -3.974726282562027\n","model saved to models/2024-05-06_16-53-16/q_network_ep_0832.pth\n","\n","End of episode 833, totel reward is: -1.1538201436280222\n","model saved to models/2024-05-06_16-53-17/q_network_ep_0833.pth\n","\n","End of episode 834, totel reward is: -825.7699472983235\n","End of episode 835, totel reward is: -1.7024505402172185\n","model saved to models/2024-05-06_16-53-19/q_network_ep_0835.pth\n","\n","End of episode 836, totel reward is: -2.5167793882908214\n","model saved to models/2024-05-06_16-53-20/q_network_ep_0836.pth\n","\n","End of episode 837, totel reward is: -2.066299651876271\n","model saved to models/2024-05-06_16-53-21/q_network_ep_0837.pth\n","\n","End of episode 838, totel reward is: -5.531812189852682\n","End of episode 839, totel reward is: -2.2791558988642304\n","model saved to models/2024-05-06_16-53-24/q_network_ep_0839.pth\n","\n","End of episode 840, totel reward is: -2.4770128934108944\n","model saved to models/2024-05-06_16-53-25/q_network_ep_0840.pth\n","\n","End of episode 841, totel reward is: -2.315521527898244\n","model saved to models/2024-05-06_16-53-26/q_network_ep_0841.pth\n","\n","End of episode 842, totel reward is: -4.278965636439411\n","model saved to models/2024-05-06_16-53-27/q_network_ep_0842.pth\n","\n","End of episode 843, totel reward is: -5.314734613543512\n","End of episode 844, totel reward is: -199.42795498820956\n","End of episode 845, totel reward is: -2.6691779114691925\n","model saved to models/2024-05-06_16-53-31/q_network_ep_0845.pth\n","\n","End of episode 846, totel reward is: -2.2443914563360146\n","model saved to models/2024-05-06_16-53-32/q_network_ep_0846.pth\n","\n","End of episode 847, totel reward is: -2.4499706197267317\n","model saved to models/2024-05-06_16-53-33/q_network_ep_0847.pth\n","\n","End of episode 848, totel reward is: -4.263442988291982\n","model saved to models/2024-05-06_16-53-34/q_network_ep_0848.pth\n","\n","End of episode 849, totel reward is: -1.7766951601165548\n","model saved to models/2024-05-06_16-53-35/q_network_ep_0849.pth\n","\n","End of episode 850, totel reward is: -1.734457086914217\n","model saved to models/2024-05-06_16-53-36/q_network_ep_0850.pth\n","\n","End of episode 851, totel reward is: -2.150484901536706\n","model saved to models/2024-05-06_16-53-37/q_network_ep_0851.pth\n","\n","End of episode 852, totel reward is: -2.144909278598003\n","model saved to models/2024-05-06_16-53-38/q_network_ep_0852.pth\n","\n","End of episode 853, totel reward is: -3.08101038493707\n","model saved to models/2024-05-06_16-53-39/q_network_ep_0853.pth\n","\n","End of episode 854, totel reward is: -3.368938225718882\n","model saved to models/2024-05-06_16-53-41/q_network_ep_0854.pth\n","\n","End of episode 855, totel reward is: -2.9052583525885582\n","model saved to models/2024-05-06_16-53-42/q_network_ep_0855.pth\n","\n","End of episode 856, totel reward is: -15.283726857268563\n","End of episode 857, totel reward is: -1.0770180954497415\n","model saved to models/2024-05-06_16-53-44/q_network_ep_0857.pth\n","\n","End of episode 858, totel reward is: -0.5017667399838525\n","model saved to models/2024-05-06_16-53-45/q_network_ep_0858.pth\n","\n","End of episode 859, totel reward is: -4.90265969030249\n","model saved to models/2024-05-06_16-53-46/q_network_ep_0859.pth\n","\n","End of episode 860, totel reward is: -5.734102990777899\n","End of episode 861, totel reward is: -3.6401660467033814\n","model saved to models/2024-05-06_16-53-49/q_network_ep_0861.pth\n","\n","End of episode 862, totel reward is: -1.390401996309846\n","model saved to models/2024-05-06_16-53-50/q_network_ep_0862.pth\n","\n","End of episode 863, totel reward is: -2.569034094434124\n","model saved to models/2024-05-06_16-53-51/q_network_ep_0863.pth\n","\n","End of episode 864, totel reward is: -2.3544486377024954\n","model saved to models/2024-05-06_16-53-52/q_network_ep_0864.pth\n","\n","End of episode 865, totel reward is: -0.5695467386958323\n","model saved to models/2024-05-06_16-53-53/q_network_ep_0865.pth\n","\n","End of episode 866, totel reward is: -1.914367575299266\n","model saved to models/2024-05-06_16-53-55/q_network_ep_0866.pth\n","\n","End of episode 867, totel reward is: -4.270764998888947\n","model saved to models/2024-05-06_16-53-56/q_network_ep_0867.pth\n","\n","End of episode 868, totel reward is: -4.731666566007313\n","model saved to models/2024-05-06_16-53-57/q_network_ep_0868.pth\n","\n","End of episode 869, totel reward is: -1.4246573650585708\n","model saved to models/2024-05-06_16-53-58/q_network_ep_0869.pth\n","\n","End of episode 870, totel reward is: -1.0205843974317568\n","model saved to models/2024-05-06_16-53-59/q_network_ep_0870.pth\n","\n","End of episode 871, totel reward is: -4.450385702643777\n","model saved to models/2024-05-06_16-54-00/q_network_ep_0871.pth\n","\n","End of episode 872, totel reward is: -9.37331406776525\n","End of episode 873, totel reward is: -1.4819885851318302\n","model saved to models/2024-05-06_16-54-02/q_network_ep_0873.pth\n","\n","End of episode 874, totel reward is: -0.6724149942484079\n","model saved to models/2024-05-06_16-54-03/q_network_ep_0874.pth\n","\n","End of episode 875, totel reward is: -2.9518838992894154\n","model saved to models/2024-05-06_16-54-04/q_network_ep_0875.pth\n","\n","End of episode 876, totel reward is: -2.5415882556592817\n","model saved to models/2024-05-06_16-54-06/q_network_ep_0876.pth\n","\n","End of episode 877, totel reward is: -1.8007788903174065\n","model saved to models/2024-05-06_16-54-07/q_network_ep_0877.pth\n","\n","End of episode 878, totel reward is: -3.3722691629521395\n","model saved to models/2024-05-06_16-54-08/q_network_ep_0878.pth\n","\n","End of episode 879, totel reward is: -4.858031639983706\n","model saved to models/2024-05-06_16-54-09/q_network_ep_0879.pth\n","\n","End of episode 880, totel reward is: -6.153981253047741\n","End of episode 881, totel reward is: -3.935407661225399\n","model saved to models/2024-05-06_16-54-12/q_network_ep_0881.pth\n","\n","End of episode 882, totel reward is: -8.318996686042611\n","End of episode 883, totel reward is: -1.8130102846697906\n","model saved to models/2024-05-06_16-54-14/q_network_ep_0883.pth\n","\n","End of episode 884, totel reward is: -3.591232525448492\n","model saved to models/2024-05-06_16-54-15/q_network_ep_0884.pth\n","\n","End of episode 885, totel reward is: -2.518640621032619\n","model saved to models/2024-05-06_16-54-16/q_network_ep_0885.pth\n","\n","End of episode 886, totel reward is: -6.586962972942405\n","End of episode 887, totel reward is: -1.493866065984228\n","model saved to models/2024-05-06_16-54-18/q_network_ep_0887.pth\n","\n","End of episode 888, totel reward is: -1.2913231029093393\n","model saved to models/2024-05-06_16-54-20/q_network_ep_0888.pth\n","\n","End of episode 889, totel reward is: -0.804192945826328\n","model saved to models/2024-05-06_16-54-21/q_network_ep_0889.pth\n","\n","End of episode 890, totel reward is: -1.9151900497413739\n","model saved to models/2024-05-06_16-54-22/q_network_ep_0890.pth\n","\n","End of episode 891, totel reward is: -1.578412259893636\n","model saved to models/2024-05-06_16-54-23/q_network_ep_0891.pth\n","\n","End of episode 892, totel reward is: -0.5531986676987665\n","model saved to models/2024-05-06_16-54-24/q_network_ep_0892.pth\n","\n","End of episode 893, totel reward is: -2.4873914349233424\n","model saved to models/2024-05-06_16-54-25/q_network_ep_0893.pth\n","\n","End of episode 894, totel reward is: -0.46881336277371854\n","model saved to models/2024-05-06_16-54-26/q_network_ep_0894.pth\n","\n","End of episode 895, totel reward is: -2.8680505956937004\n","model saved to models/2024-05-06_16-54-27/q_network_ep_0895.pth\n","\n","End of episode 896, totel reward is: -7.075134339098901\n","End of episode 897, totel reward is: -1.8593479416227294\n","model saved to models/2024-05-06_16-54-30/q_network_ep_0897.pth\n","\n","End of episode 898, totel reward is: -2.25184336151145\n","model saved to models/2024-05-06_16-54-31/q_network_ep_0898.pth\n","\n","End of episode 899, totel reward is: -1.511426580662328\n","model saved to models/2024-05-06_16-54-32/q_network_ep_0899.pth\n","\n","End of episode 900, totel reward is: -5.721639675955643\n","End of episode 901, totel reward is: -3.6199371895872527\n","model saved to models/2024-05-06_16-54-34/q_network_ep_0901.pth\n","\n","End of episode 902, totel reward is: -2.0282255296977394\n","model saved to models/2024-05-06_16-54-35/q_network_ep_0902.pth\n","\n","End of episode 903, totel reward is: -2.4677078621150716\n","model saved to models/2024-05-06_16-54-36/q_network_ep_0903.pth\n","\n","End of episode 904, totel reward is: -1.5400282904422105\n","model saved to models/2024-05-06_16-54-38/q_network_ep_0904.pth\n","\n","End of episode 905, totel reward is: -3.6320699189116037\n","model saved to models/2024-05-06_16-54-39/q_network_ep_0905.pth\n","\n","End of episode 906, totel reward is: -6.374064800914278\n","End of episode 907, totel reward is: -0.56188846982477\n","model saved to models/2024-05-06_16-54-41/q_network_ep_0907.pth\n","\n","End of episode 908, totel reward is: -725.1115586488594\n","End of episode 909, totel reward is: -2.564792439265167\n","model saved to models/2024-05-06_16-54-44/q_network_ep_0909.pth\n","\n","End of episode 910, totel reward is: -1.142404902059329\n","model saved to models/2024-05-06_16-54-45/q_network_ep_0910.pth\n","\n","End of episode 911, totel reward is: -3.508922632184441\n","model saved to models/2024-05-06_16-54-46/q_network_ep_0911.pth\n","\n","End of episode 912, totel reward is: -5.752119015747156\n","End of episode 913, totel reward is: -1.743875744170338\n","model saved to models/2024-05-06_16-54-48/q_network_ep_0913.pth\n","\n","End of episode 914, totel reward is: -2.29054497077477\n","model saved to models/2024-05-06_16-54-49/q_network_ep_0914.pth\n","\n","End of episode 915, totel reward is: -1.8127089172528188\n","model saved to models/2024-05-06_16-54-50/q_network_ep_0915.pth\n","\n","End of episode 916, totel reward is: -1.7942652829208028\n","model saved to models/2024-05-06_16-54-51/q_network_ep_0916.pth\n","\n","End of episode 917, totel reward is: -914.3191507589614\n","End of episode 918, totel reward is: -4.1299606256087085\n","model saved to models/2024-05-06_16-54-53/q_network_ep_0918.pth\n","\n","End of episode 919, totel reward is: -11.978132162559469\n","End of episode 920, totel reward is: -2.3471374729007426\n","model saved to models/2024-05-06_16-54-56/q_network_ep_0920.pth\n","\n","End of episode 921, totel reward is: -1.7613719555602625\n","model saved to models/2024-05-06_16-54-57/q_network_ep_0921.pth\n","\n","End of episode 922, totel reward is: -1.192702278854928\n","model saved to models/2024-05-06_16-54-58/q_network_ep_0922.pth\n","\n","End of episode 923, totel reward is: -6.688267251702213\n","End of episode 924, totel reward is: -3.7849144188087043\n","model saved to models/2024-05-06_16-55-00/q_network_ep_0924.pth\n","\n","End of episode 925, totel reward is: -1170.0318948219185\n","End of episode 926, totel reward is: -3.111100616246791\n","model saved to models/2024-05-06_16-55-03/q_network_ep_0926.pth\n","\n","End of episode 927, totel reward is: -4.409102530672426\n","model saved to models/2024-05-06_16-55-04/q_network_ep_0927.pth\n","\n","End of episode 928, totel reward is: -2.651628973011228\n","model saved to models/2024-05-06_16-55-05/q_network_ep_0928.pth\n","\n","End of episode 929, totel reward is: -1.1580618959753304\n","model saved to models/2024-05-06_16-55-06/q_network_ep_0929.pth\n","\n","End of episode 930, totel reward is: -18.077347516040223\n","End of episode 931, totel reward is: -12.11257261525728\n","End of episode 932, totel reward is: -3.0857280686829975\n","model saved to models/2024-05-06_16-55-10/q_network_ep_0932.pth\n","\n","End of episode 933, totel reward is: -1.0480446352705086\n","model saved to models/2024-05-06_16-55-11/q_network_ep_0933.pth\n","\n","End of episode 934, totel reward is: -5.642913288170916\n","End of episode 935, totel reward is: -18.318374450402274\n","End of episode 936, totel reward is: -30.044262230215246\n","End of episode 937, totel reward is: -8.786795545777755\n","End of episode 938, totel reward is: -1.7782843085746296\n","model saved to models/2024-05-06_16-55-16/q_network_ep_0938.pth\n","\n","End of episode 939, totel reward is: -3.9561771630096607\n","model saved to models/2024-05-06_16-55-17/q_network_ep_0939.pth\n","\n","End of episode 940, totel reward is: -5.361512019242176\n","End of episode 941, totel reward is: -1.090313984816878\n","model saved to models/2024-05-06_16-55-19/q_network_ep_0941.pth\n","\n","End of episode 942, totel reward is: -55.503557087392146\n","End of episode 943, totel reward is: -6.186117279601151\n","End of episode 944, totel reward is: -3.174613771916755\n","model saved to models/2024-05-06_16-55-23/q_network_ep_0944.pth\n","\n","End of episode 945, totel reward is: -1.2948989223917742\n","model saved to models/2024-05-06_16-55-24/q_network_ep_0945.pth\n","\n","End of episode 946, totel reward is: -4.847163240876436\n","model saved to models/2024-05-06_16-55-25/q_network_ep_0946.pth\n","\n","End of episode 947, totel reward is: -5.847445037607889\n","End of episode 948, totel reward is: -10.791109247257546\n","End of episode 949, totel reward is: -1.1118992439688236\n","model saved to models/2024-05-06_16-55-28/q_network_ep_0949.pth\n","\n","End of episode 950, totel reward is: -989.5223046709399\n","End of episode 951, totel reward is: -3.997375908585222\n","model saved to models/2024-05-06_16-55-30/q_network_ep_0951.pth\n","\n","End of episode 952, totel reward is: -2.6369282959893567\n","model saved to models/2024-05-06_16-55-32/q_network_ep_0952.pth\n","\n","End of episode 953, totel reward is: -19.052311208332117\n","End of episode 954, totel reward is: -1.8231632266694602\n","model saved to models/2024-05-06_16-55-34/q_network_ep_0954.pth\n","\n","End of episode 955, totel reward is: -1.8278770267682551\n","model saved to models/2024-05-06_16-55-35/q_network_ep_0955.pth\n","\n","End of episode 956, totel reward is: -20.88195195128862\n","End of episode 957, totel reward is: -5.040699968100952\n","End of episode 958, totel reward is: -1.2006256528654453\n","model saved to models/2024-05-06_16-55-38/q_network_ep_0958.pth\n","\n","End of episode 959, totel reward is: -5.5386961364965\n","End of episode 960, totel reward is: -8.666306354402867\n","End of episode 961, totel reward is: -6.590754344451626\n","End of episode 962, totel reward is: -7.072656536363226\n","End of episode 963, totel reward is: -1.2844766818982427\n","model saved to models/2024-05-06_16-55-44/q_network_ep_0963.pth\n","\n","End of episode 964, totel reward is: -2.6362266927485005\n","model saved to models/2024-05-06_16-55-45/q_network_ep_0964.pth\n","\n","End of episode 965, totel reward is: -178.9398422868526\n","End of episode 966, totel reward is: -8.65362273831984\n","End of episode 967, totel reward is: -2.0186957280399196\n","model saved to models/2024-05-06_16-55-49/q_network_ep_0967.pth\n","\n","End of episode 968, totel reward is: -3.3331847204445366\n","model saved to models/2024-05-06_16-55-50/q_network_ep_0968.pth\n","\n","End of episode 969, totel reward is: -1.827261935060884\n","model saved to models/2024-05-06_16-55-51/q_network_ep_0969.pth\n","\n","End of episode 970, totel reward is: -1.6038245982592028\n","model saved to models/2024-05-06_16-55-52/q_network_ep_0970.pth\n","\n","End of episode 971, totel reward is: -3.020523739080291\n","model saved to models/2024-05-06_16-55-53/q_network_ep_0971.pth\n","\n","End of episode 972, totel reward is: -15.018291424200003\n","End of episode 973, totel reward is: -3.095083065752309\n","model saved to models/2024-05-06_16-55-55/q_network_ep_0973.pth\n","\n","End of episode 974, totel reward is: -7.443797853287006\n","End of episode 975, totel reward is: -6.356505193511203\n","End of episode 976, totel reward is: -1.8960384878952383\n","model saved to models/2024-05-06_16-55-59/q_network_ep_0976.pth\n","\n","End of episode 977, totel reward is: -10.746144744734524\n","End of episode 978, totel reward is: -1.1967702506214497\n","model saved to models/2024-05-06_16-56-01/q_network_ep_0978.pth\n","\n","End of episode 979, totel reward is: -7.526859252313255\n","End of episode 980, totel reward is: -3.2103054416462062\n","model saved to models/2024-05-06_16-56-03/q_network_ep_0980.pth\n","\n","End of episode 981, totel reward is: -3.114264144886717\n","model saved to models/2024-05-06_16-56-04/q_network_ep_0981.pth\n","\n","End of episode 982, totel reward is: -33.805626613568684\n","End of episode 983, totel reward is: -3.1570081646470265\n","model saved to models/2024-05-06_16-56-06/q_network_ep_0983.pth\n","\n","End of episode 984, totel reward is: -4.818602939353849\n","model saved to models/2024-05-06_16-56-07/q_network_ep_0984.pth\n","\n","End of episode 985, totel reward is: -261.0648085983923\n","End of episode 986, totel reward is: -5.844002757502743\n","End of episode 987, totel reward is: -6.535945453152067\n","End of episode 988, totel reward is: -8.78033544270187\n","End of episode 989, totel reward is: -2.2294632048810095\n","model saved to models/2024-05-06_16-56-13/q_network_ep_0989.pth\n","\n","End of episode 990, totel reward is: -15.10675171956017\n","End of episode 991, totel reward is: -2.6003742268349948\n","model saved to models/2024-05-06_16-56-15/q_network_ep_0991.pth\n","\n","End of episode 992, totel reward is: -2.2340592407111255\n","model saved to models/2024-05-06_16-56-16/q_network_ep_0992.pth\n","\n","End of episode 993, totel reward is: -1.6657428658730085\n","model saved to models/2024-05-06_16-56-17/q_network_ep_0993.pth\n","\n","End of episode 994, totel reward is: -1.246627862601072\n","model saved to models/2024-05-06_16-56-18/q_network_ep_0994.pth\n","\n","End of episode 995, totel reward is: -8.553930371682942\n","End of episode 996, totel reward is: -1.5728043750814307\n","model saved to models/2024-05-06_16-56-21/q_network_ep_0996.pth\n","\n","End of episode 997, totel reward is: -0.5866305069329187\n","model saved to models/2024-05-06_16-56-22/q_network_ep_0997.pth\n","\n","End of episode 998, totel reward is: -2.276524873648419\n","model saved to models/2024-05-06_16-56-24/q_network_ep_0998.pth\n","\n","End of episode 999, totel reward is: -3.1366660723285817\n","model saved to models/2024-05-06_16-56-25/q_network_ep_0999.pth\n","\n","End of episode 1000, totel reward is: -3.167846666551026\n","model saved to models/2024-05-06_16-56-26/q_network_ep_1000.pth\n","\n","End of episode 1001, totel reward is: -1.317993288399502\n","model saved to models/2024-05-06_16-56-27/q_network_ep_1001.pth\n","\n","End of episode 1002, totel reward is: -111.39868325789892\n","End of episode 1003, totel reward is: -2.7914284334567805\n","model saved to models/2024-05-06_16-56-29/q_network_ep_1003.pth\n","\n","End of episode 1004, totel reward is: -9.383546472478162\n","End of episode 1005, totel reward is: -1.7662783319732314\n","model saved to models/2024-05-06_16-56-31/q_network_ep_1005.pth\n","\n","End of episode 1006, totel reward is: -2.0691672134255907\n","model saved to models/2024-05-06_16-56-32/q_network_ep_1006.pth\n","\n","End of episode 1007, totel reward is: -2.8984988107719256\n","model saved to models/2024-05-06_16-56-33/q_network_ep_1007.pth\n","\n","End of episode 1008, totel reward is: -1.8031316976698524\n","model saved to models/2024-05-06_16-56-35/q_network_ep_1008.pth\n","\n","End of episode 1009, totel reward is: -0.7199769071616144\n","model saved to models/2024-05-06_16-56-36/q_network_ep_1009.pth\n","\n","End of episode 1010, totel reward is: -7.450674975783911\n","End of episode 1011, totel reward is: -6.970045461067228\n","End of episode 1012, totel reward is: -1.0099606889538784\n","model saved to models/2024-05-06_16-56-39/q_network_ep_1012.pth\n","\n","End of episode 1013, totel reward is: -5.214085804960899\n","End of episode 1014, totel reward is: -2.2281749799298285\n","model saved to models/2024-05-06_16-56-41/q_network_ep_1014.pth\n","\n","End of episode 1015, totel reward is: -1.7990842637058642\n","model saved to models/2024-05-06_16-56-43/q_network_ep_1015.pth\n","\n","End of episode 1016, totel reward is: -5.5478707625307795\n","End of episode 1017, totel reward is: -6.518295334773937\n","End of episode 1018, totel reward is: -1.3410075741354268\n","model saved to models/2024-05-06_16-56-46/q_network_ep_1018.pth\n","\n","End of episode 1019, totel reward is: -5.6701242502914795\n","End of episode 1020, totel reward is: -1.1094905402054185\n","model saved to models/2024-05-06_16-56-49/q_network_ep_1020.pth\n","\n","End of episode 1021, totel reward is: -6.250405637351069\n","End of episode 1022, totel reward is: -1.0982647370879488\n","model saved to models/2024-05-06_16-56-51/q_network_ep_1022.pth\n","\n","End of episode 1023, totel reward is: -15.919421432833186\n","End of episode 1024, totel reward is: -2.841705654685536\n","model saved to models/2024-05-06_16-56-53/q_network_ep_1024.pth\n","\n","End of episode 1025, totel reward is: -3.150862232656578\n","model saved to models/2024-05-06_16-56-54/q_network_ep_1025.pth\n","\n","End of episode 1026, totel reward is: -4.4461434218632885\n","model saved to models/2024-05-06_16-56-55/q_network_ep_1026.pth\n","\n","End of episode 1027, totel reward is: -2.66974846087945\n","model saved to models/2024-05-06_16-56-56/q_network_ep_1027.pth\n","\n","End of episode 1028, totel reward is: -10.887490146055677\n","End of episode 1029, totel reward is: -7.904268655054288\n","End of episode 1030, totel reward is: -2.3870485983878\n","model saved to models/2024-05-06_16-57-00/q_network_ep_1030.pth\n","\n","End of episode 1031, totel reward is: -2.8502996398468388\n","model saved to models/2024-05-06_16-57-01/q_network_ep_1031.pth\n","\n","End of episode 1032, totel reward is: -3.280693265359043\n","model saved to models/2024-05-06_16-57-02/q_network_ep_1032.pth\n","\n","End of episode 1033, totel reward is: -2.441214015832935\n","model saved to models/2024-05-06_16-57-03/q_network_ep_1033.pth\n","\n","End of episode 1034, totel reward is: -2.9425228013270783\n","model saved to models/2024-05-06_16-57-04/q_network_ep_1034.pth\n","\n","End of episode 1035, totel reward is: -1.1185798640499662\n","model saved to models/2024-05-06_16-57-05/q_network_ep_1035.pth\n","\n","End of episode 1036, totel reward is: -5.379926088097991\n","End of episode 1037, totel reward is: -0.9260801682880012\n","model saved to models/2024-05-06_16-57-08/q_network_ep_1037.pth\n","\n","End of episode 1038, totel reward is: -3.4016152324219684\n","model saved to models/2024-05-06_16-57-09/q_network_ep_1038.pth\n","\n","End of episode 1039, totel reward is: -1.348132669508462\n","model saved to models/2024-05-06_16-57-10/q_network_ep_1039.pth\n","\n","End of episode 1040, totel reward is: -1.6428996956125672\n","model saved to models/2024-05-06_16-57-11/q_network_ep_1040.pth\n","\n","End of episode 1041, totel reward is: -3.1400128250088186\n","model saved to models/2024-05-06_16-57-13/q_network_ep_1041.pth\n","\n","End of episode 1042, totel reward is: -0.6211536878003322\n","model saved to models/2024-05-06_16-57-14/q_network_ep_1042.pth\n","\n","End of episode 1043, totel reward is: -1.320765202447995\n","model saved to models/2024-05-06_16-57-16/q_network_ep_1043.pth\n","\n","End of episode 1044, totel reward is: -6.806977700323268\n","End of episode 1045, totel reward is: -1.0613257161280425\n","model saved to models/2024-05-06_16-57-18/q_network_ep_1045.pth\n","\n","End of episode 1046, totel reward is: -3.020632761086672\n","model saved to models/2024-05-06_16-57-19/q_network_ep_1046.pth\n","\n","End of episode 1047, totel reward is: -3.9431756959620503\n","model saved to models/2024-05-06_16-57-20/q_network_ep_1047.pth\n","\n","End of episode 1048, totel reward is: -0.5779517776875724\n","model saved to models/2024-05-06_16-57-21/q_network_ep_1048.pth\n","\n","End of episode 1049, totel reward is: -1.3607583690434173\n","model saved to models/2024-05-06_16-57-23/q_network_ep_1049.pth\n","\n","End of episode 1050, totel reward is: -4.3854375200778\n","model saved to models/2024-05-06_16-57-24/q_network_ep_1050.pth\n","\n","End of episode 1051, totel reward is: -5.829943503599115\n","End of episode 1052, totel reward is: -4.886043466277647\n","model saved to models/2024-05-06_16-57-27/q_network_ep_1052.pth\n","\n","End of episode 1053, totel reward is: -1.6858274743176358\n","model saved to models/2024-05-06_16-57-29/q_network_ep_1053.pth\n","\n","End of episode 1054, totel reward is: -1.5341893288029393\n","model saved to models/2024-05-06_16-57-30/q_network_ep_1054.pth\n","\n","End of episode 1055, totel reward is: -6.924852466988055\n","End of episode 1056, totel reward is: -5.310888389992204\n","End of episode 1057, totel reward is: -0.4945130072418111\n","model saved to models/2024-05-06_16-57-33/q_network_ep_1057.pth\n","\n","End of episode 1058, totel reward is: -0.9463348978838949\n","model saved to models/2024-05-06_16-57-34/q_network_ep_1058.pth\n","\n","End of episode 1059, totel reward is: -27.703658479668306\n","End of episode 1060, totel reward is: -1.309405057774855\n","model saved to models/2024-05-06_16-57-37/q_network_ep_1060.pth\n","\n","End of episode 1061, totel reward is: -1.216973235197435\n","model saved to models/2024-05-06_16-57-39/q_network_ep_1061.pth\n","\n","End of episode 1062, totel reward is: -0.9093573059448116\n","model saved to models/2024-05-06_16-57-40/q_network_ep_1062.pth\n","\n","End of episode 1063, totel reward is: -2.3184467530234234\n","model saved to models/2024-05-06_16-57-41/q_network_ep_1063.pth\n","\n","End of episode 1064, totel reward is: -1.3221796877746057\n","model saved to models/2024-05-06_16-57-42/q_network_ep_1064.pth\n","\n","End of episode 1065, totel reward is: -1.519603545768404\n","model saved to models/2024-05-06_16-57-43/q_network_ep_1065.pth\n","\n","End of episode 1066, totel reward is: -6.027228817086844\n","End of episode 1067, totel reward is: -2.853852916771653\n","model saved to models/2024-05-06_16-57-46/q_network_ep_1067.pth\n","\n","End of episode 1068, totel reward is: -0.630469527493538\n","model saved to models/2024-05-06_16-57-47/q_network_ep_1068.pth\n","\n","End of episode 1069, totel reward is: -0.5368375615543921\n","model saved to models/2024-05-06_16-57-48/q_network_ep_1069.pth\n","\n","End of episode 1070, totel reward is: -1.8076016263672616\n","model saved to models/2024-05-06_16-57-50/q_network_ep_1070.pth\n","\n","End of episode 1071, totel reward is: -1.493212593307572\n","model saved to models/2024-05-06_16-57-51/q_network_ep_1071.pth\n","\n","End of episode 1072, totel reward is: -4.796397727218194\n","model saved to models/2024-05-06_16-57-52/q_network_ep_1072.pth\n","\n","End of episode 1073, totel reward is: -6.076804856838762\n","End of episode 1074, totel reward is: -0.49647705268331843\n","model saved to models/2024-05-06_16-57-56/q_network_ep_1074.pth\n","\n","End of episode 1075, totel reward is: -8.744781465004511\n","End of episode 1076, totel reward is: -1.3678802533953913\n","model saved to models/2024-05-06_16-57-58/q_network_ep_1076.pth\n","\n","End of episode 1077, totel reward is: -4.68806656193765\n","model saved to models/2024-05-06_16-58-00/q_network_ep_1077.pth\n","\n","End of episode 1078, totel reward is: -2.5836376531743728\n","model saved to models/2024-05-06_16-58-01/q_network_ep_1078.pth\n","\n","End of episode 1079, totel reward is: -2.154701558901029\n","model saved to models/2024-05-06_16-58-03/q_network_ep_1079.pth\n","\n","End of episode 1080, totel reward is: -2.9736277303590155\n","model saved to models/2024-05-06_16-58-04/q_network_ep_1080.pth\n","\n","End of episode 1081, totel reward is: -0.3837384857506914\n","model saved to models/2024-05-06_16-58-05/q_network_ep_1081.pth\n","\n","End of episode 1082, totel reward is: -2.18250949317711\n","model saved to models/2024-05-06_16-58-07/q_network_ep_1082.pth\n","\n","End of episode 1083, totel reward is: -8.566840431545334\n","End of episode 1084, totel reward is: -2.83040273302448\n","model saved to models/2024-05-06_16-58-09/q_network_ep_1084.pth\n","\n","End of episode 1085, totel reward is: -2.9010798281242147\n","model saved to models/2024-05-06_16-58-11/q_network_ep_1085.pth\n","\n","End of episode 1086, totel reward is: -4.4391309405897355\n","model saved to models/2024-05-06_16-58-12/q_network_ep_1086.pth\n","\n","End of episode 1087, totel reward is: -4.111027309049586\n","model saved to models/2024-05-06_16-58-13/q_network_ep_1087.pth\n","\n","End of episode 1088, totel reward is: -0.9511047566126734\n","model saved to models/2024-05-06_16-58-15/q_network_ep_1088.pth\n","\n","End of episode 1089, totel reward is: -1.6429135199739282\n","model saved to models/2024-05-06_16-58-17/q_network_ep_1089.pth\n","\n","End of episode 1090, totel reward is: -3.3953991593080306\n","model saved to models/2024-05-06_16-58-18/q_network_ep_1090.pth\n","\n","End of episode 1091, totel reward is: -3.4572498184245375\n","model saved to models/2024-05-06_16-58-20/q_network_ep_1091.pth\n","\n","End of episode 1092, totel reward is: -3.090064589729803\n","model saved to models/2024-05-06_16-58-21/q_network_ep_1092.pth\n","\n","End of episode 1093, totel reward is: -5.407484345276626\n","End of episode 1094, totel reward is: -3.9427077333243488\n","model saved to models/2024-05-06_16-58-24/q_network_ep_1094.pth\n","\n","End of episode 1095, totel reward is: -1.8062306662805088\n","model saved to models/2024-05-06_16-58-25/q_network_ep_1095.pth\n","\n","End of episode 1096, totel reward is: -1.0584903606012575\n","model saved to models/2024-05-06_16-58-26/q_network_ep_1096.pth\n","\n","End of episode 1097, totel reward is: -1.7434319769725484\n","model saved to models/2024-05-06_16-58-28/q_network_ep_1097.pth\n","\n","End of episode 1098, totel reward is: -1.651738976730957\n","model saved to models/2024-05-06_16-58-29/q_network_ep_1098.pth\n","\n","End of episode 1099, totel reward is: -0.9016266488887426\n","model saved to models/2024-05-06_16-58-31/q_network_ep_1099.pth\n","\n","End of episode 1100, totel reward is: -1.8795004706090546\n","model saved to models/2024-05-06_16-58-32/q_network_ep_1100.pth\n","\n","End of episode 1101, totel reward is: -2.861148835527682\n","model saved to models/2024-05-06_16-58-33/q_network_ep_1101.pth\n","\n","End of episode 1102, totel reward is: -0.30531543636554653\n","model saved to models/2024-05-06_16-58-34/q_network_ep_1102.pth\n","\n","End of episode 1103, totel reward is: -1.5644704284777582\n","model saved to models/2024-05-06_16-58-35/q_network_ep_1103.pth\n","\n","End of episode 1104, totel reward is: -1.2835766685803909\n","model saved to models/2024-05-06_16-58-36/q_network_ep_1104.pth\n","\n","End of episode 1105, totel reward is: -2.192748628007039\n","model saved to models/2024-05-06_16-58-37/q_network_ep_1105.pth\n","\n","End of episode 1106, totel reward is: -0.7648846309331967\n","model saved to models/2024-05-06_16-58-39/q_network_ep_1106.pth\n","\n","End of episode 1107, totel reward is: -2.7941623283798256\n","model saved to models/2024-05-06_16-58-41/q_network_ep_1107.pth\n","\n","End of episode 1108, totel reward is: -1.401758541097931\n","model saved to models/2024-05-06_16-58-42/q_network_ep_1108.pth\n","\n","End of episode 1109, totel reward is: -1.4115920912190218\n","model saved to models/2024-05-06_16-58-43/q_network_ep_1109.pth\n","\n","End of episode 1110, totel reward is: -0.5919607221100742\n","model saved to models/2024-05-06_16-58-44/q_network_ep_1110.pth\n","\n","End of episode 1111, totel reward is: -0.5056519138997696\n","model saved to models/2024-05-06_16-58-46/q_network_ep_1111.pth\n","\n","End of episode 1112, totel reward is: -4.049030620997802\n","model saved to models/2024-05-06_16-58-47/q_network_ep_1112.pth\n","\n","End of episode 1113, totel reward is: -0.5932225763192294\n","model saved to models/2024-05-06_16-58-48/q_network_ep_1113.pth\n","\n","End of episode 1114, totel reward is: -3.0635970603345313\n","model saved to models/2024-05-06_16-58-49/q_network_ep_1114.pth\n","\n","End of episode 1115, totel reward is: -1.022702159263976\n","model saved to models/2024-05-06_16-58-50/q_network_ep_1115.pth\n","\n","End of episode 1116, totel reward is: -3.829880511277197\n","model saved to models/2024-05-06_16-58-52/q_network_ep_1116.pth\n","\n","End of episode 1117, totel reward is: -1.6295941991600211\n","model saved to models/2024-05-06_16-58-53/q_network_ep_1117.pth\n","\n","End of episode 1118, totel reward is: -1.9161730570164848\n","model saved to models/2024-05-06_16-58-55/q_network_ep_1118.pth\n","\n","End of episode 1119, totel reward is: -1.329649037306293\n","model saved to models/2024-05-06_16-58-56/q_network_ep_1119.pth\n","\n","End of episode 1120, totel reward is: -1.187210636445914\n","model saved to models/2024-05-06_16-58-57/q_network_ep_1120.pth\n","\n","End of episode 1121, totel reward is: -0.9336031686834341\n","model saved to models/2024-05-06_16-58-58/q_network_ep_1121.pth\n","\n","End of episode 1122, totel reward is: -3.845809735435723\n","model saved to models/2024-05-06_16-58-59/q_network_ep_1122.pth\n","\n","End of episode 1123, totel reward is: -0.33862578071743676\n","model saved to models/2024-05-06_16-59-01/q_network_ep_1123.pth\n","\n","End of episode 1124, totel reward is: -5.285206236285081\n","End of episode 1125, totel reward is: -0.8414596217256177\n","model saved to models/2024-05-06_16-59-03/q_network_ep_1125.pth\n","\n","End of episode 1126, totel reward is: -5.43571945241136\n","End of episode 1127, totel reward is: -2.205908543636815\n","model saved to models/2024-05-06_16-59-06/q_network_ep_1127.pth\n","\n","End of episode 1128, totel reward is: -1.0135054316218604\n","model saved to models/2024-05-06_16-59-07/q_network_ep_1128.pth\n","\n","End of episode 1129, totel reward is: -0.5336246658404552\n","model saved to models/2024-05-06_16-59-08/q_network_ep_1129.pth\n","\n","End of episode 1130, totel reward is: -0.796873540157279\n","model saved to models/2024-05-06_16-59-10/q_network_ep_1130.pth\n","\n","End of episode 1131, totel reward is: -0.9067227475167379\n","model saved to models/2024-05-06_16-59-11/q_network_ep_1131.pth\n","\n","End of episode 1132, totel reward is: -3.6169414325116995\n","model saved to models/2024-05-06_16-59-12/q_network_ep_1132.pth\n","\n","End of episode 1133, totel reward is: -0.5567090912442528\n","model saved to models/2024-05-06_16-59-13/q_network_ep_1133.pth\n","\n","End of episode 1134, totel reward is: -4.076561853649175\n","model saved to models/2024-05-06_16-59-14/q_network_ep_1134.pth\n","\n","End of episode 1135, totel reward is: -3.1715658700837066\n","model saved to models/2024-05-06_16-59-15/q_network_ep_1135.pth\n","\n","End of episode 1136, totel reward is: -42.98727373637736\n","End of episode 1137, totel reward is: -1.3887503422300231\n","model saved to models/2024-05-06_16-59-18/q_network_ep_1137.pth\n","\n","End of episode 1138, totel reward is: -1.7772180624319602\n","model saved to models/2024-05-06_16-59-20/q_network_ep_1138.pth\n","\n","End of episode 1139, totel reward is: -4.113393893723422\n","model saved to models/2024-05-06_16-59-21/q_network_ep_1139.pth\n","\n","End of episode 1140, totel reward is: -1.2290680768579196\n","model saved to models/2024-05-06_16-59-22/q_network_ep_1140.pth\n","\n","End of episode 1141, totel reward is: -2.9013425710047875\n","model saved to models/2024-05-06_16-59-23/q_network_ep_1141.pth\n","\n","End of episode 1142, totel reward is: -3.112002034010733\n","model saved to models/2024-05-06_16-59-24/q_network_ep_1142.pth\n","\n","End of episode 1143, totel reward is: -1194.0093436269974\n","End of episode 1144, totel reward is: -2.2667687337283153\n","model saved to models/2024-05-06_16-59-27/q_network_ep_1144.pth\n","\n","End of episode 1145, totel reward is: -1.9303126152411427\n","model saved to models/2024-05-06_16-59-28/q_network_ep_1145.pth\n","\n","End of episode 1146, totel reward is: -15.074249703792125\n","End of episode 1147, totel reward is: -638.4825934848242\n","End of episode 1148, totel reward is: -5.1695626672058435\n","End of episode 1149, totel reward is: -25.22901725543489\n","End of episode 1150, totel reward is: -2.781737123264347\n","model saved to models/2024-05-06_16-59-34/q_network_ep_1150.pth\n","\n","End of episode 1151, totel reward is: -2.6914141169232733\n","model saved to models/2024-05-06_16-59-36/q_network_ep_1151.pth\n","\n","End of episode 1152, totel reward is: -23.591577714853237\n","End of episode 1153, totel reward is: -76.92068279852839\n","End of episode 1154, totel reward is: -3.7833995555493063\n","model saved to models/2024-05-06_16-59-39/q_network_ep_1154.pth\n","\n","End of episode 1155, totel reward is: -3.7601370952988877\n","model saved to models/2024-05-06_16-59-40/q_network_ep_1155.pth\n","\n","End of episode 1156, totel reward is: -9.500345657071577\n","End of episode 1157, totel reward is: -4.5811193372478325\n","model saved to models/2024-05-06_16-59-43/q_network_ep_1157.pth\n","\n","End of episode 1158, totel reward is: -5.575204192609599\n","End of episode 1159, totel reward is: -7.328778607417855\n","End of episode 1160, totel reward is: -8.000217438009251\n","End of episode 1161, totel reward is: -1.454463890872982\n","model saved to models/2024-05-06_16-59-48/q_network_ep_1161.pth\n","\n","End of episode 1162, totel reward is: -9.066707583472638\n","End of episode 1163, totel reward is: -1.4971439077062532\n","model saved to models/2024-05-06_16-59-50/q_network_ep_1163.pth\n","\n","End of episode 1164, totel reward is: -14.356344127060773\n","End of episode 1165, totel reward is: -3.4964505975282565\n","model saved to models/2024-05-06_16-59-52/q_network_ep_1165.pth\n","\n","End of episode 1166, totel reward is: -1.9289204055517148\n","model saved to models/2024-05-06_16-59-53/q_network_ep_1166.pth\n","\n","End of episode 1167, totel reward is: -5.499278342181112\n","End of episode 1168, totel reward is: -0.5263263692594068\n","model saved to models/2024-05-06_16-59-57/q_network_ep_1168.pth\n","\n","End of episode 1169, totel reward is: -3.3647692886984593\n","model saved to models/2024-05-06_16-59-58/q_network_ep_1169.pth\n","\n","End of episode 1170, totel reward is: -10.050598968884646\n","End of episode 1171, totel reward is: -2.036662934006282\n","model saved to models/2024-05-06_17-00-00/q_network_ep_1171.pth\n","\n","End of episode 1172, totel reward is: -28.82335787616891\n","End of episode 1173, totel reward is: -1.7690816250556394\n","model saved to models/2024-05-06_17-00-02/q_network_ep_1173.pth\n","\n","End of episode 1174, totel reward is: -5.043651486207853\n","End of episode 1175, totel reward is: -0.6847253859094727\n","model saved to models/2024-05-06_17-00-05/q_network_ep_1175.pth\n","\n","End of episode 1176, totel reward is: -1.7021124362518312\n","model saved to models/2024-05-06_17-00-06/q_network_ep_1176.pth\n","\n","End of episode 1177, totel reward is: -2.3332792622636975\n","model saved to models/2024-05-06_17-00-07/q_network_ep_1177.pth\n","\n","End of episode 1178, totel reward is: -5.83112750955637\n","End of episode 1179, totel reward is: -3.2773192912221774\n","model saved to models/2024-05-06_17-00-10/q_network_ep_1179.pth\n","\n","End of episode 1180, totel reward is: -4.492124808898743\n","model saved to models/2024-05-06_17-00-11/q_network_ep_1180.pth\n","\n","End of episode 1181, totel reward is: -1.9371391637163689\n","model saved to models/2024-05-06_17-00-12/q_network_ep_1181.pth\n","\n","End of episode 1182, totel reward is: -4.952195119052104\n","model saved to models/2024-05-06_17-00-14/q_network_ep_1182.pth\n","\n","End of episode 1183, totel reward is: -3.689729985662685\n","model saved to models/2024-05-06_17-00-15/q_network_ep_1183.pth\n","\n","End of episode 1184, totel reward is: -6.630134549031876\n","End of episode 1185, totel reward is: -1.2588097862631222\n","model saved to models/2024-05-06_17-00-17/q_network_ep_1185.pth\n","\n","End of episode 1186, totel reward is: -2.32805170140722\n","model saved to models/2024-05-06_17-00-19/q_network_ep_1186.pth\n","\n","End of episode 1187, totel reward is: -3.485505370664175\n","model saved to models/2024-05-06_17-00-20/q_network_ep_1187.pth\n","\n","End of episode 1188, totel reward is: -2.3592894713546073\n","model saved to models/2024-05-06_17-00-22/q_network_ep_1188.pth\n","\n","End of episode 1189, totel reward is: -1.847895645693492\n","model saved to models/2024-05-06_17-00-23/q_network_ep_1189.pth\n","\n","End of episode 1190, totel reward is: -5.368195397138044\n","End of episode 1191, totel reward is: -2.2032581057490006\n","model saved to models/2024-05-06_17-00-26/q_network_ep_1191.pth\n","\n","End of episode 1192, totel reward is: -4.288052041781414\n","model saved to models/2024-05-06_17-00-27/q_network_ep_1192.pth\n","\n","End of episode 1193, totel reward is: -4.5250806819174585\n","model saved to models/2024-05-06_17-00-28/q_network_ep_1193.pth\n","\n","End of episode 1194, totel reward is: -2.294551466442252\n","model saved to models/2024-05-06_17-00-29/q_network_ep_1194.pth\n","\n","End of episode 1195, totel reward is: -9.936279558895901\n","End of episode 1196, totel reward is: -4.525230560903695\n","model saved to models/2024-05-06_17-00-31/q_network_ep_1196.pth\n","\n","End of episode 1197, totel reward is: -1.3828229901344538\n","model saved to models/2024-05-06_17-00-33/q_network_ep_1197.pth\n","\n","End of episode 1198, totel reward is: -4.840270900698712\n","model saved to models/2024-05-06_17-00-35/q_network_ep_1198.pth\n","\n","End of episode 1199, totel reward is: -1.1184046376927206\n","model saved to models/2024-05-06_17-00-36/q_network_ep_1199.pth\n","\n","End of episode 1200, totel reward is: -2.993096919556225\n","model saved to models/2024-05-06_17-00-37/q_network_ep_1200.pth\n","\n","End of episode 1201, totel reward is: -5.328631034052813\n","End of episode 1202, totel reward is: -4.08446220837043\n","model saved to models/2024-05-06_17-00-39/q_network_ep_1202.pth\n","\n","End of episode 1203, totel reward is: -1.1512690762428868\n","model saved to models/2024-05-06_17-00-41/q_network_ep_1203.pth\n","\n","End of episode 1204, totel reward is: -0.933286741739234\n","model saved to models/2024-05-06_17-00-42/q_network_ep_1204.pth\n","\n","End of episode 1205, totel reward is: -0.8165440330211389\n","model saved to models/2024-05-06_17-00-43/q_network_ep_1205.pth\n","\n","End of episode 1206, totel reward is: -107.46812597398306\n","End of episode 1207, totel reward is: -33.52870863318272\n","End of episode 1208, totel reward is: -2.1676573903761014\n","model saved to models/2024-05-06_17-00-47/q_network_ep_1208.pth\n","\n","End of episode 1209, totel reward is: -1.0436088936721826\n","model saved to models/2024-05-06_17-00-48/q_network_ep_1209.pth\n","\n","End of episode 1210, totel reward is: -4.1553237647089905\n","model saved to models/2024-05-06_17-00-50/q_network_ep_1210.pth\n","\n","End of episode 1211, totel reward is: -1.8388195803395402\n","model saved to models/2024-05-06_17-00-51/q_network_ep_1211.pth\n","\n","End of episode 1212, totel reward is: -1.8092584854509826\n","model saved to models/2024-05-06_17-00-52/q_network_ep_1212.pth\n","\n","End of episode 1213, totel reward is: -12.643395008743\n","End of episode 1214, totel reward is: -3.7960951122225777\n","model saved to models/2024-05-06_17-00-54/q_network_ep_1214.pth\n","\n","End of episode 1215, totel reward is: -3.61037061871743\n","model saved to models/2024-05-06_17-00-56/q_network_ep_1215.pth\n","\n","End of episode 1216, totel reward is: -5.145071025889647\n","End of episode 1217, totel reward is: -1.4192725007413949\n","model saved to models/2024-05-06_17-00-59/q_network_ep_1217.pth\n","\n","End of episode 1218, totel reward is: -2.129725869319898\n","model saved to models/2024-05-06_17-01-00/q_network_ep_1218.pth\n","\n","End of episode 1219, totel reward is: -2.150336911616868\n","model saved to models/2024-05-06_17-01-01/q_network_ep_1219.pth\n","\n","End of episode 1220, totel reward is: -6.883108177259433\n","End of episode 1221, totel reward is: -5.198728366001243\n","End of episode 1222, totel reward is: -1.7303655440510097\n","model saved to models/2024-05-06_17-01-05/q_network_ep_1222.pth\n","\n","End of episode 1223, totel reward is: -3.8844021063623386\n","model saved to models/2024-05-06_17-01-06/q_network_ep_1223.pth\n","\n","End of episode 1224, totel reward is: -0.7069722725598776\n","model saved to models/2024-05-06_17-01-08/q_network_ep_1224.pth\n","\n","End of episode 1225, totel reward is: -1.8098883985552574\n","model saved to models/2024-05-06_17-01-09/q_network_ep_1225.pth\n","\n","End of episode 1226, totel reward is: -1.1429017646131248\n","model saved to models/2024-05-06_17-01-11/q_network_ep_1226.pth\n","\n","End of episode 1227, totel reward is: -1.8263951263763738\n","model saved to models/2024-05-06_17-01-12/q_network_ep_1227.pth\n","\n","End of episode 1228, totel reward is: -0.997687501602108\n","model saved to models/2024-05-06_17-01-13/q_network_ep_1228.pth\n","\n","End of episode 1229, totel reward is: -1.1870449115914417\n","model saved to models/2024-05-06_17-01-15/q_network_ep_1229.pth\n","\n","End of episode 1230, totel reward is: -19.5005322985794\n","End of episode 1231, totel reward is: -2.9666320318268897\n","model saved to models/2024-05-06_17-01-17/q_network_ep_1231.pth\n","\n","End of episode 1232, totel reward is: -1.4988577227985207\n","model saved to models/2024-05-06_17-01-18/q_network_ep_1232.pth\n","\n","End of episode 1233, totel reward is: -4.373961113123745\n","model saved to models/2024-05-06_17-01-20/q_network_ep_1233.pth\n","\n","End of episode 1234, totel reward is: -1.0442952008403068\n","model saved to models/2024-05-06_17-01-21/q_network_ep_1234.pth\n","\n","End of episode 1235, totel reward is: -0.824636570941021\n","model saved to models/2024-05-06_17-01-22/q_network_ep_1235.pth\n","\n","End of episode 1236, totel reward is: -1.1267918867737776\n","model saved to models/2024-05-06_17-01-24/q_network_ep_1236.pth\n","\n","End of episode 1237, totel reward is: -8.86663694489504\n","End of episode 1238, totel reward is: -6.516967922821976\n","End of episode 1239, totel reward is: -6.095570976513267\n","End of episode 1240, totel reward is: -14.861142338548143\n","End of episode 1241, totel reward is: -1.2883673918634897\n","model saved to models/2024-05-06_17-01-30/q_network_ep_1241.pth\n","\n","End of episode 1242, totel reward is: -3.771992207092651\n","model saved to models/2024-05-06_17-01-31/q_network_ep_1242.pth\n","\n","End of episode 1243, totel reward is: -1.9619787240852637\n","model saved to models/2024-05-06_17-01-32/q_network_ep_1243.pth\n","\n","End of episode 1244, totel reward is: -1.554714311473796\n","model saved to models/2024-05-06_17-01-33/q_network_ep_1244.pth\n","\n","End of episode 1245, totel reward is: -5.3507502221250345\n","End of episode 1246, totel reward is: -0.9449211609933281\n","model saved to models/2024-05-06_17-01-36/q_network_ep_1246.pth\n","\n","End of episode 1247, totel reward is: -1.677335322472073\n","model saved to models/2024-05-06_17-01-38/q_network_ep_1247.pth\n","\n","End of episode 1248, totel reward is: -3.819374160419151\n","model saved to models/2024-05-06_17-01-39/q_network_ep_1248.pth\n","\n","End of episode 1249, totel reward is: -1.8255785397408388\n","model saved to models/2024-05-06_17-01-40/q_network_ep_1249.pth\n","\n","End of episode 1250, totel reward is: -1.966798277106518\n","model saved to models/2024-05-06_17-01-41/q_network_ep_1250.pth\n","\n","End of episode 1251, totel reward is: -3.6102862717344926\n","model saved to models/2024-05-06_17-01-42/q_network_ep_1251.pth\n","\n","End of episode 1252, totel reward is: -11.13202566901317\n","End of episode 1253, totel reward is: -1.8667613716740696\n","model saved to models/2024-05-06_17-01-45/q_network_ep_1253.pth\n","\n","End of episode 1254, totel reward is: -3.119324750197742\n","model saved to models/2024-05-06_17-01-46/q_network_ep_1254.pth\n","\n","End of episode 1255, totel reward is: -8.714251712593233\n","End of episode 1256, totel reward is: -11.771391329521386\n","End of episode 1257, totel reward is: -4.584413521774116\n","model saved to models/2024-05-06_17-01-50/q_network_ep_1257.pth\n","\n","End of episode 1258, totel reward is: -3.0319089215395474\n","model saved to models/2024-05-06_17-01-51/q_network_ep_1258.pth\n","\n","End of episode 1259, totel reward is: -1.013753247345337\n","model saved to models/2024-05-06_17-01-53/q_network_ep_1259.pth\n","\n","End of episode 1260, totel reward is: -1.7445108744225397\n","model saved to models/2024-05-06_17-01-54/q_network_ep_1260.pth\n","\n","End of episode 1261, totel reward is: -0.9773681333376778\n","model saved to models/2024-05-06_17-01-55/q_network_ep_1261.pth\n","\n","End of episode 1262, totel reward is: -11.25695806134952\n","End of episode 1263, totel reward is: -1.8316245347216242\n","model saved to models/2024-05-06_17-01-58/q_network_ep_1263.pth\n","\n","End of episode 1264, totel reward is: -1.2947847108741641\n","model saved to models/2024-05-06_17-01-59/q_network_ep_1264.pth\n","\n","End of episode 1265, totel reward is: -7.009353190965651\n","End of episode 1266, totel reward is: -2.938561725443331\n","model saved to models/2024-05-06_17-02-02/q_network_ep_1266.pth\n","\n","End of episode 1267, totel reward is: -3.2420505616869666\n","model saved to models/2024-05-06_17-02-03/q_network_ep_1267.pth\n","\n","End of episode 1268, totel reward is: -1.2385496446959692\n","model saved to models/2024-05-06_17-02-04/q_network_ep_1268.pth\n","\n","End of episode 1269, totel reward is: -41.301952968453186\n","End of episode 1270, totel reward is: -11.547782102619008\n","End of episode 1271, totel reward is: -1.8923218109332236\n","model saved to models/2024-05-06_17-02-09/q_network_ep_1271.pth\n","\n","End of episode 1272, totel reward is: -2.8110854753919505\n","model saved to models/2024-05-06_17-02-11/q_network_ep_1272.pth\n","\n","End of episode 1273, totel reward is: -1.1912885895658918\n","model saved to models/2024-05-06_17-02-12/q_network_ep_1273.pth\n","\n","End of episode 1274, totel reward is: -8.65132672519398\n","End of episode 1275, totel reward is: -1.474995390203522\n","model saved to models/2024-05-06_17-02-15/q_network_ep_1275.pth\n","\n","End of episode 1276, totel reward is: -3.202965999385671\n","model saved to models/2024-05-06_17-02-16/q_network_ep_1276.pth\n","\n","End of episode 1277, totel reward is: -10.247570928030354\n","End of episode 1278, totel reward is: -1.8342916551430364\n","model saved to models/2024-05-06_17-02-19/q_network_ep_1278.pth\n","\n","End of episode 1279, totel reward is: -0.9289860964095088\n","model saved to models/2024-05-06_17-02-20/q_network_ep_1279.pth\n","\n","End of episode 1280, totel reward is: -1.1727612410303567\n","model saved to models/2024-05-06_17-02-21/q_network_ep_1280.pth\n","\n","End of episode 1281, totel reward is: -8.739116809854123\n","End of episode 1282, totel reward is: -8.817758158568845\n","End of episode 1283, totel reward is: -0.7141202040282101\n","model saved to models/2024-05-06_17-02-25/q_network_ep_1283.pth\n","\n","End of episode 1284, totel reward is: -1.1306534414303386\n","model saved to models/2024-05-06_17-02-27/q_network_ep_1284.pth\n","\n","End of episode 1285, totel reward is: -2.137385311424217\n","model saved to models/2024-05-06_17-02-28/q_network_ep_1285.pth\n","\n","End of episode 1286, totel reward is: -0.7641651999048\n","model saved to models/2024-05-06_17-02-29/q_network_ep_1286.pth\n","\n","End of episode 1287, totel reward is: -1.2473887046394827\n","model saved to models/2024-05-06_17-02-31/q_network_ep_1287.pth\n","\n","End of episode 1288, totel reward is: -1.3197606106067141\n","model saved to models/2024-05-06_17-02-32/q_network_ep_1288.pth\n","\n","End of episode 1289, totel reward is: -2.6320828424899254\n","model saved to models/2024-05-06_17-02-33/q_network_ep_1289.pth\n","\n","End of episode 1290, totel reward is: -2.4875572757991713\n","model saved to models/2024-05-06_17-02-34/q_network_ep_1290.pth\n","\n","End of episode 1291, totel reward is: -3.0815840691884433\n","model saved to models/2024-05-06_17-02-36/q_network_ep_1291.pth\n","\n","End of episode 1292, totel reward is: -1.6173003249777143\n","model saved to models/2024-05-06_17-02-37/q_network_ep_1292.pth\n","\n","End of episode 1293, totel reward is: -1.1659342897871872\n","model saved to models/2024-05-06_17-02-38/q_network_ep_1293.pth\n","\n","End of episode 1294, totel reward is: -4.180388352152557\n","model saved to models/2024-05-06_17-02-40/q_network_ep_1294.pth\n","\n","End of episode 1295, totel reward is: -9.593954486599202\n","End of episode 1296, totel reward is: -1.1724982238948338\n","model saved to models/2024-05-06_17-02-42/q_network_ep_1296.pth\n","\n","End of episode 1297, totel reward is: -1.7679332057767807\n","model saved to models/2024-05-06_17-02-43/q_network_ep_1297.pth\n","\n","End of episode 1298, totel reward is: -1.996103880157579\n","model saved to models/2024-05-06_17-02-45/q_network_ep_1298.pth\n","\n","End of episode 1299, totel reward is: -6.296370302216138\n","End of episode 1300, totel reward is: -1.8274854453997023\n","model saved to models/2024-05-06_17-02-47/q_network_ep_1300.pth\n","\n","End of episode 1301, totel reward is: -0.9807142523035016\n","model saved to models/2024-05-06_17-02-48/q_network_ep_1301.pth\n","\n","End of episode 1302, totel reward is: -4.936558741974731\n","model saved to models/2024-05-06_17-02-49/q_network_ep_1302.pth\n","\n","End of episode 1303, totel reward is: -0.6844972355990947\n","model saved to models/2024-05-06_17-02-51/q_network_ep_1303.pth\n","\n","End of episode 1304, totel reward is: -0.8422927030697981\n","model saved to models/2024-05-06_17-02-52/q_network_ep_1304.pth\n","\n","End of episode 1305, totel reward is: -1.4893666889829285\n","model saved to models/2024-05-06_17-02-54/q_network_ep_1305.pth\n","\n","End of episode 1306, totel reward is: -0.8082405599707009\n","model saved to models/2024-05-06_17-02-55/q_network_ep_1306.pth\n","\n","End of episode 1307, totel reward is: -1.181810793008015\n","model saved to models/2024-05-06_17-02-56/q_network_ep_1307.pth\n","\n","End of episode 1308, totel reward is: -0.937559210744962\n","model saved to models/2024-05-06_17-02-57/q_network_ep_1308.pth\n","\n","End of episode 1309, totel reward is: -0.8024469831038584\n","model saved to models/2024-05-06_17-02-58/q_network_ep_1309.pth\n","\n","End of episode 1310, totel reward is: -0.8934001200514176\n","model saved to models/2024-05-06_17-02-59/q_network_ep_1310.pth\n","\n","End of episode 1311, totel reward is: -0.7749852341484291\n","model saved to models/2024-05-06_17-03-01/q_network_ep_1311.pth\n","\n","End of episode 1312, totel reward is: -4.841212675383794\n","model saved to models/2024-05-06_17-03-02/q_network_ep_1312.pth\n","\n","End of episode 1313, totel reward is: -1.4924570181594996\n","model saved to models/2024-05-06_17-03-03/q_network_ep_1313.pth\n","\n","End of episode 1314, totel reward is: -1.9108472100783878\n","model saved to models/2024-05-06_17-03-05/q_network_ep_1314.pth\n","\n","End of episode 1315, totel reward is: -1.3635194700093136\n","model saved to models/2024-05-06_17-03-06/q_network_ep_1315.pth\n","\n","End of episode 1316, totel reward is: -5.618021227412675\n","End of episode 1317, totel reward is: -35.816550104627886\n","End of episode 1318, totel reward is: -1.3702732044322787\n","model saved to models/2024-05-06_17-03-10/q_network_ep_1318.pth\n","\n","End of episode 1319, totel reward is: -2.7039086351198245\n","model saved to models/2024-05-06_17-03-11/q_network_ep_1319.pth\n","\n","End of episode 1320, totel reward is: -3.3928262578156336\n","model saved to models/2024-05-06_17-03-12/q_network_ep_1320.pth\n","\n","End of episode 1321, totel reward is: -1.3846062334654805\n","model saved to models/2024-05-06_17-03-13/q_network_ep_1321.pth\n","\n","End of episode 1322, totel reward is: -4.1742855698524854\n","model saved to models/2024-05-06_17-03-15/q_network_ep_1322.pth\n","\n","End of episode 1323, totel reward is: -0.6381395554904247\n","model saved to models/2024-05-06_17-03-16/q_network_ep_1323.pth\n","\n","End of episode 1324, totel reward is: -5.4804026820788305\n","End of episode 1325, totel reward is: -6.873299384105335\n","End of episode 1326, totel reward is: -3.339193163067034\n","model saved to models/2024-05-06_17-03-20/q_network_ep_1326.pth\n","\n","End of episode 1327, totel reward is: -12.677960854215442\n","End of episode 1328, totel reward is: -1.7125615303120534\n","model saved to models/2024-05-06_17-03-22/q_network_ep_1328.pth\n","\n","End of episode 1329, totel reward is: -0.650995759544601\n","model saved to models/2024-05-06_17-03-24/q_network_ep_1329.pth\n","\n","End of episode 1330, totel reward is: -2.609864719586862\n","model saved to models/2024-05-06_17-03-25/q_network_ep_1330.pth\n","\n","End of episode 1331, totel reward is: -1.4576902409530315\n","model saved to models/2024-05-06_17-03-26/q_network_ep_1331.pth\n","\n","End of episode 1332, totel reward is: -2.400510001635573\n","model saved to models/2024-05-06_17-03-27/q_network_ep_1332.pth\n","\n","End of episode 1333, totel reward is: -1.2545078634369158\n","model saved to models/2024-05-06_17-03-29/q_network_ep_1333.pth\n","\n","End of episode 1334, totel reward is: -4.751464311298835\n","model saved to models/2024-05-06_17-03-30/q_network_ep_1334.pth\n","\n","End of episode 1335, totel reward is: -1.227537485482523\n","model saved to models/2024-05-06_17-03-31/q_network_ep_1335.pth\n","\n","End of episode 1336, totel reward is: -0.9193272473071032\n","model saved to models/2024-05-06_17-03-33/q_network_ep_1336.pth\n","\n","End of episode 1337, totel reward is: -0.7343884624316178\n","model saved to models/2024-05-06_17-03-34/q_network_ep_1337.pth\n","\n","End of episode 1338, totel reward is: -3.2708415711096834\n","model saved to models/2024-05-06_17-03-35/q_network_ep_1338.pth\n","\n","End of episode 1339, totel reward is: -1.6230831723108765\n","model saved to models/2024-05-06_17-03-36/q_network_ep_1339.pth\n","\n","End of episode 1340, totel reward is: -0.5170201833552763\n","model saved to models/2024-05-06_17-03-37/q_network_ep_1340.pth\n","\n","End of episode 1341, totel reward is: -6.751593391738219\n","End of episode 1342, totel reward is: -6.528845429321696\n","End of episode 1343, totel reward is: -2.8726457193409174\n","model saved to models/2024-05-06_17-03-41/q_network_ep_1343.pth\n","\n","End of episode 1344, totel reward is: -1.111112993791883\n","model saved to models/2024-05-06_17-03-43/q_network_ep_1344.pth\n","\n","End of episode 1345, totel reward is: -0.8883640772173856\n","model saved to models/2024-05-06_17-03-44/q_network_ep_1345.pth\n","\n","End of episode 1346, totel reward is: -9.082198532603712\n","End of episode 1347, totel reward is: -2.1828632761425633\n","model saved to models/2024-05-06_17-03-46/q_network_ep_1347.pth\n","\n","End of episode 1348, totel reward is: -9.634273029151661\n","End of episode 1349, totel reward is: -4.659524280522824\n","model saved to models/2024-05-06_17-03-49/q_network_ep_1349.pth\n","\n","End of episode 1350, totel reward is: -8.218132710406179\n","End of episode 1351, totel reward is: -10.609281368088412\n","End of episode 1352, totel reward is: -0.6091087191211544\n","model saved to models/2024-05-06_17-03-52/q_network_ep_1352.pth\n","\n","End of episode 1353, totel reward is: -0.751066754454533\n","model saved to models/2024-05-06_17-03-54/q_network_ep_1353.pth\n","\n","End of episode 1354, totel reward is: -1.5810598381959053\n","model saved to models/2024-05-06_17-03-55/q_network_ep_1354.pth\n","\n","End of episode 1355, totel reward is: -0.8758542205905195\n","model saved to models/2024-05-06_17-03-57/q_network_ep_1355.pth\n","\n","End of episode 1356, totel reward is: -1.1718801281440032\n","model saved to models/2024-05-06_17-03-58/q_network_ep_1356.pth\n","\n","End of episode 1357, totel reward is: -35.16025133394038\n","End of episode 1358, totel reward is: -0.663654724487173\n","model saved to models/2024-05-06_17-04-00/q_network_ep_1358.pth\n","\n","End of episode 1359, totel reward is: -1.7158202802486244\n","model saved to models/2024-05-06_17-04-01/q_network_ep_1359.pth\n","\n","End of episode 1360, totel reward is: -0.7567178569075099\n","model saved to models/2024-05-06_17-04-03/q_network_ep_1360.pth\n","\n","End of episode 1361, totel reward is: -4.941896109332735\n","model saved to models/2024-05-06_17-04-04/q_network_ep_1361.pth\n","\n","End of episode 1362, totel reward is: -3.564552019504414\n","model saved to models/2024-05-06_17-04-05/q_network_ep_1362.pth\n","\n","End of episode 1363, totel reward is: -1.5908132110767605\n","model saved to models/2024-05-06_17-04-07/q_network_ep_1363.pth\n","\n","End of episode 1364, totel reward is: -3.051532139503328\n","model saved to models/2024-05-06_17-04-08/q_network_ep_1364.pth\n","\n","End of episode 1365, totel reward is: -0.7735013872649766\n","model saved to models/2024-05-06_17-04-10/q_network_ep_1365.pth\n","\n","End of episode 1366, totel reward is: -0.5694953888544688\n","model saved to models/2024-05-06_17-04-11/q_network_ep_1366.pth\n","\n","End of episode 1367, totel reward is: -3.1336885379297925\n","model saved to models/2024-05-06_17-04-12/q_network_ep_1367.pth\n","\n","End of episode 1368, totel reward is: -0.8390482776514118\n","model saved to models/2024-05-06_17-04-13/q_network_ep_1368.pth\n","\n","End of episode 1369, totel reward is: -2.2706463260162817\n","model saved to models/2024-05-06_17-04-14/q_network_ep_1369.pth\n","\n","End of episode 1370, totel reward is: -16.05366475314916\n","End of episode 1371, totel reward is: -0.45178711131768634\n","model saved to models/2024-05-06_17-04-17/q_network_ep_1371.pth\n","\n","End of episode 1372, totel reward is: -2.2224667267792477\n","model saved to models/2024-05-06_17-04-18/q_network_ep_1372.pth\n","\n","End of episode 1373, totel reward is: -2.153191861647406\n","model saved to models/2024-05-06_17-04-20/q_network_ep_1373.pth\n","\n","End of episode 1374, totel reward is: -7.099044832395309\n","End of episode 1375, totel reward is: -1.2881135285992025\n","model saved to models/2024-05-06_17-04-23/q_network_ep_1375.pth\n","\n","End of episode 1376, totel reward is: -0.6473842656318622\n","model saved to models/2024-05-06_17-04-24/q_network_ep_1376.pth\n","\n","End of episode 1377, totel reward is: -1.4464126696062052\n","model saved to models/2024-05-06_17-04-25/q_network_ep_1377.pth\n","\n","End of episode 1378, totel reward is: -1.4224715923521598\n","model saved to models/2024-05-06_17-04-26/q_network_ep_1378.pth\n","\n","End of episode 1379, totel reward is: -0.5137327297873677\n","model saved to models/2024-05-06_17-04-27/q_network_ep_1379.pth\n","\n","End of episode 1380, totel reward is: -1.412067677053798\n","model saved to models/2024-05-06_17-04-28/q_network_ep_1380.pth\n","\n","End of episode 1381, totel reward is: -1.2092396885232424\n","model saved to models/2024-05-06_17-04-30/q_network_ep_1381.pth\n","\n","End of episode 1382, totel reward is: -0.7030134921059121\n","model saved to models/2024-05-06_17-04-31/q_network_ep_1382.pth\n","\n","End of episode 1383, totel reward is: -1.0383774365014298\n","model saved to models/2024-05-06_17-04-33/q_network_ep_1383.pth\n","\n","End of episode 1384, totel reward is: -2.2107674737213756\n","model saved to models/2024-05-06_17-04-34/q_network_ep_1384.pth\n","\n","End of episode 1385, totel reward is: -9.753837403117965\n","End of episode 1386, totel reward is: -3.929367529956095\n","model saved to models/2024-05-06_17-04-36/q_network_ep_1386.pth\n","\n","End of episode 1387, totel reward is: -2.2835630985779476\n","model saved to models/2024-05-06_17-04-38/q_network_ep_1387.pth\n","\n","End of episode 1388, totel reward is: -5.512312776936157\n","End of episode 1389, totel reward is: -0.5116591569330476\n","model saved to models/2024-05-06_17-04-40/q_network_ep_1389.pth\n","\n","End of episode 1390, totel reward is: -7.828058616683883\n","End of episode 1391, totel reward is: -0.6772358909652828\n","model saved to models/2024-05-06_17-04-42/q_network_ep_1391.pth\n","\n","End of episode 1392, totel reward is: -3.236716746385113\n","model saved to models/2024-05-06_17-04-44/q_network_ep_1392.pth\n","\n","End of episode 1393, totel reward is: -0.8510668167881962\n","model saved to models/2024-05-06_17-04-46/q_network_ep_1393.pth\n","\n","End of episode 1394, totel reward is: -1.9311749106098781\n","model saved to models/2024-05-06_17-04-47/q_network_ep_1394.pth\n","\n","End of episode 1395, totel reward is: -3.934779604560051\n","model saved to models/2024-05-06_17-04-48/q_network_ep_1395.pth\n","\n","End of episode 1396, totel reward is: -9.734085768461837\n","End of episode 1397, totel reward is: -0.6596864992939648\n","model saved to models/2024-05-06_17-04-50/q_network_ep_1397.pth\n","\n","End of episode 1398, totel reward is: -1.3387045234091899\n","model saved to models/2024-05-06_17-04-52/q_network_ep_1398.pth\n","\n","End of episode 1399, totel reward is: -1.694490624807749\n","model saved to models/2024-05-06_17-04-53/q_network_ep_1399.pth\n","\n","End of episode 1400, totel reward is: -20.74104123215736\n","End of episode 1401, totel reward is: -1.1818082802379293\n","model saved to models/2024-05-06_17-04-55/q_network_ep_1401.pth\n","\n","End of episode 1402, totel reward is: -2.230033378100059\n","model saved to models/2024-05-06_17-04-57/q_network_ep_1402.pth\n","\n","End of episode 1403, totel reward is: -0.6849061643360467\n","model saved to models/2024-05-06_17-04-58/q_network_ep_1403.pth\n","\n","End of episode 1404, totel reward is: -0.8560756803610503\n","model saved to models/2024-05-06_17-05-00/q_network_ep_1404.pth\n","\n","End of episode 1405, totel reward is: -1.0290536629431344\n","model saved to models/2024-05-06_17-05-01/q_network_ep_1405.pth\n","\n","End of episode 1406, totel reward is: -0.4177180742343715\n","model saved to models/2024-05-06_17-05-02/q_network_ep_1406.pth\n","\n","End of episode 1407, totel reward is: -12.23432768041999\n","End of episode 1408, totel reward is: -2.7879796543453694\n","model saved to models/2024-05-06_17-05-05/q_network_ep_1408.pth\n","\n","End of episode 1409, totel reward is: -6.395451052497291\n","End of episode 1410, totel reward is: -1.3823325227546677\n","model saved to models/2024-05-06_17-05-07/q_network_ep_1410.pth\n","\n","End of episode 1411, totel reward is: -1.1489481558625492\n","model saved to models/2024-05-06_17-05-08/q_network_ep_1411.pth\n","\n","End of episode 1412, totel reward is: -4.747541750452073\n","model saved to models/2024-05-06_17-05-10/q_network_ep_1412.pth\n","\n","End of episode 1413, totel reward is: -1.7071206946730326\n","model saved to models/2024-05-06_17-05-12/q_network_ep_1413.pth\n","\n","End of episode 1414, totel reward is: -3.9529648021628554\n","model saved to models/2024-05-06_17-05-13/q_network_ep_1414.pth\n","\n","End of episode 1415, totel reward is: -1.9185027371958137\n","model saved to models/2024-05-06_17-05-14/q_network_ep_1415.pth\n","\n","End of episode 1416, totel reward is: -2.5966997390537094\n","model saved to models/2024-05-06_17-05-15/q_network_ep_1416.pth\n","\n","End of episode 1417, totel reward is: -1.2019167721979156\n","model saved to models/2024-05-06_17-05-16/q_network_ep_1417.pth\n","\n","End of episode 1418, totel reward is: -1.1945282157877555\n","model saved to models/2024-05-06_17-05-18/q_network_ep_1418.pth\n","\n","End of episode 1419, totel reward is: -0.9361766124660984\n","model saved to models/2024-05-06_17-05-19/q_network_ep_1419.pth\n","\n","End of episode 1420, totel reward is: -1.2640086813742244\n","model saved to models/2024-05-06_17-05-20/q_network_ep_1420.pth\n","\n","End of episode 1421, totel reward is: -6.165635701468593\n","End of episode 1422, totel reward is: -1.270230837954868\n","model saved to models/2024-05-06_17-05-23/q_network_ep_1422.pth\n","\n","End of episode 1423, totel reward is: -7.053938173578511\n","End of episode 1424, totel reward is: -0.8133025722093451\n","model saved to models/2024-05-06_17-05-26/q_network_ep_1424.pth\n","\n","End of episode 1425, totel reward is: -1.6165230510373738\n","model saved to models/2024-05-06_17-05-27/q_network_ep_1425.pth\n","\n","End of episode 1426, totel reward is: -4.386195061159176\n","model saved to models/2024-05-06_17-05-28/q_network_ep_1426.pth\n","\n","End of episode 1427, totel reward is: -3.8119928003959926\n","model saved to models/2024-05-06_17-05-29/q_network_ep_1427.pth\n","\n","End of episode 1428, totel reward is: -4.25181959157525\n","model saved to models/2024-05-06_17-05-31/q_network_ep_1428.pth\n","\n","End of episode 1429, totel reward is: -2.8954513683817407\n","model saved to models/2024-05-06_17-05-32/q_network_ep_1429.pth\n","\n","End of episode 1430, totel reward is: -1.8794821455005688\n","model saved to models/2024-05-06_17-05-33/q_network_ep_1430.pth\n","\n","End of episode 1431, totel reward is: -0.5825751134917406\n","model saved to models/2024-05-06_17-05-35/q_network_ep_1431.pth\n","\n","End of episode 1432, totel reward is: -0.601075233778196\n","model saved to models/2024-05-06_17-05-36/q_network_ep_1432.pth\n","\n","End of episode 1433, totel reward is: -1.5707095467006313\n","model saved to models/2024-05-06_17-05-38/q_network_ep_1433.pth\n","\n","End of episode 1434, totel reward is: -2.905138302354344\n","model saved to models/2024-05-06_17-05-39/q_network_ep_1434.pth\n","\n","End of episode 1435, totel reward is: -1.2644822195766188\n","model saved to models/2024-05-06_17-05-40/q_network_ep_1435.pth\n","\n","End of episode 1436, totel reward is: -0.9243699712194723\n","model saved to models/2024-05-06_17-05-41/q_network_ep_1436.pth\n","\n","End of episode 1437, totel reward is: -6.090125898863547\n","End of episode 1438, totel reward is: -4.779204037843901\n","model saved to models/2024-05-06_17-05-44/q_network_ep_1438.pth\n","\n","End of episode 1439, totel reward is: -1.1058761131503518\n","model saved to models/2024-05-06_17-05-45/q_network_ep_1439.pth\n","\n","End of episode 1440, totel reward is: -3.773277667493844\n","model saved to models/2024-05-06_17-05-46/q_network_ep_1440.pth\n","\n","End of episode 1441, totel reward is: -0.859994154514683\n","model saved to models/2024-05-06_17-05-48/q_network_ep_1441.pth\n","\n","End of episode 1442, totel reward is: -2.714192359733771\n","model saved to models/2024-05-06_17-05-49/q_network_ep_1442.pth\n","\n","End of episode 1443, totel reward is: -1.4158713430633765\n","model saved to models/2024-05-06_17-05-51/q_network_ep_1443.pth\n","\n","End of episode 1444, totel reward is: -2.234055029018462\n","model saved to models/2024-05-06_17-05-52/q_network_ep_1444.pth\n","\n","End of episode 1445, totel reward is: -1.8040704018273508\n","model saved to models/2024-05-06_17-05-53/q_network_ep_1445.pth\n","\n","End of episode 1446, totel reward is: -3.243171034031885\n","model saved to models/2024-05-06_17-05-54/q_network_ep_1446.pth\n","\n","End of episode 1447, totel reward is: -8.3363976209094\n","End of episode 1448, totel reward is: -2.4294645630965896\n","model saved to models/2024-05-06_17-05-57/q_network_ep_1448.pth\n","\n","End of episode 1449, totel reward is: -2.2514257622588287\n","model saved to models/2024-05-06_17-05-58/q_network_ep_1449.pth\n","\n","End of episode 1450, totel reward is: -1.8398430673664918\n","model saved to models/2024-05-06_17-05-59/q_network_ep_1450.pth\n","\n","End of episode 1451, totel reward is: -1.4105408317415007\n","model saved to models/2024-05-06_17-06-01/q_network_ep_1451.pth\n","\n","End of episode 1452, totel reward is: -11.853911405110273\n","End of episode 1453, totel reward is: -2.5006850756251575\n","model saved to models/2024-05-06_17-06-04/q_network_ep_1453.pth\n","\n","End of episode 1454, totel reward is: -4.669754440926196\n","model saved to models/2024-05-06_17-06-05/q_network_ep_1454.pth\n","\n","End of episode 1455, totel reward is: -0.8416820322700633\n","model saved to models/2024-05-06_17-06-06/q_network_ep_1455.pth\n","\n","End of episode 1456, totel reward is: -2.727037933014828\n","model saved to models/2024-05-06_17-06-07/q_network_ep_1456.pth\n","\n","End of episode 1457, totel reward is: -1.0743366659983635\n","model saved to models/2024-05-06_17-06-08/q_network_ep_1457.pth\n","\n","End of episode 1458, totel reward is: -3.517864992065031\n","model saved to models/2024-05-06_17-06-10/q_network_ep_1458.pth\n","\n","End of episode 1459, totel reward is: -7.6825743824862816\n","End of episode 1460, totel reward is: -1.8947601118190027\n","model saved to models/2024-05-06_17-06-12/q_network_ep_1460.pth\n","\n","End of episode 1461, totel reward is: -0.3769161617088836\n","model saved to models/2024-05-06_17-06-14/q_network_ep_1461.pth\n","\n","End of episode 1462, totel reward is: -1.6020346997682366\n","model saved to models/2024-05-06_17-06-15/q_network_ep_1462.pth\n","\n","End of episode 1463, totel reward is: -3.638086477135183\n","model saved to models/2024-05-06_17-06-16/q_network_ep_1463.pth\n","\n","End of episode 1464, totel reward is: -4.531253599242444\n","model saved to models/2024-05-06_17-06-18/q_network_ep_1464.pth\n","\n","End of episode 1465, totel reward is: -1.9860146008528214\n","model saved to models/2024-05-06_17-06-19/q_network_ep_1465.pth\n","\n","End of episode 1466, totel reward is: -4.5320568038374365\n","model saved to models/2024-05-06_17-06-20/q_network_ep_1466.pth\n","\n","End of episode 1467, totel reward is: -1.6052195533765024\n","model saved to models/2024-05-06_17-06-21/q_network_ep_1467.pth\n","\n","End of episode 1468, totel reward is: -0.6003841500348046\n","model saved to models/2024-05-06_17-06-23/q_network_ep_1468.pth\n","\n","End of episode 1469, totel reward is: -5.447988294747521\n","End of episode 1470, totel reward is: -2.8040723940901366\n","model saved to models/2024-05-06_17-06-26/q_network_ep_1470.pth\n","\n","End of episode 1471, totel reward is: -4.735796842258544\n","model saved to models/2024-05-06_17-06-27/q_network_ep_1471.pth\n","\n","End of episode 1472, totel reward is: -1.6243896904123731\n","model saved to models/2024-05-06_17-06-28/q_network_ep_1472.pth\n","\n","End of episode 1473, totel reward is: -1.2472602773724908\n","model saved to models/2024-05-06_17-06-29/q_network_ep_1473.pth\n","\n","End of episode 1474, totel reward is: -6.680193334945911\n","End of episode 1475, totel reward is: -0.8264873863699636\n","model saved to models/2024-05-06_17-06-32/q_network_ep_1475.pth\n","\n","End of episode 1476, totel reward is: -5.269363387665136\n","End of episode 1477, totel reward is: -1.4769406135485459\n","model saved to models/2024-05-06_17-06-34/q_network_ep_1477.pth\n","\n","End of episode 1478, totel reward is: -0.4702677330202422\n","model saved to models/2024-05-06_17-06-36/q_network_ep_1478.pth\n","\n","End of episode 1479, totel reward is: -119.1554914975395\n","End of episode 1480, totel reward is: -1.685836158948766\n","model saved to models/2024-05-06_17-06-39/q_network_ep_1480.pth\n","\n","End of episode 1481, totel reward is: -1.4920785452476524\n","model saved to models/2024-05-06_17-06-40/q_network_ep_1481.pth\n","\n","End of episode 1482, totel reward is: -1.583805377086998\n","model saved to models/2024-05-06_17-06-41/q_network_ep_1482.pth\n","\n","End of episode 1483, totel reward is: -1.4459591809623955\n","model saved to models/2024-05-06_17-06-42/q_network_ep_1483.pth\n","\n","End of episode 1484, totel reward is: -2.6297710277968136\n","model saved to models/2024-05-06_17-06-44/q_network_ep_1484.pth\n","\n","End of episode 1485, totel reward is: -1.0804620624898107\n","model saved to models/2024-05-06_17-06-45/q_network_ep_1485.pth\n","\n","End of episode 1486, totel reward is: -5.5508609479637085\n","End of episode 1487, totel reward is: -1.0330382437836383\n","model saved to models/2024-05-06_17-06-47/q_network_ep_1487.pth\n","\n","End of episode 1488, totel reward is: -1.8982695909181584\n","model saved to models/2024-05-06_17-06-48/q_network_ep_1488.pth\n","\n","End of episode 1489, totel reward is: -1.9623859530674659\n","model saved to models/2024-05-06_17-06-50/q_network_ep_1489.pth\n","\n","End of episode 1490, totel reward is: -1.988055571663308\n","model saved to models/2024-05-06_17-06-52/q_network_ep_1490.pth\n","\n","End of episode 1491, totel reward is: -0.9829440020883059\n","model saved to models/2024-05-06_17-06-53/q_network_ep_1491.pth\n","\n","End of episode 1492, totel reward is: -0.38716928361986636\n","model saved to models/2024-05-06_17-06-54/q_network_ep_1492.pth\n","\n","End of episode 1493, totel reward is: -1.0040015612592845\n","model saved to models/2024-05-06_17-06-55/q_network_ep_1493.pth\n","\n","End of episode 1494, totel reward is: -4.162598561065998\n","model saved to models/2024-05-06_17-06-57/q_network_ep_1494.pth\n","\n","End of episode 1495, totel reward is: -3.3049162356812323\n","model saved to models/2024-05-06_17-06-58/q_network_ep_1495.pth\n","\n","End of episode 1496, totel reward is: -3.7260056246123163\n","model saved to models/2024-05-06_17-06-59/q_network_ep_1496.pth\n","\n","End of episode 1497, totel reward is: -4.620813789409785\n","model saved to models/2024-05-06_17-07-00/q_network_ep_1497.pth\n","\n","End of episode 1498, totel reward is: -5.9336452544312515\n","End of episode 1499, totel reward is: -8.808564095216724\n","now all models have finished training\n","model tested: models/2024-05-06_16-52-42/q_network_ep_0802.pth\n","\n","overall performance: -48.92554569567854\n","\n","\n","model tested: models/2024-05-06_16-52-43/q_network_ep_0803.pth\n","\n","overall performance: -4.608844118399207\n","\n","\n","model tested: models/2024-05-06_16-52-44/q_network_ep_0804.pth\n","\n","overall performance: -4.816905381920824\n","\n","\n","model tested: models/2024-05-06_16-52-46/q_network_ep_0806.pth\n","\n","overall performance: -3.706846879412473\n","\n","\n","model tested: models/2024-05-06_16-52-47/q_network_ep_0807.pth\n","\n","overall performance: -4.4679191282334365\n","\n","\n","model tested: models/2024-05-06_16-52-49/q_network_ep_0809.pth\n","\n","overall performance: -4.658493979247326\n","\n","\n","model tested: models/2024-05-06_16-52-52/q_network_ep_0811.pth\n","\n","overall performance: -5.478458940007458\n","\n","\n","model tested: models/2024-05-06_16-52-53/q_network_ep_0812.pth\n","\n","overall performance: -6.289659429024095\n","\n","\n","model tested: models/2024-05-06_16-52-54/q_network_ep_0813.pth\n","\n","overall performance: -3.9580910214858362\n","\n","\n","model tested: models/2024-05-06_16-52-55/q_network_ep_0814.pth\n","\n","overall performance: -11.807531921349344\n","\n","\n","model tested: models/2024-05-06_16-52-58/q_network_ep_0816.pth\n","\n","overall performance: -3.800521143172498\n","\n","\n","model tested: models/2024-05-06_16-52-59/q_network_ep_0817.pth\n","\n","overall performance: -4.347011241475153\n","\n","\n","model tested: models/2024-05-06_16-53-00/q_network_ep_0818.pth\n","\n","overall performance: -4.014602407789786\n","\n","\n","model tested: models/2024-05-06_16-53-02/q_network_ep_0820.pth\n","\n","overall performance: -5.2753148992377605\n","\n","\n","model tested: models/2024-05-06_16-53-05/q_network_ep_0822.pth\n","\n","overall performance: -15.733842421765956\n","\n","\n","model tested: models/2024-05-06_16-53-06/q_network_ep_0823.pth\n","\n","overall performance: -71.59568455592323\n","\n","\n","model tested: models/2024-05-06_16-53-08/q_network_ep_0825.pth\n","\n","overall performance: -3.002315680977598\n","\n","\n","model tested: models/2024-05-06_16-53-10/q_network_ep_0827.pth\n","\n","overall performance: -25.80536086746028\n","\n","\n","model tested: models/2024-05-06_16-53-11/q_network_ep_0828.pth\n","\n","overall performance: -3.821614716597798\n","\n","\n","model tested: models/2024-05-06_16-53-12/q_network_ep_0829.pth\n","\n","overall performance: -4.986802692731644\n","\n","\n","model tested: models/2024-05-06_16-53-13/q_network_ep_0830.pth\n","\n","overall performance: -3.6140662138646436\n","\n","\n","model tested: models/2024-05-06_16-53-14/q_network_ep_0831.pth\n","\n","overall performance: -24.563405503577023\n","\n","\n","model tested: models/2024-05-06_16-53-16/q_network_ep_0832.pth\n","\n","overall performance: -3.8165326711678467\n","\n","\n","model tested: models/2024-05-06_16-53-17/q_network_ep_0833.pth\n","\n","overall performance: -5.126517601941896\n","\n","\n","model tested: models/2024-05-06_16-53-19/q_network_ep_0835.pth\n","\n","overall performance: -5.6122767686023325\n","\n","\n","model tested: models/2024-05-06_16-53-20/q_network_ep_0836.pth\n","\n","overall performance: -3.148772214918116\n","\n","\n","model tested: models/2024-05-06_16-53-21/q_network_ep_0837.pth\n","\n","overall performance: -3.8216013358286616\n","\n","\n","model tested: models/2024-05-06_16-53-24/q_network_ep_0839.pth\n","\n","overall performance: -3.5612158894889383\n","\n","\n","model tested: models/2024-05-06_16-53-25/q_network_ep_0840.pth\n","\n","overall performance: -76.17428521783539\n","\n","\n","model tested: models/2024-05-06_16-53-26/q_network_ep_0841.pth\n","\n","overall performance: -2.9785008250068636\n","\n","\n","model tested: models/2024-05-06_16-53-27/q_network_ep_0842.pth\n","\n","overall performance: -2.7917979498089522\n","\n","\n","model tested: models/2024-05-06_16-53-31/q_network_ep_0845.pth\n","\n","overall performance: -2.80574205881205\n","\n","\n","model tested: models/2024-05-06_16-53-32/q_network_ep_0846.pth\n","\n","overall performance: -3.2386660517493304\n","\n","\n","model tested: models/2024-05-06_16-53-33/q_network_ep_0847.pth\n","\n","overall performance: -3.5120588801573804\n","\n","\n","model tested: models/2024-05-06_16-53-34/q_network_ep_0848.pth\n","\n","overall performance: -3.3108841588987032\n","\n","\n","model tested: models/2024-05-06_16-53-35/q_network_ep_0849.pth\n","\n","overall performance: -3.120068408368046\n","\n","\n","model tested: models/2024-05-06_16-53-36/q_network_ep_0850.pth\n","\n","overall performance: -3.274437440680967\n","\n","\n","model tested: models/2024-05-06_16-53-37/q_network_ep_0851.pth\n","\n","overall performance: -39.02443591369718\n","\n","\n","model tested: models/2024-05-06_16-53-38/q_network_ep_0852.pth\n","\n","overall performance: -3.1067499663708515\n","\n","\n","model tested: models/2024-05-06_16-53-39/q_network_ep_0853.pth\n","\n","overall performance: -2.838281608174018\n","\n","\n","model tested: models/2024-05-06_16-53-41/q_network_ep_0854.pth\n","\n","overall performance: -3.1558938371930045\n","\n","\n","model tested: models/2024-05-06_16-53-42/q_network_ep_0855.pth\n","\n","overall performance: -3.047334820841539\n","\n","\n","model tested: models/2024-05-06_16-53-44/q_network_ep_0857.pth\n","\n","overall performance: -3.619525521173901\n","\n","\n","model tested: models/2024-05-06_16-53-45/q_network_ep_0858.pth\n","\n","overall performance: -98.15676457867735\n","\n","\n","model tested: models/2024-05-06_16-53-46/q_network_ep_0859.pth\n","\n","overall performance: -39.787396206767326\n","\n","\n","model tested: models/2024-05-06_16-53-49/q_network_ep_0861.pth\n","\n","overall performance: -28.049559561588417\n","\n","\n","model tested: models/2024-05-06_16-53-50/q_network_ep_0862.pth\n","\n","overall performance: -97.11465909693494\n","\n","\n","model tested: models/2024-05-06_16-53-51/q_network_ep_0863.pth\n","\n","overall performance: -3.6479497252107054\n","\n","\n","model tested: models/2024-05-06_16-53-52/q_network_ep_0864.pth\n","\n","overall performance: -33.939163857320224\n","\n","\n","model tested: models/2024-05-06_16-53-53/q_network_ep_0865.pth\n","\n","overall performance: -102.06645155350449\n","\n","\n","model tested: models/2024-05-06_16-53-55/q_network_ep_0866.pth\n","\n","overall performance: -92.16713327645074\n","\n","\n","model tested: models/2024-05-06_16-53-56/q_network_ep_0867.pth\n","\n","overall performance: -65.04350064044718\n","\n","\n","model tested: models/2024-05-06_16-53-57/q_network_ep_0868.pth\n","\n","overall performance: -58.1311364658287\n","\n","\n","model tested: models/2024-05-06_16-53-58/q_network_ep_0869.pth\n","\n","overall performance: -47.31526067570681\n","\n","\n","model tested: models/2024-05-06_16-53-59/q_network_ep_0870.pth\n","\n","overall performance: -64.91387756074703\n","\n","\n","model tested: models/2024-05-06_16-54-00/q_network_ep_0871.pth\n","\n","overall performance: -34.25312145091424\n","\n","\n","model tested: models/2024-05-06_16-54-02/q_network_ep_0873.pth\n","\n","overall performance: -55.080930431674936\n","\n","\n","model tested: models/2024-05-06_16-54-03/q_network_ep_0874.pth\n","\n","overall performance: -2.523790903549173\n","\n","\n","model tested: models/2024-05-06_16-54-04/q_network_ep_0875.pth\n","\n","overall performance: -2.5378065640849745\n","\n","\n","model tested: models/2024-05-06_16-54-06/q_network_ep_0876.pth\n","\n","overall performance: -2.8800710303559125\n","\n","\n","model tested: models/2024-05-06_16-54-07/q_network_ep_0877.pth\n","\n","overall performance: -2.696819697186258\n","\n","\n","model tested: models/2024-05-06_16-54-08/q_network_ep_0878.pth\n","\n","overall performance: -3.820203637174969\n","\n","\n","model tested: models/2024-05-06_16-54-09/q_network_ep_0879.pth\n","\n","overall performance: -2.9380530568911594\n","\n","\n","model tested: models/2024-05-06_16-54-12/q_network_ep_0881.pth\n","\n","overall performance: -2.7817245849640075\n","\n","\n","model tested: models/2024-05-06_16-54-14/q_network_ep_0883.pth\n","\n","overall performance: -44.0204060857646\n","\n","\n","model tested: models/2024-05-06_16-54-15/q_network_ep_0884.pth\n","\n","overall performance: -52.84995191150334\n","\n","\n","model tested: models/2024-05-06_16-54-16/q_network_ep_0885.pth\n","\n","overall performance: -2.842862753669965\n","\n","\n","model tested: models/2024-05-06_16-54-18/q_network_ep_0887.pth\n","\n","overall performance: -2.4252504595708024\n","\n","\n","model tested: models/2024-05-06_16-54-20/q_network_ep_0888.pth\n","\n","overall performance: -2.2675402602744983\n","\n","\n","model tested: models/2024-05-06_16-54-21/q_network_ep_0889.pth\n","\n","overall performance: -2.328994256831669\n","\n","\n","model tested: models/2024-05-06_16-54-22/q_network_ep_0890.pth\n","\n","overall performance: -43.064514249170514\n","\n","\n","model tested: models/2024-05-06_16-54-23/q_network_ep_0891.pth\n","\n","overall performance: -105.11668794494778\n","\n","\n","model tested: models/2024-05-06_16-54-24/q_network_ep_0892.pth\n","\n","overall performance: -3.675092522567111\n","\n","\n","model tested: models/2024-05-06_16-54-25/q_network_ep_0893.pth\n","\n","overall performance: -4.004219128708244\n","\n","\n","model tested: models/2024-05-06_16-54-26/q_network_ep_0894.pth\n","\n","overall performance: -2.7160908976129816\n","\n","\n","model tested: models/2024-05-06_16-54-27/q_network_ep_0895.pth\n","\n","overall performance: -48.70795730274521\n","\n","\n","model tested: models/2024-05-06_16-54-30/q_network_ep_0897.pth\n","\n","overall performance: -99.40804154580452\n","\n","\n","model tested: models/2024-05-06_16-54-31/q_network_ep_0898.pth\n","\n","overall performance: -45.5746553697619\n","\n","\n","model tested: models/2024-05-06_16-54-32/q_network_ep_0899.pth\n","\n","overall performance: -103.03966856958182\n","\n","\n","model tested: models/2024-05-06_16-54-34/q_network_ep_0901.pth\n","\n","overall performance: -118.93673635609176\n","\n","\n","model tested: models/2024-05-06_16-54-35/q_network_ep_0902.pth\n","\n","overall performance: -61.144433597283395\n","\n","\n","model tested: models/2024-05-06_16-54-36/q_network_ep_0903.pth\n","\n","overall performance: -120.05439311046712\n","\n","\n","model tested: models/2024-05-06_16-54-38/q_network_ep_0904.pth\n","\n","overall performance: -104.7852689977112\n","\n","\n","model tested: models/2024-05-06_16-54-39/q_network_ep_0905.pth\n","\n","overall performance: -62.44817598309046\n","\n","\n","model tested: models/2024-05-06_16-54-41/q_network_ep_0907.pth\n","\n","overall performance: -48.41422122727946\n","\n","\n","model tested: models/2024-05-06_16-54-44/q_network_ep_0909.pth\n","\n","overall performance: -41.740741277982615\n","\n","\n","model tested: models/2024-05-06_16-54-45/q_network_ep_0910.pth\n","\n","overall performance: -3.456007236507569\n","\n","\n","model tested: models/2024-05-06_16-54-46/q_network_ep_0911.pth\n","\n","overall performance: -9.07366224238287\n","\n","\n","model tested: models/2024-05-06_16-54-48/q_network_ep_0913.pth\n","\n","overall performance: -8.701860304575776\n","\n","\n","model tested: models/2024-05-06_16-54-49/q_network_ep_0914.pth\n","\n","overall performance: -71.54301480394165\n","\n","\n","model tested: models/2024-05-06_16-54-50/q_network_ep_0915.pth\n","\n","overall performance: -46.69159174811555\n","\n","\n","model tested: models/2024-05-06_16-54-51/q_network_ep_0916.pth\n","\n","overall performance: -58.686960408524854\n","\n","\n","model tested: models/2024-05-06_16-54-53/q_network_ep_0918.pth\n","\n","overall performance: -14.436202043250038\n","\n","\n","model tested: models/2024-05-06_16-54-56/q_network_ep_0920.pth\n","\n","overall performance: -27.801322087961495\n","\n","\n","model tested: models/2024-05-06_16-54-57/q_network_ep_0921.pth\n","\n","overall performance: -32.78591317109048\n","\n","\n","model tested: models/2024-05-06_16-54-58/q_network_ep_0922.pth\n","\n","overall performance: -66.27672068774204\n","\n","\n","model tested: models/2024-05-06_16-55-00/q_network_ep_0924.pth\n","\n","overall performance: -29.205923773506633\n","\n","\n","model tested: models/2024-05-06_16-55-03/q_network_ep_0926.pth\n","\n","overall performance: -7.617255300375734\n","\n","\n","model tested: models/2024-05-06_16-55-04/q_network_ep_0927.pth\n","\n","overall performance: -43.86769512741736\n","\n","\n","model tested: models/2024-05-06_16-55-05/q_network_ep_0928.pth\n","\n","overall performance: -136.59919604079505\n","\n","\n","model tested: models/2024-05-06_16-55-06/q_network_ep_0929.pth\n","\n","overall performance: -30.7480755451228\n","\n","\n","model tested: models/2024-05-06_16-55-10/q_network_ep_0932.pth\n","\n","overall performance: -6.913568965616697\n","\n","\n","model tested: models/2024-05-06_16-55-11/q_network_ep_0933.pth\n","\n","overall performance: -6.04049813810664\n","\n","\n","model tested: models/2024-05-06_16-55-16/q_network_ep_0938.pth\n","\n","overall performance: -9.271882233217882\n","\n","\n","model tested: models/2024-05-06_16-55-17/q_network_ep_0939.pth\n","\n","overall performance: -5.52451635872871\n","\n","\n","model tested: models/2024-05-06_16-55-19/q_network_ep_0941.pth\n","\n","overall performance: -9.294922068265969\n","\n","\n","model tested: models/2024-05-06_16-55-23/q_network_ep_0944.pth\n","\n","overall performance: -4.760382293039456\n","\n","\n","model tested: models/2024-05-06_16-55-24/q_network_ep_0945.pth\n","\n","overall performance: -41.44958434824575\n","\n","\n","model tested: models/2024-05-06_16-55-25/q_network_ep_0946.pth\n","\n","overall performance: -83.58596183916102\n","\n","\n","model tested: models/2024-05-06_16-55-28/q_network_ep_0949.pth\n","\n","overall performance: -90.46677259729654\n","\n","\n","model tested: models/2024-05-06_16-55-30/q_network_ep_0951.pth\n","\n","overall performance: -51.27412685437984\n","\n","\n","model tested: models/2024-05-06_16-55-32/q_network_ep_0952.pth\n","\n","overall performance: -28.909229226858592\n","\n","\n","model tested: models/2024-05-06_16-55-34/q_network_ep_0954.pth\n","\n","overall performance: -18.420227841646344\n","\n","\n","model tested: models/2024-05-06_16-55-35/q_network_ep_0955.pth\n","\n","overall performance: -49.984500984111456\n","\n","\n","model tested: models/2024-05-06_16-55-38/q_network_ep_0958.pth\n","\n","overall performance: -42.01971468500878\n","\n","\n","model tested: models/2024-05-06_16-55-44/q_network_ep_0963.pth\n","\n","overall performance: -18.574491986109575\n","\n","\n","model tested: models/2024-05-06_16-55-45/q_network_ep_0964.pth\n","\n","overall performance: -25.50911435051976\n","\n","\n","model tested: models/2024-05-06_16-55-49/q_network_ep_0967.pth\n","\n","overall performance: -6.927975478681589\n","\n","\n","model tested: models/2024-05-06_16-55-50/q_network_ep_0968.pth\n","\n","overall performance: -3.985472584716093\n","\n","\n","model tested: models/2024-05-06_16-55-51/q_network_ep_0969.pth\n","\n","overall performance: -8.648832825122033\n","\n","\n","model tested: models/2024-05-06_16-55-52/q_network_ep_0970.pth\n","\n","overall performance: -5.341358449048695\n","\n","\n","model tested: models/2024-05-06_16-55-53/q_network_ep_0971.pth\n","\n","overall performance: -6.202754824945095\n","\n","\n","model tested: models/2024-05-06_16-55-55/q_network_ep_0973.pth\n","\n","overall performance: -7.9182414193501245\n","\n","\n","model tested: models/2024-05-06_16-55-59/q_network_ep_0976.pth\n","\n","overall performance: -6.612450254377964\n","\n","\n","model tested: models/2024-05-06_16-56-01/q_network_ep_0978.pth\n","\n","overall performance: -4.024568086714103\n","\n","\n","model tested: models/2024-05-06_16-56-03/q_network_ep_0980.pth\n","\n","overall performance: -5.660451235808382\n","\n","\n","model tested: models/2024-05-06_16-56-04/q_network_ep_0981.pth\n","\n","overall performance: -23.062813527444916\n","\n","\n","model tested: models/2024-05-06_16-56-06/q_network_ep_0983.pth\n","\n","overall performance: -28.109512094591206\n","\n","\n","model tested: models/2024-05-06_16-56-07/q_network_ep_0984.pth\n","\n","overall performance: -5.6564255913578005\n","\n","\n","model tested: models/2024-05-06_16-56-13/q_network_ep_0989.pth\n","\n","overall performance: -3.845528585892963\n","\n","\n","model tested: models/2024-05-06_16-56-15/q_network_ep_0991.pth\n","\n","overall performance: -3.7545006627520534\n","\n","\n","model tested: models/2024-05-06_16-56-16/q_network_ep_0992.pth\n","\n","overall performance: -4.25335315249181\n","\n","\n","model tested: models/2024-05-06_16-56-17/q_network_ep_0993.pth\n","\n","overall performance: -3.9131170405779394\n","\n","\n","model tested: models/2024-05-06_16-56-18/q_network_ep_0994.pth\n","\n","overall performance: -3.5909520658821483\n","\n","\n","model tested: models/2024-05-06_16-56-21/q_network_ep_0996.pth\n","\n","overall performance: -3.430961325078767\n","\n","\n","model tested: models/2024-05-06_16-56-22/q_network_ep_0997.pth\n","\n","overall performance: -3.3043260592625217\n","\n","\n","model tested: models/2024-05-06_16-56-24/q_network_ep_0998.pth\n","\n","overall performance: -3.757116465190942\n","\n","\n","model tested: models/2024-05-06_16-56-25/q_network_ep_0999.pth\n","\n","overall performance: -2.787807149987197\n","\n","\n","model tested: models/2024-05-06_16-56-26/q_network_ep_1000.pth\n","\n","overall performance: -2.8452299911758536\n","\n","\n","model tested: models/2024-05-06_16-56-27/q_network_ep_1001.pth\n","\n","overall performance: -3.714244190108913\n","\n","\n","model tested: models/2024-05-06_16-56-29/q_network_ep_1003.pth\n","\n","overall performance: -3.0153430167116477\n","\n","\n","model tested: models/2024-05-06_16-56-31/q_network_ep_1005.pth\n","\n","overall performance: -3.3009621968692775\n","\n","\n","model tested: models/2024-05-06_16-56-32/q_network_ep_1006.pth\n","\n","overall performance: -2.941899998917078\n","\n","\n","model tested: models/2024-05-06_16-56-33/q_network_ep_1007.pth\n","\n","overall performance: -3.1303056187718115\n","\n","\n","model tested: models/2024-05-06_16-56-35/q_network_ep_1008.pth\n","\n","overall performance: -2.9158116569527666\n","\n","\n","model tested: models/2024-05-06_16-56-36/q_network_ep_1009.pth\n","\n","overall performance: -2.9939168620002787\n","\n","\n","model tested: models/2024-05-06_16-56-39/q_network_ep_1012.pth\n","\n","overall performance: -2.7821861597056987\n","\n","\n","model tested: models/2024-05-06_16-56-41/q_network_ep_1014.pth\n","\n","overall performance: -3.0540059228406014\n","\n","\n","model tested: models/2024-05-06_16-56-43/q_network_ep_1015.pth\n","\n","overall performance: -2.751797749730693\n","\n","\n","model tested: models/2024-05-06_16-56-46/q_network_ep_1018.pth\n","\n","overall performance: -2.550323293771718\n","\n","\n","model tested: models/2024-05-06_16-56-49/q_network_ep_1020.pth\n","\n","overall performance: -2.5345687756418833\n","\n","\n","model tested: models/2024-05-06_16-56-51/q_network_ep_1022.pth\n","\n","overall performance: -2.643312180609713\n","\n","\n","model tested: models/2024-05-06_16-56-53/q_network_ep_1024.pth\n","\n","overall performance: -2.9049225146501874\n","\n","\n","model tested: models/2024-05-06_16-56-54/q_network_ep_1025.pth\n","\n","overall performance: -2.8845043420567036\n","\n","\n","model tested: models/2024-05-06_16-56-55/q_network_ep_1026.pth\n","\n","overall performance: -2.6209428801102423\n","\n","\n","model tested: models/2024-05-06_16-56-56/q_network_ep_1027.pth\n","\n","overall performance: -2.5658004688165224\n","\n","\n","model tested: models/2024-05-06_16-57-00/q_network_ep_1030.pth\n","\n","overall performance: -2.5261026017286072\n","\n","\n","model tested: models/2024-05-06_16-57-01/q_network_ep_1031.pth\n","\n","overall performance: -3.208971623227599\n","\n","\n","model tested: models/2024-05-06_16-57-02/q_network_ep_1032.pth\n","\n","overall performance: -2.5371647391267844\n","\n","\n","model tested: models/2024-05-06_16-57-03/q_network_ep_1033.pth\n","\n","overall performance: -2.4450323692791907\n","\n","\n","model tested: models/2024-05-06_16-57-04/q_network_ep_1034.pth\n","\n","overall performance: -2.3733011769548917\n","\n","\n","model tested: models/2024-05-06_16-57-05/q_network_ep_1035.pth\n","\n","overall performance: -3.649842364420146\n","\n","\n","model tested: models/2024-05-06_16-57-08/q_network_ep_1037.pth\n","\n","overall performance: -3.6251574718793527\n","\n","\n","model tested: models/2024-05-06_16-57-09/q_network_ep_1038.pth\n","\n","overall performance: -3.4937475355396614\n","\n","\n","model tested: models/2024-05-06_16-57-10/q_network_ep_1039.pth\n","\n","overall performance: -3.1308375227046894\n","\n","\n","model tested: models/2024-05-06_16-57-11/q_network_ep_1040.pth\n","\n","overall performance: -20.683774536117294\n","\n","\n","model tested: models/2024-05-06_16-57-13/q_network_ep_1041.pth\n","\n","overall performance: -22.994130621671097\n","\n","\n","model tested: models/2024-05-06_16-57-14/q_network_ep_1042.pth\n","\n","overall performance: -24.37620281952149\n","\n","\n","model tested: models/2024-05-06_16-57-16/q_network_ep_1043.pth\n","\n","overall performance: -18.37726183588897\n","\n","\n","model tested: models/2024-05-06_16-57-18/q_network_ep_1045.pth\n","\n","overall performance: -2.507761757465387\n","\n","\n","model tested: models/2024-05-06_16-57-19/q_network_ep_1046.pth\n","\n","overall performance: -34.47225465233266\n","\n","\n","model tested: models/2024-05-06_16-57-20/q_network_ep_1047.pth\n","\n","overall performance: -2.4038534577158024\n","\n","\n","model tested: models/2024-05-06_16-57-21/q_network_ep_1048.pth\n","\n","overall performance: -11.784357353820994\n","\n","\n","model tested: models/2024-05-06_16-57-23/q_network_ep_1049.pth\n","\n","overall performance: -2.6060251396784566\n","\n","\n","model tested: models/2024-05-06_16-57-24/q_network_ep_1050.pth\n","\n","overall performance: -13.389085775052013\n","\n","\n","model tested: models/2024-05-06_16-57-27/q_network_ep_1052.pth\n","\n","overall performance: -36.337386406244725\n","\n","\n","model tested: models/2024-05-06_16-57-29/q_network_ep_1053.pth\n","\n","overall performance: -47.812647045490316\n","\n","\n","model tested: models/2024-05-06_16-57-30/q_network_ep_1054.pth\n","\n","overall performance: -2.2292882191883043\n","\n","\n","model tested: models/2024-05-06_16-57-33/q_network_ep_1057.pth\n","\n","overall performance: -2.23332966822928\n","\n","\n","model tested: models/2024-05-06_16-57-34/q_network_ep_1058.pth\n","\n","overall performance: -2.2725977969827307\n","\n","\n","model tested: models/2024-05-06_16-57-37/q_network_ep_1060.pth\n","\n","overall performance: -2.2832559930678515\n","\n","\n","model tested: models/2024-05-06_16-57-39/q_network_ep_1061.pth\n","\n","overall performance: -39.4104755468821\n","\n","\n","model tested: models/2024-05-06_16-57-40/q_network_ep_1062.pth\n","\n","overall performance: -34.8284067069731\n","\n","\n","model tested: models/2024-05-06_16-57-41/q_network_ep_1063.pth\n","\n","overall performance: -2.5544220936979656\n","\n","\n","model tested: models/2024-05-06_16-57-42/q_network_ep_1064.pth\n","\n","overall performance: -27.866778196184736\n","\n","\n","model tested: models/2024-05-06_16-57-43/q_network_ep_1065.pth\n","\n","overall performance: -2.193178060563095\n","\n","\n","model tested: models/2024-05-06_16-57-46/q_network_ep_1067.pth\n","\n","overall performance: -2.357136319126311\n","\n","\n","model tested: models/2024-05-06_16-57-47/q_network_ep_1068.pth\n","\n","overall performance: -2.4857703463940153\n","\n","\n","model tested: models/2024-05-06_16-57-48/q_network_ep_1069.pth\n","\n","overall performance: -2.34166420571407\n","\n","\n","model tested: models/2024-05-06_16-57-50/q_network_ep_1070.pth\n","\n","overall performance: -27.671444338194334\n","\n","\n","model tested: models/2024-05-06_16-57-51/q_network_ep_1071.pth\n","\n","overall performance: -2.4448783207384537\n","\n","\n","model tested: models/2024-05-06_16-57-52/q_network_ep_1072.pth\n","\n","overall performance: -32.54623480172529\n","\n","\n","model tested: models/2024-05-06_16-57-56/q_network_ep_1074.pth\n","\n","overall performance: -2.5463161649377875\n","\n","\n","model tested: models/2024-05-06_16-57-58/q_network_ep_1076.pth\n","\n","overall performance: -2.9337492273123496\n","\n","\n","model tested: models/2024-05-06_16-58-00/q_network_ep_1077.pth\n","\n","overall performance: -2.382726337981246\n","\n","\n","model tested: models/2024-05-06_16-58-01/q_network_ep_1078.pth\n","\n","overall performance: -36.12215769542654\n","\n","\n","model tested: models/2024-05-06_16-58-03/q_network_ep_1079.pth\n","\n","overall performance: -2.3554565311553626\n","\n","\n","model tested: models/2024-05-06_16-58-04/q_network_ep_1080.pth\n","\n","overall performance: -2.1819683240297314\n","\n","\n","model tested: models/2024-05-06_16-58-05/q_network_ep_1081.pth\n","\n","overall performance: -2.5551506131771635\n","\n","\n","model tested: models/2024-05-06_16-58-07/q_network_ep_1082.pth\n","\n","overall performance: -2.358884365456165\n","\n","\n","model tested: models/2024-05-06_16-58-09/q_network_ep_1084.pth\n","\n","overall performance: -2.6959023292849906\n","\n","\n","model tested: models/2024-05-06_16-58-11/q_network_ep_1085.pth\n","\n","overall performance: -3.4715249652333475\n","\n","\n","model tested: models/2024-05-06_16-58-12/q_network_ep_1086.pth\n","\n","overall performance: -3.8243202554102234\n","\n","\n","model tested: models/2024-05-06_16-58-13/q_network_ep_1087.pth\n","\n","overall performance: -32.76190301131156\n","\n","\n","model tested: models/2024-05-06_16-58-15/q_network_ep_1088.pth\n","\n","overall performance: -2.617487878722105\n","\n","\n","model tested: models/2024-05-06_16-58-17/q_network_ep_1089.pth\n","\n","overall performance: -29.29185495920823\n","\n","\n","model tested: models/2024-05-06_16-58-18/q_network_ep_1090.pth\n","\n","overall performance: -29.611919374544158\n","\n","\n","model tested: models/2024-05-06_16-58-20/q_network_ep_1091.pth\n","\n","overall performance: -2.6697755649002035\n","\n","\n","model tested: models/2024-05-06_16-58-21/q_network_ep_1092.pth\n","\n","overall performance: -2.9829686122439347\n","\n","\n","model tested: models/2024-05-06_16-58-24/q_network_ep_1094.pth\n","\n","overall performance: -2.9768458375174967\n","\n","\n","model tested: models/2024-05-06_16-58-25/q_network_ep_1095.pth\n","\n","overall performance: -29.914543089289264\n","\n","\n","model tested: models/2024-05-06_16-58-26/q_network_ep_1096.pth\n","\n","overall performance: -2.7303085319146585\n","\n","\n","model tested: models/2024-05-06_16-58-28/q_network_ep_1097.pth\n","\n","overall performance: -2.9215768318775703\n","\n","\n","model tested: models/2024-05-06_16-58-29/q_network_ep_1098.pth\n","\n","overall performance: -2.3268012973470933\n","\n","\n","model tested: models/2024-05-06_16-58-31/q_network_ep_1099.pth\n","\n","overall performance: -2.5381520902696737\n","\n","\n","model tested: models/2024-05-06_16-58-32/q_network_ep_1100.pth\n","\n","overall performance: -30.521499833228518\n","\n","\n","model tested: models/2024-05-06_16-58-33/q_network_ep_1101.pth\n","\n","overall performance: -3.3335541329901033\n","\n","\n","model tested: models/2024-05-06_16-58-34/q_network_ep_1102.pth\n","\n","overall performance: -24.125540813729273\n","\n","\n","model tested: models/2024-05-06_16-58-35/q_network_ep_1103.pth\n","\n","overall performance: -2.822191339602268\n","\n","\n","model tested: models/2024-05-06_16-58-36/q_network_ep_1104.pth\n","\n","overall performance: -2.79781703581689\n","\n","\n","model tested: models/2024-05-06_16-58-37/q_network_ep_1105.pth\n","\n","overall performance: -2.7905992396480856\n","\n","\n","model tested: models/2024-05-06_16-58-39/q_network_ep_1106.pth\n","\n","overall performance: -7.777444255834506\n","\n","\n","model tested: models/2024-05-06_16-58-41/q_network_ep_1107.pth\n","\n","overall performance: -2.487101865560405\n","\n","\n","model tested: models/2024-05-06_16-58-42/q_network_ep_1108.pth\n","\n","overall performance: -3.061989236889916\n","\n","\n","model tested: models/2024-05-06_16-58-43/q_network_ep_1109.pth\n","\n","overall performance: -49.6540793761564\n","\n","\n","model tested: models/2024-05-06_16-58-44/q_network_ep_1110.pth\n","\n","overall performance: -2.7004300535024406\n","\n","\n","model tested: models/2024-05-06_16-58-46/q_network_ep_1111.pth\n","\n","overall performance: -2.590316723388092\n","\n","\n","model tested: models/2024-05-06_16-58-47/q_network_ep_1112.pth\n","\n","overall performance: -2.9105422277689668\n","\n","\n","model tested: models/2024-05-06_16-58-48/q_network_ep_1113.pth\n","\n","overall performance: -27.444775756423855\n","\n","\n","model tested: models/2024-05-06_16-58-49/q_network_ep_1114.pth\n","\n","overall performance: -2.9148499531533796\n","\n","\n","model tested: models/2024-05-06_16-58-50/q_network_ep_1115.pth\n","\n","overall performance: -2.78473130711604\n","\n","\n","model tested: models/2024-05-06_16-58-52/q_network_ep_1116.pth\n","\n","overall performance: -2.783609278195804\n","\n","\n","model tested: models/2024-05-06_16-58-53/q_network_ep_1117.pth\n","\n","overall performance: -3.1559747217356007\n","\n","\n","model tested: models/2024-05-06_16-58-55/q_network_ep_1118.pth\n","\n","overall performance: -3.5496739985231827\n","\n","\n","model tested: models/2024-05-06_16-58-56/q_network_ep_1119.pth\n","\n","overall performance: -3.325871711704501\n","\n","\n","model tested: models/2024-05-06_16-58-57/q_network_ep_1120.pth\n","\n","overall performance: -2.882453072488066\n","\n","\n","model tested: models/2024-05-06_16-58-58/q_network_ep_1121.pth\n","\n","overall performance: -2.9850307119256962\n","\n","\n","model tested: models/2024-05-06_16-58-59/q_network_ep_1122.pth\n","\n","overall performance: -3.022320175975324\n","\n","\n","model tested: models/2024-05-06_16-59-01/q_network_ep_1123.pth\n","\n","overall performance: -2.7995318384717955\n","\n","\n","model tested: models/2024-05-06_16-59-03/q_network_ep_1125.pth\n","\n","overall performance: -3.0474691301553594\n","\n","\n","model tested: models/2024-05-06_16-59-06/q_network_ep_1127.pth\n","\n","overall performance: -3.278048313977193\n","\n","\n","model tested: models/2024-05-06_16-59-07/q_network_ep_1128.pth\n","\n","overall performance: -6.889963573458059\n","\n","\n","model tested: models/2024-05-06_16-59-08/q_network_ep_1129.pth\n","\n","overall performance: -3.284175571359291\n","\n","\n","model tested: models/2024-05-06_16-59-10/q_network_ep_1130.pth\n","\n","overall performance: -3.6886469934338613\n","\n","\n","model tested: models/2024-05-06_16-59-11/q_network_ep_1131.pth\n","\n","overall performance: -3.4906007903989478\n","\n","\n","model tested: models/2024-05-06_16-59-12/q_network_ep_1132.pth\n","\n","overall performance: -3.1585823720488357\n","\n","\n","model tested: models/2024-05-06_16-59-13/q_network_ep_1133.pth\n","\n","overall performance: -3.695986084324949\n","\n","\n","model tested: models/2024-05-06_16-59-14/q_network_ep_1134.pth\n","\n","overall performance: -31.200245134316937\n","\n","\n","model tested: models/2024-05-06_16-59-15/q_network_ep_1135.pth\n","\n","overall performance: -36.77359070940355\n","\n","\n","model tested: models/2024-05-06_16-59-18/q_network_ep_1137.pth\n","\n","overall performance: -88.66938284434887\n","\n","\n","model tested: models/2024-05-06_16-59-20/q_network_ep_1138.pth\n","\n","overall performance: -74.9369969739071\n","\n","\n","model tested: models/2024-05-06_16-59-21/q_network_ep_1139.pth\n","\n","overall performance: -74.27750720911784\n","\n","\n","model tested: models/2024-05-06_16-59-22/q_network_ep_1140.pth\n","\n","overall performance: -3.011971186990357\n","\n","\n","model tested: models/2024-05-06_16-59-23/q_network_ep_1141.pth\n","\n","overall performance: -37.409489508148354\n","\n","\n","model tested: models/2024-05-06_16-59-24/q_network_ep_1142.pth\n","\n","overall performance: -29.965131797174223\n","\n","\n","model tested: models/2024-05-06_16-59-27/q_network_ep_1144.pth\n","\n","overall performance: -30.112398369716004\n","\n","\n","model tested: models/2024-05-06_16-59-28/q_network_ep_1145.pth\n","\n","overall performance: -6.497581718325796\n","\n","\n","model tested: models/2024-05-06_16-59-34/q_network_ep_1150.pth\n","\n","overall performance: -209.6209214002369\n","\n","\n","model tested: models/2024-05-06_16-59-36/q_network_ep_1151.pth\n","\n","overall performance: -9.870042640468268\n","\n","\n","model tested: models/2024-05-06_16-59-39/q_network_ep_1154.pth\n","\n","overall performance: -10.111676309371541\n","\n","\n","model tested: models/2024-05-06_16-59-40/q_network_ep_1155.pth\n","\n","overall performance: -8.269774444997168\n","\n","\n","model tested: models/2024-05-06_16-59-43/q_network_ep_1157.pth\n","\n","overall performance: -15.70121393935086\n","\n","\n","model tested: models/2024-05-06_16-59-48/q_network_ep_1161.pth\n","\n","overall performance: -55.622102485313825\n","\n","\n","model tested: models/2024-05-06_16-59-50/q_network_ep_1163.pth\n","\n","overall performance: -33.63866141398901\n","\n","\n","model tested: models/2024-05-06_16-59-52/q_network_ep_1165.pth\n","\n","overall performance: -30.470723821974417\n","\n","\n","model tested: models/2024-05-06_16-59-53/q_network_ep_1166.pth\n","\n","overall performance: -40.0839485210585\n","\n","\n","model tested: models/2024-05-06_16-59-57/q_network_ep_1168.pth\n","\n","overall performance: -37.469124458475896\n","\n","\n","model tested: models/2024-05-06_16-59-58/q_network_ep_1169.pth\n","\n","overall performance: -37.548450493252744\n","\n","\n","model tested: models/2024-05-06_17-00-00/q_network_ep_1171.pth\n","\n","overall performance: -5.020873964111608\n","\n","\n","model tested: models/2024-05-06_17-00-02/q_network_ep_1173.pth\n","\n","overall performance: -30.004563692530915\n","\n","\n","model tested: models/2024-05-06_17-00-05/q_network_ep_1175.pth\n","\n","overall performance: -4.981675734085767\n","\n","\n","model tested: models/2024-05-06_17-00-06/q_network_ep_1176.pth\n","\n","overall performance: -4.49185948058418\n","\n","\n","model tested: models/2024-05-06_17-00-07/q_network_ep_1177.pth\n","\n","overall performance: -55.35777521413415\n","\n","\n","model tested: models/2024-05-06_17-00-10/q_network_ep_1179.pth\n","\n","overall performance: -27.727327908843375\n","\n","\n","model tested: models/2024-05-06_17-00-11/q_network_ep_1180.pth\n","\n","overall performance: -4.4802769251417045\n","\n","\n","model tested: models/2024-05-06_17-00-12/q_network_ep_1181.pth\n","\n","overall performance: -5.786832624860175\n","\n","\n","model tested: models/2024-05-06_17-00-14/q_network_ep_1182.pth\n","\n","overall performance: -3.81338061803354\n","\n","\n","model tested: models/2024-05-06_17-00-15/q_network_ep_1183.pth\n","\n","overall performance: -5.222333975689126\n","\n","\n","model tested: models/2024-05-06_17-00-17/q_network_ep_1185.pth\n","\n","overall performance: -5.438122947106661\n","\n","\n","model tested: models/2024-05-06_17-00-19/q_network_ep_1186.pth\n","\n","overall performance: -3.7911684251893605\n","\n","\n","model tested: models/2024-05-06_17-00-20/q_network_ep_1187.pth\n","\n","overall performance: -3.696399523430105\n","\n","\n","model tested: models/2024-05-06_17-00-22/q_network_ep_1188.pth\n","\n","overall performance: -12.879374548987027\n","\n","\n","model tested: models/2024-05-06_17-00-23/q_network_ep_1189.pth\n","\n","overall performance: -3.514554941189438\n","\n","\n","model tested: models/2024-05-06_17-00-26/q_network_ep_1191.pth\n","\n","overall performance: -16.662112611896124\n","\n","\n","model tested: models/2024-05-06_17-00-27/q_network_ep_1192.pth\n","\n","overall performance: -3.977479969146736\n","\n","\n","model tested: models/2024-05-06_17-00-28/q_network_ep_1193.pth\n","\n","overall performance: -3.259331553712015\n","\n","\n","model tested: models/2024-05-06_17-00-29/q_network_ep_1194.pth\n","\n","overall performance: -4.101666601600419\n","\n","\n","model tested: models/2024-05-06_17-00-31/q_network_ep_1196.pth\n","\n","overall performance: -4.100577451070427\n","\n","\n","model tested: models/2024-05-06_17-00-33/q_network_ep_1197.pth\n","\n","overall performance: -11.764395227274658\n","\n","\n","model tested: models/2024-05-06_17-00-35/q_network_ep_1198.pth\n","\n","overall performance: -64.19062011372459\n","\n","\n","model tested: models/2024-05-06_17-00-36/q_network_ep_1199.pth\n","\n","overall performance: -3.3477910508500983\n","\n","\n","model tested: models/2024-05-06_17-00-37/q_network_ep_1200.pth\n","\n","overall performance: -7.924709384564051\n","\n","\n","model tested: models/2024-05-06_17-00-39/q_network_ep_1202.pth\n","\n","overall performance: -2.281543489559743\n","\n","\n","model tested: models/2024-05-06_17-00-41/q_network_ep_1203.pth\n","\n","overall performance: -2.8613449025743187\n","\n","\n","model tested: models/2024-05-06_17-00-42/q_network_ep_1204.pth\n","\n","overall performance: -2.2424130007386784\n","\n","\n","model tested: models/2024-05-06_17-00-43/q_network_ep_1205.pth\n","\n","overall performance: -2.403982333988689\n","\n","\n","model tested: models/2024-05-06_17-00-47/q_network_ep_1208.pth\n","\n","overall performance: -2.968945357604265\n","\n","\n","model tested: models/2024-05-06_17-00-48/q_network_ep_1209.pth\n","\n","overall performance: -4.646659631895094\n","\n","\n","model tested: models/2024-05-06_17-00-50/q_network_ep_1210.pth\n","\n","overall performance: -3.96670273035568\n","\n","\n","model tested: models/2024-05-06_17-00-51/q_network_ep_1211.pth\n","\n","overall performance: -5.17800165078884\n","\n","\n","model tested: models/2024-05-06_17-00-52/q_network_ep_1212.pth\n","\n","overall performance: -4.0387867691727815\n","\n","\n","model tested: models/2024-05-06_17-00-54/q_network_ep_1214.pth\n","\n","overall performance: -3.994604100356413\n","\n","\n","model tested: models/2024-05-06_17-00-56/q_network_ep_1215.pth\n","\n","overall performance: -6.145727301358555\n","\n","\n","model tested: models/2024-05-06_17-00-59/q_network_ep_1217.pth\n","\n","overall performance: -42.01152716753531\n","\n","\n","model tested: models/2024-05-06_17-01-00/q_network_ep_1218.pth\n","\n","overall performance: -3.364058199884633\n","\n","\n","model tested: models/2024-05-06_17-01-01/q_network_ep_1219.pth\n","\n","overall performance: -4.161615382116844\n","\n","\n","model tested: models/2024-05-06_17-01-05/q_network_ep_1222.pth\n","\n","overall performance: -36.57586244134012\n","\n","\n","model tested: models/2024-05-06_17-01-06/q_network_ep_1223.pth\n","\n","overall performance: -45.403793358870416\n","\n","\n","model tested: models/2024-05-06_17-01-08/q_network_ep_1224.pth\n","\n","overall performance: -74.10751653384948\n","\n","\n","model tested: models/2024-05-06_17-01-09/q_network_ep_1225.pth\n","\n","overall performance: -4.999296352814699\n","\n","\n","model tested: models/2024-05-06_17-01-11/q_network_ep_1226.pth\n","\n","overall performance: -12.184277440990197\n","\n","\n","model tested: models/2024-05-06_17-01-12/q_network_ep_1227.pth\n","\n","overall performance: -4.327734994165844\n","\n","\n","model tested: models/2024-05-06_17-01-13/q_network_ep_1228.pth\n","\n","overall performance: -35.29843194600803\n","\n","\n","model tested: models/2024-05-06_17-01-15/q_network_ep_1229.pth\n","\n","overall performance: -4.6588587219069\n","\n","\n","model tested: models/2024-05-06_17-01-17/q_network_ep_1231.pth\n","\n","overall performance: -2.6199433133879793\n","\n","\n","model tested: models/2024-05-06_17-01-18/q_network_ep_1232.pth\n","\n","overall performance: -4.256911175271442\n","\n","\n","model tested: models/2024-05-06_17-01-20/q_network_ep_1233.pth\n","\n","overall performance: -5.141685654457032\n","\n","\n","model tested: models/2024-05-06_17-01-21/q_network_ep_1234.pth\n","\n","overall performance: -44.2398660049926\n","\n","\n","model tested: models/2024-05-06_17-01-22/q_network_ep_1235.pth\n","\n","overall performance: -2.3747205758289476\n","\n","\n","model tested: models/2024-05-06_17-01-24/q_network_ep_1236.pth\n","\n","overall performance: -20.98389705216264\n","\n","\n","model tested: models/2024-05-06_17-01-30/q_network_ep_1241.pth\n","\n","overall performance: -27.187313233758516\n","\n","\n","model tested: models/2024-05-06_17-01-31/q_network_ep_1242.pth\n","\n","overall performance: -8.625972413074777\n","\n","\n","model tested: models/2024-05-06_17-01-32/q_network_ep_1243.pth\n","\n","overall performance: -7.724165174580809\n","\n","\n","model tested: models/2024-05-06_17-01-33/q_network_ep_1244.pth\n","\n","overall performance: -7.79988951987159\n","\n","\n","model tested: models/2024-05-06_17-01-36/q_network_ep_1246.pth\n","\n","overall performance: -4.828883224467549\n","\n","\n","model tested: models/2024-05-06_17-01-38/q_network_ep_1247.pth\n","\n","overall performance: -9.805972273607425\n","\n","\n","model tested: models/2024-05-06_17-01-39/q_network_ep_1248.pth\n","\n","overall performance: -8.981910769736466\n","\n","\n","model tested: models/2024-05-06_17-01-40/q_network_ep_1249.pth\n","\n","overall performance: -9.049148250105041\n","\n","\n","model tested: models/2024-05-06_17-01-41/q_network_ep_1250.pth\n","\n","overall performance: -10.743943970092554\n","\n","\n","model tested: models/2024-05-06_17-01-42/q_network_ep_1251.pth\n","\n","overall performance: -9.163268607525419\n","\n","\n","model tested: models/2024-05-06_17-01-45/q_network_ep_1253.pth\n","\n","overall performance: -14.331983877675176\n","\n","\n","model tested: models/2024-05-06_17-01-46/q_network_ep_1254.pth\n","\n","overall performance: -3.8203790101742343\n","\n","\n","model tested: models/2024-05-06_17-01-50/q_network_ep_1257.pth\n","\n","overall performance: -7.799441167679754\n","\n","\n","model tested: models/2024-05-06_17-01-51/q_network_ep_1258.pth\n","\n","overall performance: -3.06288289123581\n","\n","\n","model tested: models/2024-05-06_17-01-53/q_network_ep_1259.pth\n","\n","overall performance: -3.195389700451667\n","\n","\n","model tested: models/2024-05-06_17-01-54/q_network_ep_1260.pth\n","\n","overall performance: -3.368693702833261\n","\n","\n","model tested: models/2024-05-06_17-01-55/q_network_ep_1261.pth\n","\n","overall performance: -3.1932486592018554\n","\n","\n","model tested: models/2024-05-06_17-01-58/q_network_ep_1263.pth\n","\n","overall performance: -3.233968428388171\n","\n","\n","model tested: models/2024-05-06_17-01-59/q_network_ep_1264.pth\n","\n","overall performance: -3.88118907308696\n","\n","\n","model tested: models/2024-05-06_17-02-02/q_network_ep_1266.pth\n","\n","overall performance: -2.8872570082531395\n","\n","\n","model tested: models/2024-05-06_17-02-03/q_network_ep_1267.pth\n","\n","overall performance: -6.147761978240287\n","\n","\n","model tested: models/2024-05-06_17-02-04/q_network_ep_1268.pth\n","\n","overall performance: -4.245130100347257\n","\n","\n","model tested: models/2024-05-06_17-02-09/q_network_ep_1271.pth\n","\n","overall performance: -2.72134951918145\n","\n","\n","model tested: models/2024-05-06_17-02-11/q_network_ep_1272.pth\n","\n","overall performance: -3.0378219214640834\n","\n","\n","model tested: models/2024-05-06_17-02-12/q_network_ep_1273.pth\n","\n","overall performance: -3.3278607924326593\n","\n","\n","model tested: models/2024-05-06_17-02-15/q_network_ep_1275.pth\n","\n","overall performance: -3.59021337964687\n","\n","\n","model tested: models/2024-05-06_17-02-16/q_network_ep_1276.pth\n","\n","overall performance: -2.65382158298929\n","\n","\n","model tested: models/2024-05-06_17-02-19/q_network_ep_1278.pth\n","\n","overall performance: -4.756788248846457\n","\n","\n","model tested: models/2024-05-06_17-02-20/q_network_ep_1279.pth\n","\n","overall performance: -4.754090811807087\n","\n","\n","model tested: models/2024-05-06_17-02-21/q_network_ep_1280.pth\n","\n","overall performance: -5.055980745660202\n","\n","\n","model tested: models/2024-05-06_17-02-25/q_network_ep_1283.pth\n","\n","overall performance: -2.431539653304\n","\n","\n","model tested: models/2024-05-06_17-02-27/q_network_ep_1284.pth\n","\n","overall performance: -2.9150878930420605\n","\n","\n","model tested: models/2024-05-06_17-02-28/q_network_ep_1285.pth\n","\n","overall performance: -3.1720084078539545\n","\n","\n","model tested: models/2024-05-06_17-02-29/q_network_ep_1286.pth\n","\n","overall performance: -3.0173399502432856\n","\n","\n","model tested: models/2024-05-06_17-02-31/q_network_ep_1287.pth\n","\n","overall performance: -2.881445955128281\n","\n","\n","model tested: models/2024-05-06_17-02-32/q_network_ep_1288.pth\n","\n","overall performance: -2.3851335406211565\n","\n","\n","model tested: models/2024-05-06_17-02-33/q_network_ep_1289.pth\n","\n","overall performance: -2.5198733257386943\n","\n","\n","model tested: models/2024-05-06_17-02-34/q_network_ep_1290.pth\n","\n","overall performance: -2.096074799503958\n","\n","\n","model tested: models/2024-05-06_17-02-36/q_network_ep_1291.pth\n","\n","overall performance: -3.306493448842235\n","\n","\n","model tested: models/2024-05-06_17-02-37/q_network_ep_1292.pth\n","\n","overall performance: -2.1312752635137544\n","\n","\n","model tested: models/2024-05-06_17-02-38/q_network_ep_1293.pth\n","\n","overall performance: -2.159043468406357\n","\n","\n","model tested: models/2024-05-06_17-02-40/q_network_ep_1294.pth\n","\n","overall performance: -2.2306661225715234\n","\n","\n","model tested: models/2024-05-06_17-02-42/q_network_ep_1296.pth\n","\n","overall performance: -2.9254059481738013\n","\n","\n","model tested: models/2024-05-06_17-02-43/q_network_ep_1297.pth\n","\n","overall performance: -3.154322319759804\n","\n","\n","model tested: models/2024-05-06_17-02-45/q_network_ep_1298.pth\n","\n","overall performance: -3.65706272479517\n","\n","\n","model tested: models/2024-05-06_17-02-47/q_network_ep_1300.pth\n","\n","overall performance: -2.5454732193468623\n","\n","\n","model tested: models/2024-05-06_17-02-48/q_network_ep_1301.pth\n","\n","overall performance: -2.791027439466849\n","\n","\n","model tested: models/2024-05-06_17-02-49/q_network_ep_1302.pth\n","\n","overall performance: -2.034486781620133\n","\n","\n","model tested: models/2024-05-06_17-02-51/q_network_ep_1303.pth\n","\n","overall performance: -2.518290101007578\n","\n","\n","model tested: models/2024-05-06_17-02-52/q_network_ep_1304.pth\n","\n","overall performance: -7.092552038606454\n","\n","\n","model tested: models/2024-05-06_17-02-54/q_network_ep_1305.pth\n","\n","overall performance: -6.820329531884336\n","\n","\n","model tested: models/2024-05-06_17-02-55/q_network_ep_1306.pth\n","\n","overall performance: -8.084617532353695\n","\n","\n","model tested: models/2024-05-06_17-02-56/q_network_ep_1307.pth\n","\n","overall performance: -7.968903940378579\n","\n","\n","model tested: models/2024-05-06_17-02-57/q_network_ep_1308.pth\n","\n","overall performance: -6.444055561717573\n","\n","\n","model tested: models/2024-05-06_17-02-58/q_network_ep_1309.pth\n","\n","overall performance: -6.702210009416025\n","\n","\n","model tested: models/2024-05-06_17-02-59/q_network_ep_1310.pth\n","\n","overall performance: -13.8430214888967\n","\n","\n","model tested: models/2024-05-06_17-03-01/q_network_ep_1311.pth\n","\n","overall performance: -8.636421338407713\n","\n","\n","model tested: models/2024-05-06_17-03-02/q_network_ep_1312.pth\n","\n","overall performance: -9.532601173508565\n","\n","\n","model tested: models/2024-05-06_17-03-03/q_network_ep_1313.pth\n","\n","overall performance: -11.261899298876576\n","\n","\n","model tested: models/2024-05-06_17-03-05/q_network_ep_1314.pth\n","\n","overall performance: -2.9158301745622888\n","\n","\n","model tested: models/2024-05-06_17-03-06/q_network_ep_1315.pth\n","\n","overall performance: -10.551126997854771\n","\n","\n","model tested: models/2024-05-06_17-03-10/q_network_ep_1318.pth\n","\n","overall performance: -7.885771068918392\n","\n","\n","model tested: models/2024-05-06_17-03-11/q_network_ep_1319.pth\n","\n","overall performance: -8.486503084696656\n","\n","\n","model tested: models/2024-05-06_17-03-12/q_network_ep_1320.pth\n","\n","overall performance: -7.222935732828338\n","\n","\n","model tested: models/2024-05-06_17-03-13/q_network_ep_1321.pth\n","\n","overall performance: -6.867822306762994\n","\n","\n","model tested: models/2024-05-06_17-03-15/q_network_ep_1322.pth\n","\n","overall performance: -6.478235477258981\n","\n","\n","model tested: models/2024-05-06_17-03-16/q_network_ep_1323.pth\n","\n","overall performance: -6.026902577677542\n","\n","\n","model tested: models/2024-05-06_17-03-20/q_network_ep_1326.pth\n","\n","overall performance: -2.8027754715058877\n","\n","\n","model tested: models/2024-05-06_17-03-22/q_network_ep_1328.pth\n","\n","overall performance: -2.3769025935859163\n","\n","\n","model tested: models/2024-05-06_17-03-24/q_network_ep_1329.pth\n","\n","overall performance: -2.2182983415903497\n","\n","\n","model tested: models/2024-05-06_17-03-25/q_network_ep_1330.pth\n","\n","overall performance: -2.877043913597341\n","\n","\n","model tested: models/2024-05-06_17-03-26/q_network_ep_1331.pth\n","\n","overall performance: -2.4446543572694903\n","\n","\n","model tested: models/2024-05-06_17-03-27/q_network_ep_1332.pth\n","\n","overall performance: -2.4408864514044244\n","\n","\n","model tested: models/2024-05-06_17-03-29/q_network_ep_1333.pth\n","\n","overall performance: -2.4525120089935686\n","\n","\n","model tested: models/2024-05-06_17-03-30/q_network_ep_1334.pth\n","\n","overall performance: -2.8957952373303124\n","\n","\n","model tested: models/2024-05-06_17-03-31/q_network_ep_1335.pth\n","\n","overall performance: -2.553097662989601\n","\n","\n","model tested: models/2024-05-06_17-03-33/q_network_ep_1336.pth\n","\n","overall performance: -2.627500105337806\n","\n","\n","model tested: models/2024-05-06_17-03-34/q_network_ep_1337.pth\n","\n","overall performance: -2.370862607794797\n","\n","\n","model tested: models/2024-05-06_17-03-35/q_network_ep_1338.pth\n","\n","overall performance: -2.5816849790372127\n","\n","\n","model tested: models/2024-05-06_17-03-36/q_network_ep_1339.pth\n","\n","overall performance: -3.2477722041699564\n","\n","\n","model tested: models/2024-05-06_17-03-37/q_network_ep_1340.pth\n","\n","overall performance: -2.584778117639519\n","\n","\n","model tested: models/2024-05-06_17-03-41/q_network_ep_1343.pth\n","\n","overall performance: -2.7025094793318027\n","\n","\n","model tested: models/2024-05-06_17-03-43/q_network_ep_1344.pth\n","\n","overall performance: -3.0800856123025957\n","\n","\n","model tested: models/2024-05-06_17-03-44/q_network_ep_1345.pth\n","\n","overall performance: -2.672417747532637\n","\n","\n","model tested: models/2024-05-06_17-03-46/q_network_ep_1347.pth\n","\n","overall performance: -2.632699434243116\n","\n","\n","model tested: models/2024-05-06_17-03-49/q_network_ep_1349.pth\n","\n","overall performance: -2.058509311750984\n","\n","\n","model tested: models/2024-05-06_17-03-52/q_network_ep_1352.pth\n","\n","overall performance: -2.925472542992166\n","\n","\n","model tested: models/2024-05-06_17-03-54/q_network_ep_1353.pth\n","\n","overall performance: -2.436752908898371\n","\n","\n","model tested: models/2024-05-06_17-03-55/q_network_ep_1354.pth\n","\n","overall performance: -2.055724944918428\n","\n","\n","model tested: models/2024-05-06_17-03-57/q_network_ep_1355.pth\n","\n","overall performance: -2.5552664025767275\n","\n","\n","model tested: models/2024-05-06_17-03-58/q_network_ep_1356.pth\n","\n","overall performance: -2.2830402304382895\n","\n","\n","model tested: models/2024-05-06_17-04-00/q_network_ep_1358.pth\n","\n","overall performance: -2.689520028529099\n","\n","\n","model tested: models/2024-05-06_17-04-01/q_network_ep_1359.pth\n","\n","overall performance: -2.4592869396864456\n","\n","\n","model tested: models/2024-05-06_17-04-03/q_network_ep_1360.pth\n","\n","overall performance: -2.390754423504653\n","\n","\n","model tested: models/2024-05-06_17-04-04/q_network_ep_1361.pth\n","\n","overall performance: -2.39965874039335\n","\n","\n","model tested: models/2024-05-06_17-04-05/q_network_ep_1362.pth\n","\n","overall performance: -2.1845796531901267\n","\n","\n","model tested: models/2024-05-06_17-04-07/q_network_ep_1363.pth\n","\n","overall performance: -2.2214585054204643\n","\n","\n","model tested: models/2024-05-06_17-04-08/q_network_ep_1364.pth\n","\n","overall performance: -2.214301340051465\n","\n","\n","model tested: models/2024-05-06_17-04-10/q_network_ep_1365.pth\n","\n","overall performance: -2.208761671598563\n","\n","\n","model tested: models/2024-05-06_17-04-11/q_network_ep_1366.pth\n","\n","overall performance: -2.613690726343996\n","\n","\n","model tested: models/2024-05-06_17-04-12/q_network_ep_1367.pth\n","\n","overall performance: -2.417822953695626\n","\n","\n","model tested: models/2024-05-06_17-04-13/q_network_ep_1368.pth\n","\n","overall performance: -2.5824457622503894\n","\n","\n","model tested: models/2024-05-06_17-04-14/q_network_ep_1369.pth\n","\n","overall performance: -2.3741867779994426\n","\n","\n","model tested: models/2024-05-06_17-04-17/q_network_ep_1371.pth\n","\n","overall performance: -2.1341465122216428\n","\n","\n","model tested: models/2024-05-06_17-04-18/q_network_ep_1372.pth\n","\n","overall performance: -2.080684681769914\n","\n","\n","model tested: models/2024-05-06_17-04-20/q_network_ep_1373.pth\n","\n","overall performance: -2.337236630420948\n","\n","\n","model tested: models/2024-05-06_17-04-23/q_network_ep_1375.pth\n","\n","overall performance: -2.0102857534947165\n","\n","\n","model tested: models/2024-05-06_17-04-24/q_network_ep_1376.pth\n","\n","overall performance: -2.126565198863797\n","\n","\n","model tested: models/2024-05-06_17-04-25/q_network_ep_1377.pth\n","\n","overall performance: -2.1394343334325794\n","\n","\n","model tested: models/2024-05-06_17-04-26/q_network_ep_1378.pth\n","\n","overall performance: -2.2626359801095925\n","\n","\n","model tested: models/2024-05-06_17-04-27/q_network_ep_1379.pth\n","\n","overall performance: -2.7121337406662573\n","\n","\n","model tested: models/2024-05-06_17-04-28/q_network_ep_1380.pth\n","\n","overall performance: -2.390736986353718\n","\n","\n","model tested: models/2024-05-06_17-04-30/q_network_ep_1381.pth\n","\n","overall performance: -2.308505198087403\n","\n","\n","model tested: models/2024-05-06_17-04-31/q_network_ep_1382.pth\n","\n","overall performance: -2.8105090704429436\n","\n","\n","model tested: models/2024-05-06_17-04-33/q_network_ep_1383.pth\n","\n","overall performance: -2.6123800009485825\n","\n","\n","model tested: models/2024-05-06_17-04-34/q_network_ep_1384.pth\n","\n","overall performance: -2.8264269387633005\n","\n","\n","model tested: models/2024-05-06_17-04-36/q_network_ep_1386.pth\n","\n","overall performance: -4.001285146098437\n","\n","\n","model tested: models/2024-05-06_17-04-38/q_network_ep_1387.pth\n","\n","overall performance: -2.2741025066407707\n","\n","\n","model tested: models/2024-05-06_17-04-40/q_network_ep_1389.pth\n","\n","overall performance: -2.022274548174293\n","\n","\n","model tested: models/2024-05-06_17-04-42/q_network_ep_1391.pth\n","\n","overall performance: -2.119236119682013\n","\n","\n","model tested: models/2024-05-06_17-04-44/q_network_ep_1392.pth\n","\n","overall performance: -2.092861171604461\n","\n","\n","model tested: models/2024-05-06_17-04-46/q_network_ep_1393.pth\n","\n","overall performance: -2.5350065964138055\n","\n","\n","model tested: models/2024-05-06_17-04-47/q_network_ep_1394.pth\n","\n","overall performance: -3.933724974858258\n","\n","\n","model tested: models/2024-05-06_17-04-48/q_network_ep_1395.pth\n","\n","overall performance: -2.768184047750036\n","\n","\n","model tested: models/2024-05-06_17-04-50/q_network_ep_1397.pth\n","\n","overall performance: -2.415117530600897\n","\n","\n","model tested: models/2024-05-06_17-04-52/q_network_ep_1398.pth\n","\n","overall performance: -3.7086614002471743\n","\n","\n","model tested: models/2024-05-06_17-04-53/q_network_ep_1399.pth\n","\n","overall performance: -2.4067192438120175\n","\n","\n","model tested: models/2024-05-06_17-04-55/q_network_ep_1401.pth\n","\n","overall performance: -6.509264052016758\n","\n","\n","model tested: models/2024-05-06_17-04-57/q_network_ep_1402.pth\n","\n","overall performance: -2.302680773436184\n","\n","\n","model tested: models/2024-05-06_17-04-58/q_network_ep_1403.pth\n","\n","overall performance: -4.81017144775035\n","\n","\n","model tested: models/2024-05-06_17-05-00/q_network_ep_1404.pth\n","\n","overall performance: -2.211457136447689\n","\n","\n","model tested: models/2024-05-06_17-05-01/q_network_ep_1405.pth\n","\n","overall performance: -2.1754803436268775\n","\n","\n","model tested: models/2024-05-06_17-05-02/q_network_ep_1406.pth\n","\n","overall performance: -11.658279199646412\n","\n","\n","model tested: models/2024-05-06_17-05-05/q_network_ep_1408.pth\n","\n","overall performance: -2.2863587187703365\n","\n","\n","model tested: models/2024-05-06_17-05-07/q_network_ep_1410.pth\n","\n","overall performance: -2.5243235969654725\n","\n","\n","model tested: models/2024-05-06_17-05-08/q_network_ep_1411.pth\n","\n","overall performance: -8.054856914833431\n","\n","\n","model tested: models/2024-05-06_17-05-10/q_network_ep_1412.pth\n","\n","overall performance: -4.849040043664514\n","\n","\n","model tested: models/2024-05-06_17-05-12/q_network_ep_1413.pth\n","\n","overall performance: -4.708295218928638\n","\n","\n","model tested: models/2024-05-06_17-05-13/q_network_ep_1414.pth\n","\n","overall performance: -5.861829612306778\n","\n","\n","model tested: models/2024-05-06_17-05-14/q_network_ep_1415.pth\n","\n","overall performance: -4.629232720144344\n","\n","\n","model tested: models/2024-05-06_17-05-15/q_network_ep_1416.pth\n","\n","overall performance: -5.199596347349952\n","\n","\n","model tested: models/2024-05-06_17-05-16/q_network_ep_1417.pth\n","\n","overall performance: -3.02663245870773\n","\n","\n","model tested: models/2024-05-06_17-05-18/q_network_ep_1418.pth\n","\n","overall performance: -2.6644013988853277\n","\n","\n","model tested: models/2024-05-06_17-05-19/q_network_ep_1419.pth\n","\n","overall performance: -3.0484975764434608\n","\n","\n","model tested: models/2024-05-06_17-05-20/q_network_ep_1420.pth\n","\n","overall performance: -2.6874195227900346\n","\n","\n","model tested: models/2024-05-06_17-05-23/q_network_ep_1422.pth\n","\n","overall performance: -2.6516133177756895\n","\n","\n","model tested: models/2024-05-06_17-05-26/q_network_ep_1424.pth\n","\n","overall performance: -2.3256823430709885\n","\n","\n","model tested: models/2024-05-06_17-05-27/q_network_ep_1425.pth\n","\n","overall performance: -2.566328719817509\n","\n","\n","model tested: models/2024-05-06_17-05-28/q_network_ep_1426.pth\n","\n","overall performance: -2.5804134578961078\n","\n","\n","model tested: models/2024-05-06_17-05-29/q_network_ep_1427.pth\n","\n","overall performance: -2.5582969774947673\n","\n","\n","model tested: models/2024-05-06_17-05-31/q_network_ep_1428.pth\n","\n","overall performance: -2.3817969989678196\n","\n","\n","model tested: models/2024-05-06_17-05-32/q_network_ep_1429.pth\n","\n","overall performance: -2.366090987679979\n","\n","\n","model tested: models/2024-05-06_17-05-33/q_network_ep_1430.pth\n","\n","overall performance: -2.3252347780921747\n","\n","\n","model tested: models/2024-05-06_17-05-35/q_network_ep_1431.pth\n","\n","overall performance: -2.7418615421438206\n","\n","\n","model tested: models/2024-05-06_17-05-36/q_network_ep_1432.pth\n","\n","overall performance: -3.4271373425120535\n","\n","\n","model tested: models/2024-05-06_17-05-38/q_network_ep_1433.pth\n","\n","overall performance: -55.57656902827654\n","\n","\n","model tested: models/2024-05-06_17-05-39/q_network_ep_1434.pth\n","\n","overall performance: -60.857849142687726\n","\n","\n","model tested: models/2024-05-06_17-05-40/q_network_ep_1435.pth\n","\n","overall performance: -59.14256036278133\n","\n","\n","model tested: models/2024-05-06_17-05-41/q_network_ep_1436.pth\n","\n","overall performance: -2.772892969443515\n","\n","\n","model tested: models/2024-05-06_17-05-44/q_network_ep_1438.pth\n","\n","overall performance: -2.0658313225224463\n","\n","\n","model tested: models/2024-05-06_17-05-45/q_network_ep_1439.pth\n","\n","overall performance: -2.0817274007717437\n","\n","\n","model tested: models/2024-05-06_17-05-46/q_network_ep_1440.pth\n","\n","overall performance: -2.150073370476031\n","\n","\n","model tested: models/2024-05-06_17-05-48/q_network_ep_1441.pth\n","\n","overall performance: -2.4420781319123024\n","\n","\n","model tested: models/2024-05-06_17-05-49/q_network_ep_1442.pth\n","\n","overall performance: -2.2229362283647793\n","\n","\n","model tested: models/2024-05-06_17-05-51/q_network_ep_1443.pth\n","\n","overall performance: -1.9943243297574853\n","\n","\n","model tested: models/2024-05-06_17-05-52/q_network_ep_1444.pth\n","\n","overall performance: -2.4279434691540307\n","\n","\n","model tested: models/2024-05-06_17-05-53/q_network_ep_1445.pth\n","\n","overall performance: -2.1249898148356\n","\n","\n","model tested: models/2024-05-06_17-05-54/q_network_ep_1446.pth\n","\n","overall performance: -2.467162659237073\n","\n","\n","model tested: models/2024-05-06_17-05-57/q_network_ep_1448.pth\n","\n","overall performance: -1.9261600121636622\n","\n","\n","model tested: models/2024-05-06_17-05-58/q_network_ep_1449.pth\n","\n","overall performance: -1.9584419860176587\n","\n","\n","model tested: models/2024-05-06_17-05-59/q_network_ep_1450.pth\n","\n","overall performance: -2.2406775059986273\n","\n","\n","model tested: models/2024-05-06_17-06-01/q_network_ep_1451.pth\n","\n","overall performance: -2.3269545564055845\n","\n","\n","model tested: models/2024-05-06_17-06-04/q_network_ep_1453.pth\n","\n","overall performance: -1.9063676738335087\n","\n","\n","model tested: models/2024-05-06_17-06-05/q_network_ep_1454.pth\n","\n","overall performance: -2.0877591855505626\n","\n","\n","model tested: models/2024-05-06_17-06-06/q_network_ep_1455.pth\n","\n","overall performance: -2.2080655565487577\n","\n","\n","model tested: models/2024-05-06_17-06-07/q_network_ep_1456.pth\n","\n","overall performance: -2.165300630147816\n","\n","\n","model tested: models/2024-05-06_17-06-08/q_network_ep_1457.pth\n","\n","overall performance: -2.0974603027993384\n","\n","\n","model tested: models/2024-05-06_17-06-10/q_network_ep_1458.pth\n","\n","overall performance: -2.116082324348814\n","\n","\n","model tested: models/2024-05-06_17-06-12/q_network_ep_1460.pth\n","\n","overall performance: -1.949507955345084\n","\n","\n","model tested: models/2024-05-06_17-06-14/q_network_ep_1461.pth\n","\n","overall performance: -30.47275372740561\n","\n","\n","model tested: models/2024-05-06_17-06-15/q_network_ep_1462.pth\n","\n","overall performance: -3.664700763362365\n","\n","\n","model tested: models/2024-05-06_17-06-16/q_network_ep_1463.pth\n","\n","overall performance: -2.3231607629728317\n","\n","\n","model tested: models/2024-05-06_17-06-18/q_network_ep_1464.pth\n","\n","overall performance: -1.9850901063978164\n","\n","\n","model tested: models/2024-05-06_17-06-19/q_network_ep_1465.pth\n","\n","overall performance: -1.9181822106788047\n","\n","\n","model tested: models/2024-05-06_17-06-20/q_network_ep_1466.pth\n","\n","overall performance: -4.8013094651080594\n","\n","\n","model tested: models/2024-05-06_17-06-21/q_network_ep_1467.pth\n","\n","overall performance: -5.4864862676365345\n","\n","\n","model tested: models/2024-05-06_17-06-23/q_network_ep_1468.pth\n","\n","overall performance: -3.9171776778116154\n","\n","\n","model tested: models/2024-05-06_17-06-26/q_network_ep_1470.pth\n","\n","overall performance: -2.2294681150080167\n","\n","\n","model tested: models/2024-05-06_17-06-27/q_network_ep_1471.pth\n","\n","overall performance: -2.110106018112523\n","\n","\n","model tested: models/2024-05-06_17-06-28/q_network_ep_1472.pth\n","\n","overall performance: -1.9558746345931706\n","\n","\n","model tested: models/2024-05-06_17-06-29/q_network_ep_1473.pth\n","\n","overall performance: -2.2687299092100393\n","\n","\n","model tested: models/2024-05-06_17-06-32/q_network_ep_1475.pth\n","\n","overall performance: -2.0127060564403445\n","\n","\n","model tested: models/2024-05-06_17-06-34/q_network_ep_1477.pth\n","\n","overall performance: -1.9685717150360822\n","\n","\n","model tested: models/2024-05-06_17-06-36/q_network_ep_1478.pth\n","\n","overall performance: -17.977643132397475\n","\n","\n","model tested: models/2024-05-06_17-06-39/q_network_ep_1480.pth\n","\n","overall performance: -2.0721815073115457\n","\n","\n","model tested: models/2024-05-06_17-06-40/q_network_ep_1481.pth\n","\n","overall performance: -2.310970228382977\n","\n","\n","model tested: models/2024-05-06_17-06-41/q_network_ep_1482.pth\n","\n","overall performance: -1.980478056110607\n","\n","\n","model tested: models/2024-05-06_17-06-42/q_network_ep_1483.pth\n","\n","overall performance: -1.9080275844649457\n","\n","\n","model tested: models/2024-05-06_17-06-44/q_network_ep_1484.pth\n","\n","overall performance: -22.957036171921683\n","\n","\n","model tested: models/2024-05-06_17-06-45/q_network_ep_1485.pth\n","\n","overall performance: -1.9702338057712871\n","\n","\n","model tested: models/2024-05-06_17-06-47/q_network_ep_1487.pth\n","\n","overall performance: -43.321963951071325\n","\n","\n","model tested: models/2024-05-06_17-06-48/q_network_ep_1488.pth\n","\n","overall performance: -44.83258926574468\n","\n","\n","model tested: models/2024-05-06_17-06-50/q_network_ep_1489.pth\n","\n","overall performance: -46.98625151459391\n","\n","\n","model tested: models/2024-05-06_17-06-52/q_network_ep_1490.pth\n","\n","overall performance: -57.375244488958415\n","\n","\n","model tested: models/2024-05-06_17-06-53/q_network_ep_1491.pth\n","\n","overall performance: -43.09260138068021\n","\n","\n","model tested: models/2024-05-06_17-06-54/q_network_ep_1492.pth\n","\n","overall performance: -37.34081093006506\n","\n","\n","model tested: models/2024-05-06_17-06-55/q_network_ep_1493.pth\n","\n","overall performance: -97.67890098543914\n","\n","\n","model tested: models/2024-05-06_17-06-57/q_network_ep_1494.pth\n","\n","overall performance: -35.61037787019738\n","\n","\n","model tested: models/2024-05-06_17-06-58/q_network_ep_1495.pth\n","\n","overall performance: -59.82429463236226\n","\n","\n","model tested: models/2024-05-06_17-06-59/q_network_ep_1496.pth\n","\n","overall performance: -43.12973661022046\n","\n","\n","model tested: models/2024-05-06_17-07-00/q_network_ep_1497.pth\n","\n","overall performance: -88.55672981105408\n","\n","\n"]}],"source":["from robot import Robot\n","from arm_dynamics import ArmDynamics\n","\n","# DO NOT CHANGE\n","# ---------------\n","arm = Robot(\n","        ArmDynamics(\n","            num_links=2,\n","            link_mass=0.1,\n","            link_length=1,\n","            joint_viscous_friction=0.1,\n","            dt=0.01,\n","\t    \t\t\tgravity=False\n","        )\n","    )\n","arm.reset()\n","env = ArmEnv(arm, gui=False)\n","tqdn = TrainDQN(env)\n","# ---------------\n","\n","# Call your trin function here\n","model_path=tqdn.train()"]},{"cell_type":"markdown","source":["To keep track of your experiments, it is good practice to plot and check how well is your model trained based on the returns vs episodes plot. With a large number of episodes, this  plot may look very jagged making it difficult to ascertain how well you are doing. We are proving code to smoothen out the plot by. This will take a large list of returns in every episode and plot a smoothened version of the list. Feel free to use it if it helps.\n","```\n","import seaborn as sns\n","returns = __\n","smoothing = 10\n","\n","smoothened = [sum(returns[i:i+smoothing])/smoothing for i in range(0, len(returns), smoothing)]\n","sns.lineplot(smoothened)\n","```"],"metadata":{"id":"jAlaOcVJsn5a"}},{"cell_type":"markdown","metadata":{"id":"lIcBDbeTRNZI"},"source":["### Load your model and test its performance\n","Change your model path and the goal to see how well your learnt model is performing"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"x5gTRNKhRQQM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715017757458,"user_tz":240,"elapsed":524,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"7fdb6c1d-ae80-41d5-9557-6d6a78a35164"},"outputs":[{"output_type":"stream","name":"stdout","text":["models/2024-05-06_17-06-04/q_network_ep_1453.pth\n","Episode return:  -1.5164057455798456\n"]}],"source":["import collections\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from render import Renderer\n","from arm_env import ArmEnv\n","import numpy as np\n","import os\n","from math import dist\n","import seaborn as sns\n","from robot import Robot\n","from arm_dynamics import ArmDynamics\n","from geometry import polar2cartesian\n","\n","\n","# DO NOT CHANGE arm parameters\n","arm = Robot(\n","        ArmDynamics(\n","            num_links=2,\n","            link_mass=0.1,\n","            link_length=1,\n","            joint_viscous_friction=0.1,\n","            dt=0.01,\n","\t    \t\t\tgravity=False\n","        )\n","    )\n","arm.reset()\n","# ------------------\n","\n","env = ArmEnv(arm, gui=False)\n","model_path = model_path # Fill in the model_path\n","print(model_path)\n","device = torch.device('cpu')\n","qnet = QNetwork(env).to(device)\n","qnet.load_state_dict(torch.load(model_path))\n","qnet.eval()\n","goal = polar2cartesian(1.6, 0.25 - np.pi/2.0)\n","done = False\n","obs = env.reset(goal)\n","torch.save(qnet, ' q_network.pth')\n","\n","episode_return = 0\n","while not done:\n","  action = qnet.select_discrete_action(obs, device)\n","  action = qnet.action_discrete_to_continuous(action)\n","  new_obs, reward, done, info = env.step(action)\n","  episode_return += reward\n","\n","  pos_ee = info['pos_ee']\n","  vel_ee = info['vel_ee']\n","  dist = np.linalg.norm(pos_ee - goal)\n","\n","  obs = new_obs\n","print('Episode return: ', episode_return)\n"]},{"cell_type":"markdown","source":["### Grading and Evaluation\n","You will be evaluated on 5 different goal positions worth 1.5 points each. You must pass the best `model_path` for your network. The scoring function will run one episode for every goal position and find the total reward (aka return) for the episode. For every goal you get:\n","\n","* 1 Point if `easy target < total reward < hard target`\n","* 1.5 Points if `hard target < total reward`"],"metadata":{"id":"pUDEYLsZLSp4"}},{"cell_type":"code","source":["from score import compute_score\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from render import Renderer\n","from arm_env import ArmEnv\n","from robot import Robot\n","from arm_dynamics import ArmDynamics\n","import numpy as np\n","\n","\n","# DO NOT CHANGE arm parameters\n","arm = Robot(\n","        ArmDynamics(\n","            num_links=2,\n","            link_mass=0.1,\n","            link_length=1,\n","            joint_viscous_friction=0.1,\n","            dt=0.01,\n","\t    \t\t\tgravity=False\n","        )\n","    )\n","arm.reset()\n","# ------------------\n","\n","env = ArmEnv(arm, gui=False)\n","model_path = 'models/2024-05-06_17-06-04/q_network_ep_1453.pth'\n","device = torch.device('cpu')\n","qnet = QNetwork(env).to(device)\n","qnet.load_state_dict(torch.load(model_path))\n","qnet.eval()\n","score = compute_score(qnet, env, device)"],"metadata":{"id":"OhPD-u6TIxdl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715017783355,"user_tz":240,"elapsed":1902,"user":{"displayName":"Runsheng Wang","userId":"03011584503133139471"}},"outputId":"e771052a-6d49-418a-9c52-f35f7a19e1ef"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["---Computing score---\n","\n","Goal 1:\n","Total reward: -1.2345310268992231\n","easy target: -7\n","hard target: -5\n","points: 1.5\n","\n","Goal 2:\n","Total reward: -1.5164057455798456\n","easy target: -7\n","hard target: -5\n","points: 1.5\n","\n","Goal 3:\n","Total reward: -2.547095029131439\n","easy target: -7\n","hard target: -5\n","points: 1.5\n","\n","Goal 4:\n","Total reward: -9.733207651982383\n","easy target: -7\n","hard target: -5\n","points: 0\n","\n","Goal 5:\n","Total reward: -4.8514713089341335\n","easy target: -10\n","hard target: -7\n","points: 1.5\n","\n","\n","Final score: 6.0\n"]}]},{"cell_type":"markdown","source":["# Part 2: PPO with an open source RL library\n","\n","In this part, you will use one of the most popular open source RL libraries ([Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)) to solve the same goal reaching problem as Part 1. We will use the same `ArmEnv` gym environment. The algorithm you should choose to use is PPO."],"metadata":{"id":"vkCvO0-05XK5"}},{"cell_type":"markdown","source":["## PPO training\n","\n","We provide the code to construct parallel environments. Parallel environments can be very useful if you have good CPUs and it can speed up training."],"metadata":{"id":"UBK89P2B8CgL"}},{"cell_type":"code","source":["# DO NOT CHANGE\n","\n","from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n","from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n","from copy import deepcopy\n","from robot import Robot\n","from arm_dynamics import ArmDynamics\n","from arm_env import ArmEnv\n","\n","class EnvMaker:\n","    def __init__(self,  arm, seed):\n","        self.seed = seed\n","        self.arm = arm\n","\n","    def __call__(self):\n","        arm = deepcopy(self.arm)\n","        env = ArmEnv(arm)\n","        env.seed(self.seed)\n","        return env\n","\n","def make_vec_env(arm, nenv, seed):\n","    return VecMonitor(SubprocVecEnv([EnvMaker(arm, seed  + 100 * i) for i in range(nenv)]))\n","\n","# conveniet function to create a robot arm\n","def make_arm():\n","    arm = Robot(\n","        ArmDynamics(\n","            num_links=2,\n","            link_mass=0.1,\n","            link_length=1,\n","            joint_viscous_friction=0.1,\n","            dt=0.01\n","        )\n","    )\n","    arm.reset()\n","    return arm\n"],"metadata":{"id":"2RTqfmpVwMja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You will need to complete the code to train the policy using the [PPO class](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html) from stable_baselines3. We provide the code to generate the name of the directory to save the checkpoint, an example is `ppo_models/2024-04-13_01-14-13`. Your checkpoint model should be named `ppo_network.zip`. See the [save](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#stable_baselines3.ppo.PPO.save) function. Training should take less than 40 minutes."],"metadata":{"id":"Bniz2TouwM3S"}},{"cell_type":"code","source":["from stable_baselines3.ppo import PPO\n","import os\n","import time\n","from stable_baselines3.common.utils import set_random_seed\n","\n","\n","# Default parameters\n","timesteps = 1000000\n","nenv = 8  # number of parallel environments. This can speed up training when you have good CPUs\n","seed = 8\n","batch_size = 2048\n","\n","# Generate path of the directory to save the checkpoint\n","timestr = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n","save_dir = os.path.join('ppo_network' )\n","\n","# Set random seed\n","set_random_seed(seed)\n","\n","# Create arm\n","arm = make_arm()\n","\n","# Create parallel envs\n","vec_env = make_vec_env(arm=arm, nenv=nenv, seed=seed)\n","\n","# ------ IMPLEMENT YOUR TRAINING CODE HERE ------------\n","model = PPO('MlpPolicy', vec_env, verbose = 1, batch_size=batch_size,learning_rate=0.0005)\n","model.learn(total_timesteps=timesteps)\n","model.save(f'{save_dir}')\n","\n","\n","#raise NotImplementedError\n","\n","# Do not forget to save your model at the end of training"],"metadata":{"id":"FHoSWOnG-2sH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714077701034,"user_tz":240,"elapsed":1811666,"user":{"displayName":"Jingran Wang","userId":"11496959489179416337"}},"outputId":"bed8d385-1ee3-47a9-f675-7c0e8784ea5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","-----------------------------------\n","| rollout/           |            |\n","|    ep_len_mean     | 200        |\n","|    ep_rew_mean     | -211.95427 |\n","| time/              |            |\n","|    fps             | 601        |\n","|    iterations      | 1          |\n","|    time_elapsed    | 27         |\n","|    total_timesteps | 16384      |\n","-----------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -154.62141   |\n","| time/                   |              |\n","|    fps                  | 590          |\n","|    iterations           | 2            |\n","|    time_elapsed         | 55           |\n","|    total_timesteps      | 32768        |\n","| train/                  |              |\n","|    approx_kl            | 0.0040957723 |\n","|    clip_fraction        | 0.0306       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.84        |\n","|    explained_variance   | -0.00092     |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 233          |\n","|    n_updates            | 10           |\n","|    policy_gradient_loss | -0.00359     |\n","|    std                  | 1            |\n","|    value_loss           | 556          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -106.268654  |\n","| time/                   |              |\n","|    fps                  | 585          |\n","|    iterations           | 3            |\n","|    time_elapsed         | 84           |\n","|    total_timesteps      | 49152        |\n","| train/                  |              |\n","|    approx_kl            | 0.0032346053 |\n","|    clip_fraction        | 0.02         |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.84        |\n","|    explained_variance   | -0.0159      |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 68.8         |\n","|    n_updates            | 20           |\n","|    policy_gradient_loss | -0.00256     |\n","|    std                  | 1            |\n","|    value_loss           | 170          |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -86.69221   |\n","| time/                   |             |\n","|    fps                  | 581         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 112         |\n","|    total_timesteps      | 65536       |\n","| train/                  |             |\n","|    approx_kl            | 0.004074446 |\n","|    clip_fraction        | 0.0257      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.85       |\n","|    explained_variance   | -0.0473     |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 38.3        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.00355    |\n","|    std                  | 1.01        |\n","|    value_loss           | 82.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -69.07798   |\n","| time/                   |             |\n","|    fps                  | 581         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 140         |\n","|    total_timesteps      | 81920       |\n","| train/                  |             |\n","|    approx_kl            | 0.004404255 |\n","|    clip_fraction        | 0.0273      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.87       |\n","|    explained_variance   | -0.0141     |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 39.8        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0028     |\n","|    std                  | 1.02        |\n","|    value_loss           | 87.8        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -48.935055   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 6            |\n","|    time_elapsed         | 170          |\n","|    total_timesteps      | 98304        |\n","| train/                  |              |\n","|    approx_kl            | 0.0045055747 |\n","|    clip_fraction        | 0.0424       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.88        |\n","|    explained_variance   | 0.000447     |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 14.3         |\n","|    n_updates            | 50           |\n","|    policy_gradient_loss | -0.00337     |\n","|    std                  | 1.02         |\n","|    value_loss           | 30.1         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -35.36001   |\n","| time/                   |             |\n","|    fps                  | 569         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 201         |\n","|    total_timesteps      | 114688      |\n","| train/                  |             |\n","|    approx_kl            | 0.004467997 |\n","|    clip_fraction        | 0.0374      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.88       |\n","|    explained_variance   | -0.00103    |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 16.1        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.00256    |\n","|    std                  | 1.03        |\n","|    value_loss           | 31.1        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -34.910046   |\n","| time/                   |              |\n","|    fps                  | 570          |\n","|    iterations           | 8            |\n","|    time_elapsed         | 229          |\n","|    total_timesteps      | 131072       |\n","| train/                  |              |\n","|    approx_kl            | 0.0029176893 |\n","|    clip_fraction        | 0.025        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.89        |\n","|    explained_variance   | -0.00459     |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 5.8          |\n","|    n_updates            | 70           |\n","|    policy_gradient_loss | -0.000205    |\n","|    std                  | 1.02         |\n","|    value_loss           | 13.2         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -32.129047   |\n","| time/                   |              |\n","|    fps                  | 571          |\n","|    iterations           | 9            |\n","|    time_elapsed         | 258          |\n","|    total_timesteps      | 147456       |\n","| train/                  |              |\n","|    approx_kl            | 0.0032551226 |\n","|    clip_fraction        | 0.0286       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.87        |\n","|    explained_variance   | 0.00331      |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 7.86         |\n","|    n_updates            | 80           |\n","|    policy_gradient_loss | -0.00222     |\n","|    std                  | 1.01         |\n","|    value_loss           | 16.4         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -30.914814  |\n","| time/                   |             |\n","|    fps                  | 572         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 286         |\n","|    total_timesteps      | 163840      |\n","| train/                  |             |\n","|    approx_kl            | 0.004740769 |\n","|    clip_fraction        | 0.0312      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.87       |\n","|    explained_variance   | 0.0164      |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 6.59        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.00165    |\n","|    std                  | 1.01        |\n","|    value_loss           | 14          |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -24.178738   |\n","| time/                   |              |\n","|    fps                  | 572          |\n","|    iterations           | 11           |\n","|    time_elapsed         | 314          |\n","|    total_timesteps      | 180224       |\n","| train/                  |              |\n","|    approx_kl            | 0.0050489963 |\n","|    clip_fraction        | 0.0363       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.87        |\n","|    explained_variance   | 0.0173       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 6.19         |\n","|    n_updates            | 100          |\n","|    policy_gradient_loss | -0.00307     |\n","|    std                  | 1.02         |\n","|    value_loss           | 13.3         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -22.690083   |\n","| time/                   |              |\n","|    fps                  | 573          |\n","|    iterations           | 12           |\n","|    time_elapsed         | 343          |\n","|    total_timesteps      | 196608       |\n","| train/                  |              |\n","|    approx_kl            | 0.0049168514 |\n","|    clip_fraction        | 0.0208       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.88        |\n","|    explained_variance   | 0.0181       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 3.54         |\n","|    n_updates            | 110          |\n","|    policy_gradient_loss | -0.00197     |\n","|    std                  | 1.01         |\n","|    value_loss           | 7.65         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -20.942638  |\n","| time/                   |             |\n","|    fps                  | 573         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 371         |\n","|    total_timesteps      | 212992      |\n","| train/                  |             |\n","|    approx_kl            | 0.005403281 |\n","|    clip_fraction        | 0.0416      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.85       |\n","|    explained_variance   | 0.00711     |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 2.83        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00173    |\n","|    std                  | 1           |\n","|    value_loss           | 5.79        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -21.928272   |\n","| time/                   |              |\n","|    fps                  | 573          |\n","|    iterations           | 14           |\n","|    time_elapsed         | 399          |\n","|    total_timesteps      | 229376       |\n","| train/                  |              |\n","|    approx_kl            | 0.0037928727 |\n","|    clip_fraction        | 0.051        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.85        |\n","|    explained_variance   | 0.0126       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 2.83         |\n","|    n_updates            | 130          |\n","|    policy_gradient_loss | 0.000931     |\n","|    std                  | 1.01         |\n","|    value_loss           | 5.64         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -18.686346  |\n","| time/                   |             |\n","|    fps                  | 574         |\n","|    iterations           | 15          |\n","|    time_elapsed         | 427         |\n","|    total_timesteps      | 245760      |\n","| train/                  |             |\n","|    approx_kl            | 0.003397731 |\n","|    clip_fraction        | 0.0317      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.84       |\n","|    explained_variance   | 0.0309      |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 2.65        |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.00208    |\n","|    std                  | 1           |\n","|    value_loss           | 5.23        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -17.421833   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 16           |\n","|    time_elapsed         | 456          |\n","|    total_timesteps      | 262144       |\n","| train/                  |              |\n","|    approx_kl            | 0.0057475707 |\n","|    clip_fraction        | 0.0413       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.84        |\n","|    explained_variance   | 0.0386       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 2.24         |\n","|    n_updates            | 150          |\n","|    policy_gradient_loss | -0.00277     |\n","|    std                  | 1            |\n","|    value_loss           | 4.58         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -19.028814  |\n","| time/                   |             |\n","|    fps                  | 572         |\n","|    iterations           | 17          |\n","|    time_elapsed         | 486         |\n","|    total_timesteps      | 278528      |\n","| train/                  |             |\n","|    approx_kl            | 0.005037508 |\n","|    clip_fraction        | 0.0312      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.84       |\n","|    explained_variance   | 0.00123     |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 1.52        |\n","|    n_updates            | 160         |\n","|    policy_gradient_loss | -0.00203    |\n","|    std                  | 0.998       |\n","|    value_loss           | 3.19        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -17.742104   |\n","| time/                   |              |\n","|    fps                  | 571          |\n","|    iterations           | 18           |\n","|    time_elapsed         | 516          |\n","|    total_timesteps      | 294912       |\n","| train/                  |              |\n","|    approx_kl            | 0.0037921725 |\n","|    clip_fraction        | 0.034        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.83        |\n","|    explained_variance   | 0.0212       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1.83         |\n","|    n_updates            | 170          |\n","|    policy_gradient_loss | -0.00102     |\n","|    std                  | 0.995        |\n","|    value_loss           | 3.55         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -19.359932   |\n","| time/                   |              |\n","|    fps                  | 571          |\n","|    iterations           | 19           |\n","|    time_elapsed         | 544          |\n","|    total_timesteps      | 311296       |\n","| train/                  |              |\n","|    approx_kl            | 0.0036882095 |\n","|    clip_fraction        | 0.0266       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.81        |\n","|    explained_variance   | 0.0163       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1.38         |\n","|    n_updates            | 180          |\n","|    policy_gradient_loss | -0.00126     |\n","|    std                  | 0.981        |\n","|    value_loss           | 2.96         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -16.459278  |\n","| time/                   |             |\n","|    fps                  | 572         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 572         |\n","|    total_timesteps      | 327680      |\n","| train/                  |             |\n","|    approx_kl            | 0.003891468 |\n","|    clip_fraction        | 0.031       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.79       |\n","|    explained_variance   | 0.0718      |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 1.57        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.00181    |\n","|    std                  | 0.979       |\n","|    value_loss           | 3.43        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -15.23135   |\n","| time/                   |             |\n","|    fps                  | 572         |\n","|    iterations           | 21          |\n","|    time_elapsed         | 600         |\n","|    total_timesteps      | 344064      |\n","| train/                  |             |\n","|    approx_kl            | 0.002958884 |\n","|    clip_fraction        | 0.0234      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.79       |\n","|    explained_variance   | 0.0173      |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 1.43        |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.000686   |\n","|    std                  | 0.974       |\n","|    value_loss           | 2.64        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -16.439281   |\n","| time/                   |              |\n","|    fps                  | 573          |\n","|    iterations           | 22           |\n","|    time_elapsed         | 628          |\n","|    total_timesteps      | 360448       |\n","| train/                  |              |\n","|    approx_kl            | 0.0039458303 |\n","|    clip_fraction        | 0.0218       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.77        |\n","|    explained_variance   | 0.0435       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1.2          |\n","|    n_updates            | 210          |\n","|    policy_gradient_loss | -0.00125     |\n","|    std                  | 0.964        |\n","|    value_loss           | 2.4          |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -16.514141   |\n","| time/                   |              |\n","|    fps                  | 573          |\n","|    iterations           | 23           |\n","|    time_elapsed         | 656          |\n","|    total_timesteps      | 376832       |\n","| train/                  |              |\n","|    approx_kl            | 0.0042888075 |\n","|    clip_fraction        | 0.035        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.75        |\n","|    explained_variance   | 0.127        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1.46         |\n","|    n_updates            | 220          |\n","|    policy_gradient_loss | -0.00195     |\n","|    std                  | 0.957        |\n","|    value_loss           | 2.69         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -18.133186   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 24           |\n","|    time_elapsed         | 684          |\n","|    total_timesteps      | 393216       |\n","| train/                  |              |\n","|    approx_kl            | 0.0034116467 |\n","|    clip_fraction        | 0.0304       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.74        |\n","|    explained_variance   | 0.0433       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1.11         |\n","|    n_updates            | 230          |\n","|    policy_gradient_loss | -0.00174     |\n","|    std                  | 0.948        |\n","|    value_loss           | 2.31         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -15.226062   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 25           |\n","|    time_elapsed         | 712          |\n","|    total_timesteps      | 409600       |\n","| train/                  |              |\n","|    approx_kl            | 0.0036641913 |\n","|    clip_fraction        | 0.0193       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.71        |\n","|    explained_variance   | 0.0553       |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 1            |\n","|    n_updates            | 240          |\n","|    policy_gradient_loss | -0.00116     |\n","|    std                  | 0.935        |\n","|    value_loss           | 2.03         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -14.035905  |\n","| time/                   |             |\n","|    fps                  | 574         |\n","|    iterations           | 26          |\n","|    time_elapsed         | 741         |\n","|    total_timesteps      | 425984      |\n","| train/                  |             |\n","|    approx_kl            | 0.004655158 |\n","|    clip_fraction        | 0.0333      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.7        |\n","|    explained_variance   | 0.151       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.913       |\n","|    n_updates            | 250         |\n","|    policy_gradient_loss | -0.00226    |\n","|    std                  | 0.934       |\n","|    value_loss           | 1.88        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -12.630901  |\n","| time/                   |             |\n","|    fps                  | 574         |\n","|    iterations           | 27          |\n","|    time_elapsed         | 770         |\n","|    total_timesteps      | 442368      |\n","| train/                  |             |\n","|    approx_kl            | 0.004556961 |\n","|    clip_fraction        | 0.0342      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.69       |\n","|    explained_variance   | 0.241       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.797       |\n","|    n_updates            | 260         |\n","|    policy_gradient_loss | -0.00221    |\n","|    std                  | 0.926       |\n","|    value_loss           | 1.58        |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -12.428126   |\n","| time/                   |              |\n","|    fps                  | 573          |\n","|    iterations           | 28           |\n","|    time_elapsed         | 799          |\n","|    total_timesteps      | 458752       |\n","| train/                  |              |\n","|    approx_kl            | 0.0056269797 |\n","|    clip_fraction        | 0.0533       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.68        |\n","|    explained_variance   | 0.364        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.55         |\n","|    n_updates            | 270          |\n","|    policy_gradient_loss | -0.00337     |\n","|    std                  | 0.923        |\n","|    value_loss           | 1.24         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -10.652816   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 29           |\n","|    time_elapsed         | 827          |\n","|    total_timesteps      | 475136       |\n","| train/                  |              |\n","|    approx_kl            | 0.0056239776 |\n","|    clip_fraction        | 0.0528       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.66        |\n","|    explained_variance   | 0.454        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.488        |\n","|    n_updates            | 280          |\n","|    policy_gradient_loss | -0.00365     |\n","|    std                  | 0.91         |\n","|    value_loss           | 0.963        |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -10.389169  |\n","| time/                   |             |\n","|    fps                  | 574         |\n","|    iterations           | 30          |\n","|    time_elapsed         | 855         |\n","|    total_timesteps      | 491520      |\n","| train/                  |             |\n","|    approx_kl            | 0.003174337 |\n","|    clip_fraction        | 0.049       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.64       |\n","|    explained_variance   | 0.514       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.364       |\n","|    n_updates            | 290         |\n","|    policy_gradient_loss | -0.00404    |\n","|    std                  | 0.903       |\n","|    value_loss           | 0.764       |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -9.007679   |\n","| time/                   |             |\n","|    fps                  | 574         |\n","|    iterations           | 31          |\n","|    time_elapsed         | 884         |\n","|    total_timesteps      | 507904      |\n","| train/                  |             |\n","|    approx_kl            | 0.007014873 |\n","|    clip_fraction        | 0.0586      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.63       |\n","|    explained_variance   | 0.556       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.344       |\n","|    n_updates            | 300         |\n","|    policy_gradient_loss | -0.00482    |\n","|    std                  | 0.899       |\n","|    value_loss           | 0.701       |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -7.7787995   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 32           |\n","|    time_elapsed         | 912          |\n","|    total_timesteps      | 524288       |\n","| train/                  |              |\n","|    approx_kl            | 0.0049972106 |\n","|    clip_fraction        | 0.062        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.61        |\n","|    explained_variance   | 0.584        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.222        |\n","|    n_updates            | 310          |\n","|    policy_gradient_loss | -0.00296     |\n","|    std                  | 0.888        |\n","|    value_loss           | 0.485        |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -7.2674894   |\n","| time/                   |              |\n","|    fps                  | 574          |\n","|    iterations           | 33           |\n","|    time_elapsed         | 940          |\n","|    total_timesteps      | 540672       |\n","| train/                  |              |\n","|    approx_kl            | 0.0047672037 |\n","|    clip_fraction        | 0.0424       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.59        |\n","|    explained_variance   | 0.615        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.177        |\n","|    n_updates            | 320          |\n","|    policy_gradient_loss | -0.004       |\n","|    std                  | 0.884        |\n","|    value_loss           | 0.44         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -7.32339    |\n","| time/                   |             |\n","|    fps                  | 575         |\n","|    iterations           | 34          |\n","|    time_elapsed         | 968         |\n","|    total_timesteps      | 557056      |\n","| train/                  |             |\n","|    approx_kl            | 0.004522312 |\n","|    clip_fraction        | 0.0461      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.58       |\n","|    explained_variance   | 0.648       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.149       |\n","|    n_updates            | 330         |\n","|    policy_gradient_loss | -0.00288    |\n","|    std                  | 0.878       |\n","|    value_loss           | 0.333       |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -6.898599   |\n","| time/                   |             |\n","|    fps                  | 575         |\n","|    iterations           | 35          |\n","|    time_elapsed         | 996         |\n","|    total_timesteps      | 573440      |\n","| train/                  |             |\n","|    approx_kl            | 0.004613922 |\n","|    clip_fraction        | 0.0384      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.56       |\n","|    explained_variance   | 0.685       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.138       |\n","|    n_updates            | 340         |\n","|    policy_gradient_loss | -0.00368    |\n","|    std                  | 0.87        |\n","|    value_loss           | 0.299       |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -5.363548   |\n","| time/                   |             |\n","|    fps                  | 575         |\n","|    iterations           | 36          |\n","|    time_elapsed         | 1024        |\n","|    total_timesteps      | 589824      |\n","| train/                  |             |\n","|    approx_kl            | 0.007865342 |\n","|    clip_fraction        | 0.0568      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.54       |\n","|    explained_variance   | 0.75        |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.0981      |\n","|    n_updates            | 350         |\n","|    policy_gradient_loss | -0.00179    |\n","|    std                  | 0.858       |\n","|    value_loss           | 0.223       |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -5.60253     |\n","| time/                   |              |\n","|    fps                  | 576          |\n","|    iterations           | 37           |\n","|    time_elapsed         | 1052         |\n","|    total_timesteps      | 606208       |\n","| train/                  |              |\n","|    approx_kl            | 0.0054144925 |\n","|    clip_fraction        | 0.056        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.52        |\n","|    explained_variance   | 0.781        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0725       |\n","|    n_updates            | 360          |\n","|    policy_gradient_loss | -0.00365     |\n","|    std                  | 0.849        |\n","|    value_loss           | 0.136        |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -5.2474055   |\n","| time/                   |              |\n","|    fps                  | 576          |\n","|    iterations           | 38           |\n","|    time_elapsed         | 1080         |\n","|    total_timesteps      | 622592       |\n","| train/                  |              |\n","|    approx_kl            | 0.0043176073 |\n","|    clip_fraction        | 0.0467       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.5         |\n","|    explained_variance   | 0.799        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0577       |\n","|    n_updates            | 370          |\n","|    policy_gradient_loss | -0.00322     |\n","|    std                  | 0.843        |\n","|    value_loss           | 0.126        |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -5.167963    |\n","| time/                   |              |\n","|    fps                  | 576          |\n","|    iterations           | 39           |\n","|    time_elapsed         | 1108         |\n","|    total_timesteps      | 638976       |\n","| train/                  |              |\n","|    approx_kl            | 0.0055856314 |\n","|    clip_fraction        | 0.0459       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.48        |\n","|    explained_variance   | 0.827        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0473       |\n","|    n_updates            | 380          |\n","|    policy_gradient_loss | -0.00381     |\n","|    std                  | 0.835        |\n","|    value_loss           | 0.12         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -4.461251   |\n","| time/                   |             |\n","|    fps                  | 576         |\n","|    iterations           | 40          |\n","|    time_elapsed         | 1136        |\n","|    total_timesteps      | 655360      |\n","| train/                  |             |\n","|    approx_kl            | 0.005175844 |\n","|    clip_fraction        | 0.0493      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.47       |\n","|    explained_variance   | 0.814       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.0623      |\n","|    n_updates            | 390         |\n","|    policy_gradient_loss | -0.00275    |\n","|    std                  | 0.831       |\n","|    value_loss           | 0.134       |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -4.240112    |\n","| time/                   |              |\n","|    fps                  | 576          |\n","|    iterations           | 41           |\n","|    time_elapsed         | 1164         |\n","|    total_timesteps      | 671744       |\n","| train/                  |              |\n","|    approx_kl            | 0.0037342012 |\n","|    clip_fraction        | 0.0427       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.46        |\n","|    explained_variance   | 0.856        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0236       |\n","|    n_updates            | 400          |\n","|    policy_gradient_loss | -0.00192     |\n","|    std                  | 0.826        |\n","|    value_loss           | 0.0585       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -4.683312    |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 42           |\n","|    time_elapsed         | 1191         |\n","|    total_timesteps      | 688128       |\n","| train/                  |              |\n","|    approx_kl            | 0.0045121475 |\n","|    clip_fraction        | 0.0307       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.44        |\n","|    explained_variance   | 0.888        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0232       |\n","|    n_updates            | 410          |\n","|    policy_gradient_loss | -0.00187     |\n","|    std                  | 0.813        |\n","|    value_loss           | 0.0456       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -4.357022    |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 43           |\n","|    time_elapsed         | 1220         |\n","|    total_timesteps      | 704512       |\n","| train/                  |              |\n","|    approx_kl            | 0.0059183864 |\n","|    clip_fraction        | 0.0575       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.43        |\n","|    explained_variance   | 0.729        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0964       |\n","|    n_updates            | 420          |\n","|    policy_gradient_loss | -0.00356     |\n","|    std                  | 0.819        |\n","|    value_loss           | 0.17         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -4.4363236   |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 44           |\n","|    time_elapsed         | 1248         |\n","|    total_timesteps      | 720896       |\n","| train/                  |              |\n","|    approx_kl            | 0.0052099125 |\n","|    clip_fraction        | 0.0395       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.43        |\n","|    explained_variance   | 0.901        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.0119       |\n","|    n_updates            | 430          |\n","|    policy_gradient_loss | -0.00109     |\n","|    std                  | 0.811        |\n","|    value_loss           | 0.0371       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -5.0247397   |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 45           |\n","|    time_elapsed         | 1276         |\n","|    total_timesteps      | 737280       |\n","| train/                  |              |\n","|    approx_kl            | 0.0071893362 |\n","|    clip_fraction        | 0.0692       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.39        |\n","|    explained_variance   | 0.909        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00873      |\n","|    n_updates            | 440          |\n","|    policy_gradient_loss | -0.00377     |\n","|    std                  | 0.795        |\n","|    value_loss           | 0.044        |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -3.995918   |\n","| time/                   |             |\n","|    fps                  | 577         |\n","|    iterations           | 46          |\n","|    time_elapsed         | 1304        |\n","|    total_timesteps      | 753664      |\n","| train/                  |             |\n","|    approx_kl            | 0.005401356 |\n","|    clip_fraction        | 0.0504      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.37       |\n","|    explained_variance   | 0.929       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.0148      |\n","|    n_updates            | 450         |\n","|    policy_gradient_loss | -0.00359    |\n","|    std                  | 0.791       |\n","|    value_loss           | 0.0434      |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.6943457   |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 47           |\n","|    time_elapsed         | 1332         |\n","|    total_timesteps      | 770048       |\n","| train/                  |              |\n","|    approx_kl            | 0.0039858175 |\n","|    clip_fraction        | 0.0649       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.36        |\n","|    explained_variance   | 0.931        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00495      |\n","|    n_updates            | 460          |\n","|    policy_gradient_loss | -0.00402     |\n","|    std                  | 0.784        |\n","|    value_loss           | 0.027        |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -3.4940927  |\n","| time/                   |             |\n","|    fps                  | 578         |\n","|    iterations           | 48          |\n","|    time_elapsed         | 1360        |\n","|    total_timesteps      | 786432      |\n","| train/                  |             |\n","|    approx_kl            | 0.007766734 |\n","|    clip_fraction        | 0.0498      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.34       |\n","|    explained_variance   | 0.928       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.00826     |\n","|    n_updates            | 470         |\n","|    policy_gradient_loss | -0.00262    |\n","|    std                  | 0.774       |\n","|    value_loss           | 0.0223      |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -3.4513314  |\n","| time/                   |             |\n","|    fps                  | 578         |\n","|    iterations           | 49          |\n","|    time_elapsed         | 1388        |\n","|    total_timesteps      | 802816      |\n","| train/                  |             |\n","|    approx_kl            | 0.004691406 |\n","|    clip_fraction        | 0.0535      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.31       |\n","|    explained_variance   | 0.945       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | -0.00193    |\n","|    n_updates            | 480         |\n","|    policy_gradient_loss | -0.00401    |\n","|    std                  | 0.765       |\n","|    value_loss           | 0.018       |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.411217    |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 50           |\n","|    time_elapsed         | 1416         |\n","|    total_timesteps      | 819200       |\n","| train/                  |              |\n","|    approx_kl            | 0.0061305026 |\n","|    clip_fraction        | 0.0795       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.28        |\n","|    explained_variance   | 0.914        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00914      |\n","|    n_updates            | 490          |\n","|    policy_gradient_loss | -0.00275     |\n","|    std                  | 0.752        |\n","|    value_loss           | 0.0231       |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -3.8387785  |\n","| time/                   |             |\n","|    fps                  | 577         |\n","|    iterations           | 51          |\n","|    time_elapsed         | 1446        |\n","|    total_timesteps      | 835584      |\n","| train/                  |             |\n","|    approx_kl            | 0.006980977 |\n","|    clip_fraction        | 0.0624      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.24       |\n","|    explained_variance   | 0.924       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.0046      |\n","|    n_updates            | 500         |\n","|    policy_gradient_loss | -0.00342    |\n","|    std                  | 0.734       |\n","|    value_loss           | 0.0194      |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.5223472   |\n","| time/                   |              |\n","|    fps                  | 577          |\n","|    iterations           | 52           |\n","|    time_elapsed         | 1474         |\n","|    total_timesteps      | 851968       |\n","| train/                  |              |\n","|    approx_kl            | 0.0065789167 |\n","|    clip_fraction        | 0.0825       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.2         |\n","|    explained_variance   | 0.949        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00204      |\n","|    n_updates            | 510          |\n","|    policy_gradient_loss | -0.00213     |\n","|    std                  | 0.721        |\n","|    value_loss           | 0.0215       |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -3.2460525  |\n","| time/                   |             |\n","|    fps                  | 578         |\n","|    iterations           | 53          |\n","|    time_elapsed         | 1502        |\n","|    total_timesteps      | 868352      |\n","| train/                  |             |\n","|    approx_kl            | 0.008112618 |\n","|    clip_fraction        | 0.0615      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.18       |\n","|    explained_variance   | 0.893       |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.00786     |\n","|    n_updates            | 520         |\n","|    policy_gradient_loss | -0.00407    |\n","|    std                  | 0.719       |\n","|    value_loss           | 0.0359      |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.7316883   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 54           |\n","|    time_elapsed         | 1530         |\n","|    total_timesteps      | 884736       |\n","| train/                  |              |\n","|    approx_kl            | 0.0053598206 |\n","|    clip_fraction        | 0.0755       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.16        |\n","|    explained_variance   | 0.932        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00134      |\n","|    n_updates            | 530          |\n","|    policy_gradient_loss | -0.00231     |\n","|    std                  | 0.708        |\n","|    value_loss           | 0.0169       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.2603164   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 55           |\n","|    time_elapsed         | 1558         |\n","|    total_timesteps      | 901120       |\n","| train/                  |              |\n","|    approx_kl            | 0.0039523523 |\n","|    clip_fraction        | 0.0413       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.14        |\n","|    explained_variance   | 0.957        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00223      |\n","|    n_updates            | 540          |\n","|    policy_gradient_loss | -0.00294     |\n","|    std                  | 0.702        |\n","|    value_loss           | 0.0167       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.1975741   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 56           |\n","|    time_elapsed         | 1585         |\n","|    total_timesteps      | 917504       |\n","| train/                  |              |\n","|    approx_kl            | 0.0060720653 |\n","|    clip_fraction        | 0.0641       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.11        |\n","|    explained_variance   | 0.947        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00481      |\n","|    n_updates            | 550          |\n","|    policy_gradient_loss | -0.00428     |\n","|    std                  | 0.687        |\n","|    value_loss           | 0.0134       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -2.7195954   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 57           |\n","|    time_elapsed         | 1613         |\n","|    total_timesteps      | 933888       |\n","| train/                  |              |\n","|    approx_kl            | 0.0057197297 |\n","|    clip_fraction        | 0.0547       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.07        |\n","|    explained_variance   | 0.947        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | 0.00339      |\n","|    n_updates            | 560          |\n","|    policy_gradient_loss | -0.00239     |\n","|    std                  | 0.681        |\n","|    value_loss           | 0.0116       |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.0823593   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 58           |\n","|    time_elapsed         | 1641         |\n","|    total_timesteps      | 950272       |\n","| train/                  |              |\n","|    approx_kl            | 0.0076614968 |\n","|    clip_fraction        | 0.0707       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.06        |\n","|    explained_variance   | 0.95         |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | -0.0033      |\n","|    n_updates            | 570          |\n","|    policy_gradient_loss | -0.0034      |\n","|    std                  | 0.673        |\n","|    value_loss           | 0.00678      |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -2.872926   |\n","| time/                   |             |\n","|    fps                  | 578         |\n","|    iterations           | 59          |\n","|    time_elapsed         | 1669        |\n","|    total_timesteps      | 966656      |\n","| train/                  |             |\n","|    approx_kl            | 0.009482986 |\n","|    clip_fraction        | 0.0785      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -2.04       |\n","|    explained_variance   | 0.96        |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | -0.00263    |\n","|    n_updates            | 580         |\n","|    policy_gradient_loss | -0.00365    |\n","|    std                  | 0.667       |\n","|    value_loss           | 0.00962     |\n","-----------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.0963578   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 60           |\n","|    time_elapsed         | 1698         |\n","|    total_timesteps      | 983040       |\n","| train/                  |              |\n","|    approx_kl            | 0.0055935825 |\n","|    clip_fraction        | 0.0633       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -2.02        |\n","|    explained_variance   | 0.958        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | -0.000999    |\n","|    n_updates            | 590          |\n","|    policy_gradient_loss | -0.00221     |\n","|    std                  | 0.66         |\n","|    value_loss           | 0.00772      |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 200          |\n","|    ep_rew_mean          | -3.4136505   |\n","| time/                   |              |\n","|    fps                  | 578          |\n","|    iterations           | 61           |\n","|    time_elapsed         | 1726         |\n","|    total_timesteps      | 999424       |\n","| train/                  |              |\n","|    approx_kl            | 0.0073733507 |\n","|    clip_fraction        | 0.0531       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -1.99        |\n","|    explained_variance   | 0.954        |\n","|    learning_rate        | 0.0005       |\n","|    loss                 | -0.000257    |\n","|    n_updates            | 600          |\n","|    policy_gradient_loss | -0.00254     |\n","|    std                  | 0.652        |\n","|    value_loss           | 0.0108       |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 200         |\n","|    ep_rew_mean          | -2.6127431  |\n","| time/                   |             |\n","|    fps                  | 578         |\n","|    iterations           | 62          |\n","|    time_elapsed         | 1754        |\n","|    total_timesteps      | 1015808     |\n","| train/                  |             |\n","|    approx_kl            | 0.007189634 |\n","|    clip_fraction        | 0.0676      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.97       |\n","|    explained_variance   | 0.93        |\n","|    learning_rate        | 0.0005      |\n","|    loss                 | 0.00553     |\n","|    n_updates            | 610         |\n","|    policy_gradient_loss | -0.00204    |\n","|    std                  | 0.647       |\n","|    value_loss           | 0.0156      |\n","-----------------------------------------\n"]}]},{"cell_type":"markdown","source":["## Grading and evaluation\n","\n","The total number of points for Part 2 is 7.5. We will evaluate your trained model on 5 random goal locations. For each test, we assign points based on the distance between the end effector and the goal location at the end of the episode.\n","\n","- If 0 < distance < 0.05, you get 1.5 points.\n","- If 0.05 <= distance < 0.1, you get 1 point.\n","- If distance >= 0.1, you get 0 point.\n","\n"],"metadata":{"id":"f9N2falIz9rq"}},{"cell_type":"code","source":["from score import score_policy\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.utils import set_random_seed\n","from robot import Robot\n","from arm_dynamics import ArmDynamics\n","from render import Renderer\n","import time\n","\n","# Set the path to your model\n","model_path = 'ppo_network.zip'\n","\n","set_random_seed(seed=100)\n","\n","# Create arm robot\n","arm = make_arm()\n","\n","# Create environment\n","env = ArmEnv(arm, gui=False)\n","env.seed(100)\n","\n","# Load and test policy\n","policy = PPO.load(model_path)\n","score_policy(policy, env)"],"metadata":{"id":"X6eQ2mzglwd0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714077709974,"user_tz":240,"elapsed":1287,"user":{"displayName":"Jingran Wang","userId":"11496959489179416337"}},"outputId":"79e52a99-5612-4e1b-9b81-ba5d99b127c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Computing score ---\n","\n","Goal 1: 1.5\n","\n","Goal 2: 1.5\n","\n","Goal 3: 1.5\n","\n","Goal 4: 1.5\n","\n","Goal 5: 1.5\n","\n","\n","---\n","Final score: 7.5/7.5\n","---\n"]},{"output_type":"execute_result","data":{"text/plain":["7.5"]},"metadata":{},"execution_count":44}]}]}